{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Instructions: Panel Data Modeling with Machine Learning Models\n",
    "\n",
    "**Objective:**\n",
    "The goal of this exercise is to practice panel data modeling skills using three machine learning models (Random Forest, Single Decision Tree, and Linear Regression with Elastic Net) that have not been utilized in the project so far. Completing the entire task or a significant portion during the class will earn you an additional 7 points (above what is outlined in the syllabus) towards your final grade.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. **GitHub Setup:**\n",
    "   - If you haven't done so already, [create](https://github.com/join) a GitHub account.\n",
    "   - [Download](https://desktop.github.com) and [configure](https://docs.github.com/en/desktop/configuring-and-customizing-github-desktop/configuring-basic-settings-in-github-desktop) GitHub Desktop on your laptop. (Here you can find nice intro to the GitHub Dekstop app: [link](https://joshuadull.github.io/GitHub-Desktop/02-getting-started/index.html)). If you prefare git command line usage you can go with this [instruction](https://github.com/michaelwozniak/ml2_tools?tab=readme-ov-file#git).\n",
    "2. **Repository Forking:**\n",
    "   - [Fork](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo) the following repository to your projects: [https://github.com/michaelwozniak/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates](https://github.com/michaelwozniak/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates)\n",
    "\n",
    "3. **Repository Cloning:**\n",
    "   - [Clone](https://docs.github.com/en/desktop/adding-and-cloning-repositories/cloning-a-repository-from-github-to-github-desktop) the forked repository to your local computer using GitHub Desktop.\n",
    "\n",
    "4. **Notebook Exploration:**\n",
    "   - Open the file `notebooks/10.exercise.ipynb` to begin the ML tasks.\n",
    "\n",
    "5. **Model Creation:**\n",
    "\n",
    "   In the file `notebooks/10.exercise.ipynb`:\n",
    "   - Create the following models:\n",
    "      1. Random Forest ([RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html))\n",
    "      2. Decision Tree ([DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html))\n",
    "      3. Linear Regression with Elastic Net ([ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html))\n",
    "   \n",
    "   Follow a similar process to the models presented in class (e.g., KNN - `notebooks/07.knn-model.ipynb`):\n",
    "      - Load the prepared training data.\n",
    "      - Perform feature engineering if deemed necessary (note: these three models do not require data standardization, unlike SVM and KNN).\n",
    "      - Conduct feature selection.\n",
    "      - Perform hyperparameter tuning.\n",
    "      - Identify a local champion for each model class (the best model for RF, DT, Elastic Net).\n",
    "      - Save local champions to a pickle file.\n",
    "\n",
    "6. **Model Evaluation:**\n",
    "   - In the notebook `notebooks/09.final-comparison-and-summary.ipynb`, load the models you created and check if they outperform the previously used models.\n",
    "\n",
    "7. **Version Control:**\n",
    "   - At the end of the class, even if the tasks are incomplete, [commit](https://docs.github.com/en/desktop/making-changes-in-a-branch/committing-and-reviewing-changes-to-your-project-in-github-desktop) your changes using GitHub Desktop.\n",
    "   - [Push](https://docs.github.com/en/desktop/making-changes-in-a-branch/pushing-changes-to-github-from-github-desktop) your changes to your remote GitHub repository.\n",
    "\n",
    "8. **Submission:**\n",
    "   - Send me the link to your GitHub project (my email: *mj.wozniak9@uw.edu.pl*).\n",
    "\n",
    "Good luck with the exercise! If you have any questions, feel free to ask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Dependencies loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import uniform\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree  import DecisionTreeRegressor\n",
    "from ReliefF import ReliefF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    Lasso,\n",
    "    Ridge,\n",
    "    ElasticNet\n",
    ")\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    ShuffleSplit,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    RandomizedSearchCV,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    median_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 150)\n",
    "\n",
    "# np.random.seed(1916)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_output_data_path = \"C:/Users/adria/Desktop/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates-main/data/output\"\n",
    "\n",
    "df = pd.read_csv(f\"{preprocessed_output_data_path}/train_fe.csv\", index_col=0)\n",
    "\n",
    "fr = pd.read_excel(f\"{preprocessed_output_data_path}/feature_ranking.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can omit that part in the case of Decision Tree \n",
    "# (as stated in the exercise description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['etr_y_past', 'etr_y_ma', 'txt', 'diff', 'ni', 'pi', 'intant', 'intant_sqrt', 'ta', 'revenue']\n"
     ]
    }
   ],
   "source": [
    "# Searching for \"good enough\" model to feature selection\n",
    "var = fr.mi_score.sort_values(ascending=False).index.tolist()[0:10]\n",
    "print(var)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.190189111918315"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 5, 10, 15, 20],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(mean_squared_error, greater_is_better=False))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param = {\n",
    "    \"max_depth\": [None, 5, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "# Define the mean squared error scorer\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Create the DecisionTreeRegressor model\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_CV = GridSearchCV(\n",
    "    model, param, cv=5, scoring=mse, return_train_score=True, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_CV.fit(df.loc[:, var].values, df.loc[:, \"etr\"].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_CV.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.09602318, 0.09837122, 0.0949203 , 0.08719249, 0.07798138,\n",
      "       0.09028826, 0.08354769, 0.0917398 , 0.09120336, 0.03666186,\n",
      "       0.03506136, 0.02604718, 0.02959561, 0.02095399, 0.03077555,\n",
      "       0.03885016, 0.02375045, 0.0237236 , 0.03246307, 0.03258634,\n",
      "       0.03741431, 0.02968779, 0.03018656, 0.02597985, 0.02463503,\n",
      "       0.02206926, 0.03017106, 0.03148799, 0.02590027, 0.02861176,\n",
      "       0.02816958, 0.02838688, 0.02843471, 0.02988653, 0.03364525,\n",
      "       0.03132849, 0.01167574, 0.01153188, 0.00740566, 0.01012535,\n",
      "       0.00575752, 0.01106195, 0.00752358, 0.0098175 , 0.01420555,\n",
      "       0.01164179, 0.01305232, 0.01097817, 0.00954418, 0.01628518,\n",
      "       0.01193423, 0.00939608, 0.01260509, 0.01303802, 0.05304685,\n",
      "       0.05430875, 0.0637578 , 0.05324702, 0.05264554, 0.06123562,\n",
      "       0.0607707 , 0.05731964, 0.06256399, 0.02012134, 0.01590466,\n",
      "       0.01953788, 0.01810355, 0.01528673, 0.02070103, 0.01621652,\n",
      "       0.01828384, 0.0171742 , 0.0180747 , 0.01714792, 0.01937761,\n",
      "       0.01709051, 0.01700535, 0.02111611, 0.01987414, 0.01815486,\n",
      "       0.01607661, 0.07320604, 0.07161999, 0.0740706 , 0.06789675,\n",
      "       0.06812596, 0.07533565, 0.07403898, 0.06516023, 0.07130589,\n",
      "       0.02103543, 0.02133718, 0.02507143, 0.02186751, 0.01899261,\n",
      "       0.02260141, 0.01986752, 0.02535887, 0.01985054, 0.02535267,\n",
      "       0.0330605 , 0.02519431, 0.02561116, 0.01985168, 0.0230948 ,\n",
      "       0.02362447, 0.03073831, 0.02578077, 0.08579631, 0.08938723,\n",
      "       0.08243375, 0.08523664, 0.07819796, 0.0866796 , 0.07058563,\n",
      "       0.07200074, 0.07110133, 0.02878399, 0.03034878, 0.0264657 ,\n",
      "       0.02530541, 0.02696123, 0.0230969 , 0.02174754, 0.0268374 ,\n",
      "       0.01519632, 0.02778506, 0.02625871, 0.02790461, 0.02479568,\n",
      "       0.02665348, 0.0261415 , 0.01631846, 0.02275424, 0.02407146]), 'std_fit_time': array([0.00463905, 0.00509617, 0.00694886, 0.00509618, 0.0080297 ,\n",
      "       0.00617245, 0.00862258, 0.01432119, 0.01418631, 0.00661593,\n",
      "       0.00401048, 0.00402386, 0.00642878, 0.00582828, 0.00352221,\n",
      "       0.00823309, 0.0058734 , 0.00732157, 0.01030448, 0.00512384,\n",
      "       0.01228511, 0.00375241, 0.00381054, 0.00493989, 0.00593711,\n",
      "       0.00498095, 0.00336431, 0.00358268, 0.00540466, 0.00383644,\n",
      "       0.00419523, 0.00663214, 0.01041475, 0.00410295, 0.00063555,\n",
      "       0.00278474, 0.00663062, 0.00609507, 0.00575696, 0.00643304,\n",
      "       0.00720619, 0.00370353, 0.00585048, 0.00632624, 0.00773377,\n",
      "       0.0066784 , 0.0072665 , 0.00670805, 0.00782901, 0.00381851,\n",
      "       0.00573861, 0.00526079, 0.00720322, 0.00446674, 0.006103  ,\n",
      "       0.00485511, 0.01185302, 0.00472155, 0.00705914, 0.01214571,\n",
      "       0.00983812, 0.00421097, 0.00953501, 0.00396468, 0.00354646,\n",
      "       0.00264665, 0.00320597, 0.00153477, 0.00761438, 0.00189632,\n",
      "       0.00301924, 0.00321024, 0.00561673, 0.00309603, 0.00794253,\n",
      "       0.00424975, 0.00298582, 0.00971345, 0.00638667, 0.00620432,\n",
      "       0.00056259, 0.00572355, 0.00627947, 0.00739655, 0.00616254,\n",
      "       0.00806712, 0.01550379, 0.00665352, 0.01085729, 0.00746283,\n",
      "       0.00539656, 0.00383696, 0.00173784, 0.00647676, 0.00468069,\n",
      "       0.00519567, 0.00674143, 0.00754198, 0.00267497, 0.0096932 ,\n",
      "       0.00488164, 0.00503994, 0.00798533, 0.00392883, 0.00373527,\n",
      "       0.00644327, 0.00649743, 0.01117933, 0.00763591, 0.01009756,\n",
      "       0.00558703, 0.00791575, 0.01597531, 0.01280199, 0.00271352,\n",
      "       0.00696287, 0.00449773, 0.0106175 , 0.00512443, 0.00505316,\n",
      "       0.0074328 , 0.00638136, 0.00834064, 0.00442026, 0.0044991 ,\n",
      "       0.00480373, 0.00714567, 0.00620072, 0.00615361, 0.00265328,\n",
      "       0.00654918, 0.00740755, 0.00426183, 0.00755498, 0.00636165]), 'mean_score_time': array([2.38080025e-03, 3.08036804e-04, 4.88805771e-04, 0.00000000e+00,\n",
      "       6.68354034e-03, 2.37417221e-04, 8.28552246e-04, 4.34780121e-04,\n",
      "       0.00000000e+00, 2.53887177e-03, 1.58023834e-03, 0.00000000e+00,\n",
      "       3.00621986e-03, 5.92808723e-03, 0.00000000e+00, 3.18527222e-05,\n",
      "       1.02829933e-03, 5.49373627e-03, 2.90193558e-03, 2.80151367e-03,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 1.33223534e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "       1.33223534e-03, 0.00000000e+00, 0.00000000e+00, 1.64322853e-03,\n",
      "       0.00000000e+00, 2.00462341e-04, 1.99937820e-04, 1.43251419e-03,\n",
      "       0.00000000e+00, 1.10321045e-03, 2.60934830e-03, 0.00000000e+00,\n",
      "       2.80127525e-03, 1.22551918e-03, 2.10962296e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 1.99842453e-04, 6.00194931e-04,\n",
      "       0.00000000e+00, 6.00242615e-04, 2.00176239e-04, 6.00767136e-04,\n",
      "       4.21047211e-04, 1.17959976e-03, 2.51994133e-03, 3.95107269e-04,\n",
      "       0.00000000e+00, 8.10480118e-04, 1.30167007e-03, 1.60160065e-03,\n",
      "       0.00000000e+00, 1.97577477e-03, 1.91860199e-03, 1.38163567e-03,\n",
      "       1.00102425e-03, 3.07703018e-04, 5.35917282e-04, 1.60160065e-03,\n",
      "       8.09526443e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 1.24707222e-03, 0.00000000e+00, 7.84492493e-04,\n",
      "       1.18203163e-03, 1.28126144e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.49125862e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       1.07049942e-03, 0.00000000e+00, 0.00000000e+00, 1.10101700e-03,\n",
      "       3.42655182e-04, 2.84767151e-04, 3.09705734e-03, 0.00000000e+00,\n",
      "       1.61185265e-03, 0.00000000e+00, 1.51228905e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 3.15189362e-05, 3.30381393e-03, 0.00000000e+00,\n",
      "       2.24857330e-03, 0.00000000e+00, 1.23510361e-03, 1.32055283e-03,\n",
      "       1.09930038e-03, 0.00000000e+00, 2.70910263e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 5.28907776e-04, 3.36074829e-04, 0.00000000e+00,\n",
      "       9.90962982e-04, 0.00000000e+00, 1.11560822e-03, 0.00000000e+00,\n",
      "       3.00407410e-05, 2.81381607e-03, 0.00000000e+00, 4.28628922e-04,\n",
      "       3.24249268e-05, 2.70133018e-03, 1.53560638e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 5.34076691e-03, 2.20799446e-03, 3.21831703e-03,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.34332085e-03,\n",
      "       0.00000000e+00, 0.00000000e+00, 2.01988220e-04]), 'std_score_time': array([2.91993841e-03, 6.16073608e-04, 9.77611542e-04, 0.00000000e+00,\n",
      "       8.18563176e-03, 4.74834442e-04, 1.65710449e-03, 8.69560242e-04,\n",
      "       0.00000000e+00, 4.98539846e-03, 3.16047668e-03, 0.00000000e+00,\n",
      "       5.51696071e-03, 7.27837239e-03, 0.00000000e+00, 6.37054443e-05,\n",
      "       2.05659866e-03, 1.03220944e-02, 5.80387115e-03, 5.60302734e-03,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 2.66447067e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "       2.66447067e-03, 0.00000000e+00, 0.00000000e+00, 3.28645706e-03,\n",
      "       0.00000000e+00, 4.00924683e-04, 3.99875641e-04, 2.86502838e-03,\n",
      "       0.00000000e+00, 2.20642090e-03, 5.21869659e-03, 0.00000000e+00,\n",
      "       5.60255051e-03, 2.45103836e-03, 4.21924591e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.99684906e-04, 4.90057140e-04,\n",
      "       0.00000000e+00, 4.90096251e-04, 4.00352478e-04, 4.90524343e-04,\n",
      "       5.16684053e-04, 2.35919952e-03, 3.26836180e-03, 7.58089646e-04,\n",
      "       0.00000000e+00, 1.55680478e-03, 2.60334015e-03, 3.20320129e-03,\n",
      "       0.00000000e+00, 2.92484623e-03, 2.91992346e-03, 2.76327133e-03,\n",
      "       2.00204849e-03, 6.15406036e-04, 1.07183456e-03, 3.20320129e-03,\n",
      "       1.61905289e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 2.49414444e-03, 0.00000000e+00, 1.56898499e-03,\n",
      "       2.36406326e-03, 2.56252289e-03, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.63060834e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       2.14099884e-03, 0.00000000e+00, 0.00000000e+00, 2.02559163e-03,\n",
      "       6.85310364e-04, 5.69534302e-04, 6.19411469e-03, 0.00000000e+00,\n",
      "       3.22370529e-03, 0.00000000e+00, 3.02457809e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 6.30378723e-05, 4.04947295e-03, 0.00000000e+00,\n",
      "       3.48074140e-03, 0.00000000e+00, 2.47020721e-03, 2.64110565e-03,\n",
      "       2.19860077e-03, 0.00000000e+00, 5.41820526e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 1.05781555e-03, 6.72149658e-04, 0.00000000e+00,\n",
      "       1.98192596e-03, 0.00000000e+00, 2.23121643e-03, 0.00000000e+00,\n",
      "       6.00814819e-05, 4.47147175e-03, 0.00000000e+00, 8.57257843e-04,\n",
      "       6.48498535e-05, 5.40266037e-03, 3.07121277e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 6.70251613e-03, 4.41598892e-03, 4.95153695e-03,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.17695034e-03,\n",
      "       0.00000000e+00, 0.00000000e+00, 4.03976440e-04]), 'param_max_depth': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 4, 4, 4, 1, 1, 1, 2, 2, 2, 4, 4, 4,\n",
      "                   1, 1, 1, 2, 2, 2, 4, 4, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
      "                   10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10,\n",
      "                   2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
      "                   10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10,\n",
      "                   2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
      "                   10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10,\n",
      "                   2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5,\n",
      "                   10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10, 2, 5, 10,\n",
      "                   2, 5, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10}], 'split0_test_score': array([-0.04463592, -0.0401845 , -0.03457658, -0.03419885, -0.03393472,\n",
      "       -0.02743963, -0.02805948, -0.02814249, -0.02708653, -0.05175064,\n",
      "       -0.03911417, -0.03783495, -0.03570185, -0.03235002, -0.02817538,\n",
      "       -0.02691779, -0.02793934, -0.02638254, -0.04142021, -0.03626801,\n",
      "       -0.03475689, -0.03422723, -0.03055273, -0.03232146, -0.0301045 ,\n",
      "       -0.028077  , -0.02598182, -0.02133365, -0.02124006, -0.02108951,\n",
      "       -0.01846557, -0.01837199, -0.01805337, -0.01871306, -0.01871306,\n",
      "       -0.01841648, -0.01738758, -0.01874763, -0.0210891 , -0.01857556,\n",
      "       -0.01695412, -0.01922447, -0.01866187, -0.01860361, -0.01883563,\n",
      "       -0.02230101, -0.02041561, -0.01824632, -0.01871393, -0.01908664,\n",
      "       -0.0193923 , -0.01940887, -0.01816583, -0.01792156, -0.03762772,\n",
      "       -0.03674437, -0.02576792, -0.0276502 , -0.02819011, -0.02264838,\n",
      "       -0.02426785, -0.02476622, -0.02355126, -0.02710486, -0.02472995,\n",
      "       -0.02850967, -0.02750211, -0.03045112, -0.02561852, -0.02381809,\n",
      "       -0.02663948, -0.02095391, -0.03117672, -0.02527082, -0.02890398,\n",
      "       -0.02407472, -0.03205291, -0.02739136, -0.0242425 , -0.0234334 ,\n",
      "       -0.02454317, -0.04771903, -0.04523428, -0.03177756, -0.0319994 ,\n",
      "       -0.03125534, -0.02620601, -0.02747081, -0.02707225, -0.02634421,\n",
      "       -0.03718492, -0.03443924, -0.03083618, -0.03491732, -0.02987146,\n",
      "       -0.02598509, -0.02444489, -0.02610928, -0.02704257, -0.04614064,\n",
      "       -0.02824728, -0.02679828, -0.03440114, -0.02806223, -0.03081407,\n",
      "       -0.02830232, -0.0301702 , -0.02707138, -0.04196204, -0.03914902,\n",
      "       -0.03550664, -0.03409511, -0.03428627, -0.02720514, -0.02804381,\n",
      "       -0.02835966, -0.0270267 , -0.04034616, -0.03893622, -0.03512536,\n",
      "       -0.03434286, -0.0312936 , -0.03489298, -0.02701847, -0.02919013,\n",
      "       -0.02493055, -0.04247969, -0.03579801, -0.03341074, -0.03343225,\n",
      "       -0.02944622, -0.02947545, -0.02909974, -0.02662655, -0.02412868]), 'split1_test_score': array([-0.05177882, -0.03927112, -0.03772585, -0.03996681, -0.03871112,\n",
      "       -0.03541075, -0.03469086, -0.03451605, -0.03387596, -0.04378211,\n",
      "       -0.03575721, -0.03264147, -0.03549938, -0.03965334, -0.03494715,\n",
      "       -0.0328515 , -0.02904207, -0.03274239, -0.04851557, -0.0393046 ,\n",
      "       -0.04039292, -0.03273956, -0.03340455, -0.03361847, -0.02763436,\n",
      "       -0.0260811 , -0.02789478, -0.02579717, -0.02241207, -0.02190512,\n",
      "       -0.02251528, -0.02260262, -0.02250402, -0.02285011, -0.02286441,\n",
      "       -0.02284335, -0.01970256, -0.01898511, -0.02086583, -0.01942034,\n",
      "       -0.02132847, -0.02307599, -0.02290746, -0.02047644, -0.02073801,\n",
      "       -0.0222146 , -0.02106199, -0.02009358, -0.02223721, -0.02227402,\n",
      "       -0.02123109, -0.02184115, -0.02220099, -0.01943906, -0.03103349,\n",
      "       -0.03086374, -0.02927146, -0.03167329, -0.0293198 , -0.029666  ,\n",
      "       -0.02954798, -0.02982414, -0.02920131, -0.03410935, -0.03418356,\n",
      "       -0.02550247, -0.02755981, -0.03170679, -0.02615111, -0.02421493,\n",
      "       -0.02468713, -0.02354514, -0.03546461, -0.02731187, -0.02557718,\n",
      "       -0.03014236, -0.02508314, -0.02452385, -0.0234593 , -0.02282301,\n",
      "       -0.02422649, -0.0376906 , -0.03538892, -0.03451432, -0.03606519,\n",
      "       -0.03372758, -0.03343923, -0.03380743, -0.03373134, -0.03330249,\n",
      "       -0.03302637, -0.03014707, -0.03496883, -0.03567344, -0.0329068 ,\n",
      "       -0.02566653, -0.02797395, -0.0285484 , -0.02689943, -0.03829522,\n",
      "       -0.03582331, -0.0341145 , -0.0358249 , -0.0294282 , -0.03204829,\n",
      "       -0.02996396, -0.02567318, -0.02756855, -0.04276974, -0.03820311,\n",
      "       -0.03658252, -0.03877244, -0.03642961, -0.03610284, -0.03463594,\n",
      "       -0.03443281, -0.0337582 , -0.03871543, -0.03251564, -0.03651438,\n",
      "       -0.03480161, -0.03650147, -0.03078901, -0.03005511, -0.03315698,\n",
      "       -0.02742124, -0.04365721, -0.03152904, -0.03689214, -0.03652185,\n",
      "       -0.03766658, -0.02958672, -0.0311636 , -0.03077003, -0.02603157]), 'split2_test_score': array([-0.03894326, -0.03648526, -0.03222332, -0.03305746, -0.0321854 ,\n",
      "       -0.03044996, -0.02730608, -0.02700172, -0.02661894, -0.04066198,\n",
      "       -0.03438736, -0.03280282, -0.03447292, -0.03599868, -0.03402433,\n",
      "       -0.03013367, -0.02867155, -0.02685574, -0.03915711, -0.03672442,\n",
      "       -0.03280966, -0.03434837, -0.02989202, -0.02924508, -0.03019303,\n",
      "       -0.02759232, -0.03030292, -0.02207563, -0.02207563, -0.02201946,\n",
      "       -0.02281687, -0.02281687, -0.0227607 , -0.0221755 , -0.02122831,\n",
      "       -0.02219396, -0.02195484, -0.02051497, -0.02093562, -0.01995246,\n",
      "       -0.02147393, -0.02076701, -0.02155701, -0.02123307, -0.01965797,\n",
      "       -0.02171957, -0.0221722 , -0.02533763, -0.02141479, -0.0212424 ,\n",
      "       -0.02120068, -0.01909046, -0.02195425, -0.02164891, -0.03009606,\n",
      "       -0.02794029, -0.0271093 , -0.02832306, -0.02728031, -0.02618616,\n",
      "       -0.02476059, -0.02502716, -0.02438655, -0.02920575, -0.0234351 ,\n",
      "       -0.02880588, -0.02625991, -0.02757365, -0.02604325, -0.02645829,\n",
      "       -0.02394777, -0.02681312, -0.02745136, -0.02805598, -0.02304923,\n",
      "       -0.0266128 , -0.02699767, -0.025535  , -0.02146965, -0.02277295,\n",
      "       -0.02302072, -0.03544189, -0.03314182, -0.03273822, -0.03096611,\n",
      "       -0.03046659, -0.02851213, -0.02505618, -0.02609508, -0.02572565,\n",
      "       -0.0374571 , -0.03323662, -0.03038566, -0.03236857, -0.02814141,\n",
      "       -0.02575383, -0.02797244, -0.02827809, -0.02632978, -0.03349458,\n",
      "       -0.03657169, -0.02620069, -0.03208736, -0.02932905, -0.02408137,\n",
      "       -0.02664693, -0.02892638, -0.0251415 , -0.0373047 , -0.03523291,\n",
      "       -0.03249357, -0.03192917, -0.03122161, -0.02977324, -0.02589533,\n",
      "       -0.02672744, -0.02598115, -0.03535875, -0.03010131, -0.03264429,\n",
      "       -0.02899473, -0.03178906, -0.03039799, -0.02695974, -0.02436524,\n",
      "       -0.02734159, -0.04131429, -0.04133304, -0.0283994 , -0.03465024,\n",
      "       -0.0339548 , -0.03645529, -0.0258377 , -0.02526022, -0.02656662]), 'split3_test_score': array([-0.05391935, -0.04969361, -0.04230365, -0.04371761, -0.04304588,\n",
      "       -0.03909762, -0.03427126, -0.03555948, -0.03396373, -0.04007755,\n",
      "       -0.04580527, -0.03644774, -0.03929622, -0.03619094, -0.03502339,\n",
      "       -0.03279347, -0.03416628, -0.03203086, -0.04992753, -0.04800234,\n",
      "       -0.03969321, -0.03987877, -0.04208895, -0.03827968, -0.03288254,\n",
      "       -0.03570474, -0.03224317, -0.02683713, -0.02682501, -0.02682501,\n",
      "       -0.02714693, -0.02714897, -0.02685506, -0.0260959 , -0.0260959 ,\n",
      "       -0.0260959 , -0.02819446, -0.02670582, -0.02572446, -0.02782417,\n",
      "       -0.02544841, -0.02573477, -0.02704711, -0.02515165, -0.02599496,\n",
      "       -0.02793747, -0.02565487, -0.02757341, -0.02756   , -0.02630596,\n",
      "       -0.02677977, -0.0262853 , -0.0257633 , -0.02626351, -0.03886088,\n",
      "       -0.03656236, -0.03490107, -0.03831456, -0.03683658, -0.03458174,\n",
      "       -0.03143349, -0.03268227, -0.03123241, -0.03706625, -0.03602151,\n",
      "       -0.03040243, -0.03242741, -0.0299563 , -0.031136  , -0.02832958,\n",
      "       -0.03270855, -0.02834834, -0.03263341, -0.03522711, -0.03252125,\n",
      "       -0.03254223, -0.03481555, -0.02934454, -0.03239574, -0.02792707,\n",
      "       -0.02917448, -0.04583415, -0.04329264, -0.04019882, -0.04265229,\n",
      "       -0.04150259, -0.03790417, -0.03485153, -0.03337376, -0.03320713,\n",
      "       -0.04291247, -0.04561923, -0.03397063, -0.04353682, -0.03588921,\n",
      "       -0.03338423, -0.03187343, -0.03374769, -0.03278942, -0.04345386,\n",
      "       -0.03871697, -0.03587242, -0.0337142 , -0.03790064, -0.03247666,\n",
      "       -0.03104342, -0.0323091 , -0.0318151 , -0.04998022, -0.04532146,\n",
      "       -0.04228665, -0.04473609, -0.04315625, -0.03875529, -0.0352662 ,\n",
      "       -0.03421629, -0.03369295, -0.04570743, -0.03831439, -0.03907015,\n",
      "       -0.03878852, -0.04320421, -0.03796512, -0.03434557, -0.03216418,\n",
      "       -0.03487238, -0.04365721, -0.04615531, -0.03660596, -0.0410197 ,\n",
      "       -0.03530804, -0.03285124, -0.03111317, -0.03366282, -0.03199604]), 'split4_test_score': array([-0.04971186, -0.04186727, -0.03934818, -0.04228024, -0.04008854,\n",
      "       -0.03667536, -0.03415115, -0.03412089, -0.03391367, -0.04092876,\n",
      "       -0.05476635, -0.0328346 , -0.03275347, -0.03738415, -0.03684633,\n",
      "       -0.03521486, -0.03091884, -0.02979398, -0.04122698, -0.03016804,\n",
      "       -0.03438592, -0.0383284 , -0.03467658, -0.03517307, -0.03235803,\n",
      "       -0.03204958, -0.03265988, -0.02441769, -0.0247432 , -0.02406693,\n",
      "       -0.02401094, -0.02401094, -0.02401094, -0.02420881, -0.02420881,\n",
      "       -0.02420881, -0.0264473 , -0.02347717, -0.02333112, -0.02301272,\n",
      "       -0.02403696, -0.02282645, -0.0232339 , -0.02526264, -0.02347327,\n",
      "       -0.02352838, -0.02450222, -0.02477458, -0.02344698, -0.0238488 ,\n",
      "       -0.0258383 , -0.02349957, -0.02410849, -0.02380964, -0.03355642,\n",
      "       -0.03243602, -0.03358547, -0.03085181, -0.03078264, -0.0308755 ,\n",
      "       -0.03128228, -0.03128774, -0.03115068, -0.02819161, -0.03052171,\n",
      "       -0.02768219, -0.03120224, -0.0289024 , -0.02765338, -0.02755482,\n",
      "       -0.02930364, -0.0304143 , -0.02984269, -0.02567463, -0.02708085,\n",
      "       -0.02916004, -0.03056035, -0.03082936, -0.02967922, -0.02928434,\n",
      "       -0.02805578, -0.04378861, -0.04011889, -0.0381234 , -0.03831775,\n",
      "       -0.03756491, -0.0347282 , -0.03394022, -0.03375583, -0.03363302,\n",
      "       -0.03688851, -0.03443458, -0.03099824, -0.03529523, -0.03630244,\n",
      "       -0.03862302, -0.02916694, -0.03567197, -0.02970121, -0.03940649,\n",
      "       -0.03671169, -0.02850049, -0.0318601 , -0.03432258, -0.02856909,\n",
      "       -0.03024869, -0.03181485, -0.02767627, -0.04138372, -0.04144237,\n",
      "       -0.03909518, -0.04033091, -0.03938508, -0.03654128, -0.03404937,\n",
      "       -0.03419943, -0.03375542, -0.04248419, -0.04485792, -0.03365611,\n",
      "       -0.03624989, -0.03694697, -0.0312965 , -0.03316626, -0.03358318,\n",
      "       -0.03175794, -0.04163136, -0.04425017, -0.03775232, -0.04041034,\n",
      "       -0.03177474, -0.03311777, -0.03498406, -0.03336501, -0.02898494]), 'mean_test_score': array([-0.04779784, -0.04150035, -0.03723552, -0.03864419, -0.03759313,\n",
      "       -0.03381466, -0.03169577, -0.03186813, -0.03109177, -0.04344021,\n",
      "       -0.04196607, -0.03451232, -0.03554477, -0.03631543, -0.03380332,\n",
      "       -0.03158226, -0.03014761, -0.0295611 , -0.04404948, -0.03809348,\n",
      "       -0.03640772, -0.03590447, -0.03412296, -0.03372755, -0.03063449,\n",
      "       -0.02990095, -0.02981651, -0.02409225, -0.0234592 , -0.0231812 ,\n",
      "       -0.02299112, -0.02299028, -0.02283682, -0.02280867, -0.0226221 ,\n",
      "       -0.0227517 , -0.02273735, -0.02168614, -0.02238923, -0.02175705,\n",
      "       -0.02184838, -0.02232574, -0.02268147, -0.02214548, -0.02173997,\n",
      "       -0.02354021, -0.02276138, -0.0232051 , -0.02267458, -0.02255156,\n",
      "       -0.02288843, -0.02202507, -0.02243857, -0.02181654, -0.03423491,\n",
      "       -0.03290936, -0.03012704, -0.03136258, -0.03048189, -0.02879156,\n",
      "       -0.02825844, -0.02871751, -0.02790444, -0.03113556, -0.02977837,\n",
      "       -0.02818053, -0.02899029, -0.02971805, -0.02732045, -0.02607514,\n",
      "       -0.02745731, -0.02601496, -0.03131376, -0.02830808, -0.02742649,\n",
      "       -0.02850643, -0.02990192, -0.02752482, -0.02624928, -0.02524815,\n",
      "       -0.02580413, -0.04209486, -0.03943531, -0.03547047, -0.03600015,\n",
      "       -0.0349034 , -0.03215795, -0.03102523, -0.03080565, -0.0304425 ,\n",
      "       -0.03749387, -0.03557535, -0.03223191, -0.03635828, -0.03262226,\n",
      "       -0.02988254, -0.02828633, -0.03047108, -0.02855248, -0.04015816,\n",
      "       -0.03521419, -0.03029728, -0.03357754, -0.03180854, -0.0295979 ,\n",
      "       -0.02924106, -0.02977874, -0.02785456, -0.04268009, -0.03986977,\n",
      "       -0.03719291, -0.03797274, -0.03689576, -0.03367556, -0.03157813,\n",
      "       -0.03158713, -0.03084288, -0.04052239, -0.0369451 , -0.03540206,\n",
      "       -0.03463552, -0.03594706, -0.03306832, -0.03030903, -0.03049194,\n",
      "       -0.02926474, -0.04254795, -0.03981312, -0.03461211, -0.03720688,\n",
      "       -0.03363008, -0.03229729, -0.03043965, -0.02993693, -0.02754157]), 'std_test_score': array([0.00539233, 0.00445233, 0.00353785, 0.00428211, 0.00399592,\n",
      "       0.00425683, 0.00329012, 0.00355738, 0.00346443, 0.00434772,\n",
      "       0.0075194 , 0.00219194, 0.00214664, 0.00237167, 0.00295903,\n",
      "       0.002833  , 0.00223705, 0.00259603, 0.00432001, 0.00579088,\n",
      "       0.00304747, 0.00271742, 0.00435722, 0.00299643, 0.00187088,\n",
      "       0.00350852, 0.00255374, 0.00210825, 0.00204512, 0.00206954,\n",
      "       0.00279457, 0.00282295, 0.00284685, 0.00244716, 0.00252455,\n",
      "       0.00254639, 0.00404935, 0.00302348, 0.00190447, 0.00338305,\n",
      "       0.00290222, 0.00221281, 0.00271428, 0.0026426 , 0.00264133,\n",
      "       0.00227788, 0.00200701, 0.0034746 , 0.00289582, 0.00243208,\n",
      "       0.00288661, 0.00267634, 0.00254519, 0.00298662, 0.00348569,\n",
      "       0.00338089, 0.00356631, 0.00378703, 0.00338601, 0.00407824,\n",
      "       0.003132  , 0.00324904, 0.00330518, 0.00381193, 0.00499317,\n",
      "       0.00160353, 0.00238422, 0.00140093, 0.00202803, 0.00178737,\n",
      "       0.00321385, 0.00338083, 0.00268596, 0.00360802, 0.00318871,\n",
      "       0.00291949, 0.00348882, 0.002333  , 0.00410364, 0.00278456,\n",
      "       0.00237721, 0.00473586, 0.00458161, 0.00320663, 0.00426554,\n",
      "       0.00412332, 0.00424228, 0.00397849, 0.0034637 , 0.00360685,\n",
      "       0.00315541, 0.00526132, 0.00186508, 0.0037716 , 0.00322312,\n",
      "       0.00526629, 0.00239147, 0.00361432, 0.0024176 , 0.00436098,\n",
      "       0.00361285, 0.00394732, 0.00147769, 0.00372244, 0.00307445,\n",
      "       0.00157462, 0.0023784 , 0.00218053, 0.00410831, 0.00337614,\n",
      "       0.00331254, 0.00454982, 0.00411371, 0.00440459, 0.00384304,\n",
      "       0.00334269, 0.00355822, 0.00348404, 0.00519442, 0.00225488,\n",
      "       0.00321824, 0.00431085, 0.00292484, 0.0030518 , 0.00342595,\n",
      "       0.00356494, 0.00098261, 0.00542159, 0.00343732, 0.00303491,\n",
      "       0.00283412, 0.00259149, 0.00298673, 0.00343972, 0.00271308]), 'rank_test_score': array([135, 128, 117, 122, 119,  95,  81,  83,  74, 133, 129,  98, 105,\n",
      "       110,  94,  79,  62,  51, 134, 121, 112, 107,  96,  93,  70,  58,\n",
      "        56,  27,  25,  23,  22,  21,  19,  18,  12,  16,  15,   1,   9,\n",
      "         3,   5,   8,  14,   7,   2,  26,  17,  24,  13,  11,  20,   6,\n",
      "        10,   4,  97,  88,  61,  77,  68,  47,  41,  46,  39,  75,  54,\n",
      "        40,  48,  53,  33,  31,  35,  30,  76,  43,  34,  44,  59,  36,\n",
      "        32,  28,  29, 130, 123, 104, 109, 101,  84,  73,  71,  66, 118,\n",
      "       106,  85, 111,  87,  57,  42,  67,  45, 126, 102,  63,  90,  82,\n",
      "        52,  49,  55,  38, 132, 125, 115, 120, 113,  92,  78,  80,  72,\n",
      "       127, 114, 103, 100, 108,  89,  64,  69,  50, 131, 124,  99, 116,\n",
      "        91,  86,  65,  60,  37]), 'split0_train_score': array([-0.00070506, -0.00309127, -0.00706858, -0.00498408, -0.00571418,\n",
      "       -0.00885043, -0.00961168, -0.0096406 , -0.01034353, -0.00070506,\n",
      "       -0.00462888, -0.00744434, -0.00613112, -0.00645488, -0.00962479,\n",
      "       -0.01029827, -0.01073895, -0.010922  , -0.00070506, -0.00423259,\n",
      "       -0.00747953, -0.00583236, -0.00650833, -0.00989386, -0.01074964,\n",
      "       -0.01050073, -0.01119676, -0.01824556, -0.01824556, -0.01837002,\n",
      "       -0.01837076, -0.01837076, -0.0186493 , -0.01812182, -0.01812182,\n",
      "       -0.01822228, -0.01850373, -0.01907189, -0.01893504, -0.0189845 ,\n",
      "       -0.01912768, -0.0190748 , -0.01823222, -0.01890924, -0.01874995,\n",
      "       -0.01867697, -0.01857271, -0.0186154 , -0.01912197, -0.01883222,\n",
      "       -0.01934647, -0.01886489, -0.01906789, -0.01911605, -0.01100871,\n",
      "       -0.01211022, -0.01347771, -0.01154068, -0.01186861, -0.01379522,\n",
      "       -0.01289102, -0.01286009, -0.01336893, -0.01118592, -0.01097394,\n",
      "       -0.01332049, -0.01222875, -0.01346632, -0.01420457, -0.01460947,\n",
      "       -0.0140978 , -0.01404   , -0.01075379, -0.01099148, -0.01410651,\n",
      "       -0.01337476, -0.01177957, -0.01476371, -0.01358687, -0.01469811,\n",
      "       -0.01398145, -0.00457569, -0.0062743 , -0.00951148, -0.00705883,\n",
      "       -0.00758779, -0.01026631, -0.01038298, -0.01041189, -0.01107653,\n",
      "       -0.0047042 , -0.00841902, -0.0091617 , -0.0072375 , -0.00874988,\n",
      "       -0.01066303, -0.01168176, -0.01147428, -0.01180766, -0.00331364,\n",
      "       -0.00742287, -0.01104791, -0.00803806, -0.00740894, -0.01014061,\n",
      "       -0.01173732, -0.0113931 , -0.01131783, -0.00156707, -0.00376974,\n",
      "       -0.00756245, -0.00516083, -0.00601518, -0.00907491, -0.00978081,\n",
      "       -0.00975189, -0.01046331, -0.00115573, -0.0050116 , -0.00867175,\n",
      "       -0.0062196 , -0.00610227, -0.00972279, -0.01119512, -0.01090656,\n",
      "       -0.0112038 , -0.00145837, -0.00541907, -0.00767862, -0.00606916,\n",
      "       -0.00666112, -0.00917189, -0.01096746, -0.01054847, -0.0116353 ]), 'split1_train_score': array([-0.00080741, -0.00352735, -0.00598438, -0.00499883, -0.00567523,\n",
      "       -0.00817671, -0.00940241, -0.00940194, -0.00997467, -0.00080741,\n",
      "       -0.00432308, -0.0073263 , -0.00587462, -0.00643437, -0.00908033,\n",
      "       -0.0107117 , -0.01091451, -0.01123045, -0.00080741, -0.00399376,\n",
      "       -0.00722606, -0.00592741, -0.00632665, -0.00962178, -0.01105655,\n",
      "       -0.01038651, -0.01113172, -0.01742345, -0.01766641, -0.01786368,\n",
      "       -0.01758004, -0.01758004, -0.01777731, -0.0175319 , -0.0175319 ,\n",
      "       -0.01766767, -0.01892992, -0.01847151, -0.01998104, -0.01850248,\n",
      "       -0.01881202, -0.01871849, -0.01886499, -0.01891036, -0.01837933,\n",
      "       -0.01737773, -0.0184888 , -0.0180104 , -0.01789548, -0.018443  ,\n",
      "       -0.01799781, -0.01812212, -0.0186217 , -0.019159  , -0.01066631,\n",
      "       -0.01155855, -0.01232454, -0.01093826, -0.01127139, -0.01230929,\n",
      "       -0.01256353, -0.01256353, -0.01279308, -0.01113813, -0.01219153,\n",
      "       -0.01214099, -0.01103749, -0.01210601, -0.01357984, -0.01399622,\n",
      "       -0.01411801, -0.01409459, -0.01054728, -0.01304029, -0.0132121 ,\n",
      "       -0.01068257, -0.01157062, -0.01376097, -0.01395207, -0.01335413,\n",
      "       -0.01592916, -0.0046801 , -0.00649031, -0.00832324, -0.00702841,\n",
      "       -0.00759908, -0.00949115, -0.01017495, -0.01017518, -0.01063161,\n",
      "       -0.00411117, -0.00576965, -0.00891206, -0.00688219, -0.00821341,\n",
      "       -0.01108789, -0.01130277, -0.01146769, -0.01170592, -0.00361871,\n",
      "       -0.00557722, -0.00986755, -0.00740193, -0.00852074, -0.0101651 ,\n",
      "       -0.01131307, -0.01158225, -0.01145426, -0.00179985, -0.00429236,\n",
      "       -0.0065953 , -0.0054806 , -0.00612175, -0.00849615, -0.00952489,\n",
      "       -0.0095256 , -0.01008836, -0.00172889, -0.0042402 , -0.0076225 ,\n",
      "       -0.00613996, -0.00684857, -0.00950029, -0.01019623, -0.01089332,\n",
      "       -0.01126752, -0.00287283, -0.00493692, -0.00699084, -0.00647632,\n",
      "       -0.00708963, -0.00976024, -0.01102538, -0.01115079, -0.01088191]), 'split2_train_score': array([-0.00063644, -0.00345368, -0.00583676, -0.00486669, -0.00569577,\n",
      "       -0.00781235, -0.00928672, -0.00929432, -0.01007233, -0.00063644,\n",
      "       -0.00389892, -0.00751651, -0.00564884, -0.0065271 , -0.0089218 ,\n",
      "       -0.01089143, -0.01042548, -0.01075427, -0.00063644, -0.00407732,\n",
      "       -0.0072882 , -0.00613579, -0.00674921, -0.00928453, -0.01034558,\n",
      "       -0.01027378, -0.01074448, -0.01703227, -0.01720638, -0.01722023,\n",
      "       -0.01719206, -0.01719206, -0.01720591, -0.01747629, -0.01747629,\n",
      "       -0.01751706, -0.01789622, -0.01822471, -0.01784512, -0.01816777,\n",
      "       -0.01861352, -0.01818462, -0.01811476, -0.0185538 , -0.01829248,\n",
      "       -0.01837117, -0.01801366, -0.01818593, -0.01834858, -0.01855088,\n",
      "       -0.01844553, -0.01911758, -0.01800252, -0.01881932, -0.00880794,\n",
      "       -0.0103424 , -0.01101767, -0.01060976, -0.01099284, -0.01186849,\n",
      "       -0.01260421, -0.01259661, -0.01296401, -0.00898854, -0.01212954,\n",
      "       -0.01153993, -0.01106752, -0.01158784, -0.01227784, -0.01297727,\n",
      "       -0.01302666, -0.01399918, -0.00962276, -0.01150257, -0.01394742,\n",
      "       -0.01051259, -0.01229574, -0.01267882, -0.0138213 , -0.01336582,\n",
      "       -0.01449868, -0.00447454, -0.00648057, -0.00826305, -0.00736594,\n",
      "       -0.00796454, -0.00949531, -0.01051038, -0.01051038, -0.01106533,\n",
      "       -0.00387833, -0.00605766, -0.00934084, -0.00767151, -0.00842782,\n",
      "       -0.01019967, -0.01085004, -0.01072949, -0.01146527, -0.00563692,\n",
      "       -0.00553899, -0.00807855, -0.00736758, -0.00788846, -0.01015282,\n",
      "       -0.01087029, -0.01130967, -0.01144636, -0.00200736, -0.004612  ,\n",
      "       -0.0066555 , -0.00564594, -0.00642967, -0.00831883, -0.00956307,\n",
      "       -0.00957067, -0.01033802, -0.00129898, -0.00411693, -0.0071927 ,\n",
      "       -0.00533143, -0.0065372 , -0.00866642, -0.0106215 , -0.01061373,\n",
      "       -0.01079046, -0.00091878, -0.00438787, -0.00837853, -0.00586109,\n",
      "       -0.00632385, -0.00961243, -0.01101728, -0.01039942, -0.0110937 ]), 'split3_train_score': array([-0.00062963, -0.00322627, -0.00591265, -0.00427988, -0.004602  ,\n",
      "       -0.00727478, -0.00911277, -0.00911277, -0.00968698, -0.00062963,\n",
      "       -0.00382408, -0.00568377, -0.00560618, -0.005799  , -0.00863404,\n",
      "       -0.01017375, -0.00996066, -0.01082124, -0.00062963, -0.00419687,\n",
      "       -0.00654631, -0.00544152, -0.00609632, -0.00860109, -0.01012044,\n",
      "       -0.00954038, -0.01023641, -0.0158301 , -0.01610027, -0.01610027,\n",
      "       -0.0161913 , -0.0161913 , -0.01627073, -0.0167158 , -0.0167158 ,\n",
      "       -0.0167158 , -0.01735882, -0.01737518, -0.01732656, -0.01699795,\n",
      "       -0.01656814, -0.01719002, -0.01713487, -0.0172889 , -0.01767497,\n",
      "       -0.01665845, -0.0171841 , -0.01769137, -0.01676761, -0.01709488,\n",
      "       -0.01718988, -0.01791928, -0.01793304, -0.01746455, -0.00893951,\n",
      "       -0.01007238, -0.01115062, -0.00988299, -0.00998978, -0.01126836,\n",
      "       -0.01154747, -0.01154747, -0.01194546, -0.00907091, -0.01015938,\n",
      "       -0.01152897, -0.0106278 , -0.01125492, -0.0123731 , -0.012521  ,\n",
      "       -0.01274479, -0.01244599, -0.0081802 , -0.01102445, -0.01256233,\n",
      "       -0.00928655, -0.00992308, -0.01176484, -0.01348828, -0.01273976,\n",
      "       -0.01261929, -0.0031778 , -0.00529807, -0.007491  , -0.00551687,\n",
      "       -0.0057714 , -0.00810084, -0.00957411, -0.00957411, -0.01008216,\n",
      "       -0.00248515, -0.00595811, -0.00829217, -0.0060137 , -0.00697722,\n",
      "       -0.00999132, -0.01102241, -0.01046066, -0.0105861 , -0.00326005,\n",
      "       -0.0056362 , -0.00866325, -0.00642408, -0.00862651, -0.009547  ,\n",
      "       -0.01087935, -0.01078354, -0.01151615, -0.001023  , -0.00351178,\n",
      "       -0.00611176, -0.00444765, -0.00478261, -0.0074019 , -0.00919989,\n",
      "       -0.00919989, -0.00975972, -0.00123129, -0.00463008, -0.00636381,\n",
      "       -0.00584982, -0.00595301, -0.00871307, -0.00988224, -0.01020272,\n",
      "       -0.00991544, -0.0013984 , -0.00375219, -0.00725788, -0.00523033,\n",
      "       -0.00626523, -0.00823104, -0.01019848, -0.01045729, -0.01062009]), 'split4_train_score': array([-0.00070919, -0.00329356, -0.00562829, -0.00440884, -0.00525227,\n",
      "       -0.00760645, -0.0085866 , -0.0085866 , -0.00926473, -0.00070919,\n",
      "       -0.00355915, -0.00669266, -0.00592496, -0.00638792, -0.00917989,\n",
      "       -0.01000237, -0.00978674, -0.01013467, -0.00070919, -0.00435748,\n",
      "       -0.00698625, -0.0055935 , -0.00601744, -0.00876134, -0.00974742,\n",
      "       -0.01030472, -0.01042197, -0.01576951, -0.01620951, -0.01620951,\n",
      "       -0.01636753, -0.01636753, -0.01636753, -0.01624081, -0.01624081,\n",
      "       -0.01624081, -0.01710733, -0.01872274, -0.01704449, -0.01772925,\n",
      "       -0.01779916, -0.01725255, -0.01789398, -0.01730161, -0.01780698,\n",
      "       -0.01716532, -0.01710242, -0.01720212, -0.01738837, -0.01724417,\n",
      "       -0.01701249, -0.01796304, -0.01762505, -0.01791594, -0.00868416,\n",
      "       -0.00998223, -0.01039361, -0.01040029, -0.01063504, -0.01133303,\n",
      "       -0.01156158, -0.01156158, -0.01187284, -0.01004397, -0.01199162,\n",
      "       -0.01342883, -0.01172123, -0.01219263, -0.01348189, -0.01251774,\n",
      "       -0.01240241, -0.01326029, -0.01008428, -0.01212132, -0.01312149,\n",
      "       -0.01297865, -0.01144801, -0.01237351, -0.01275277, -0.01308854,\n",
      "       -0.01248905, -0.00351482, -0.00557811, -0.00739986, -0.00613881,\n",
      "       -0.00687548, -0.00873191, -0.00954121, -0.00954121, -0.01008285,\n",
      "       -0.00316686, -0.00546382, -0.00869254, -0.00785525, -0.00790035,\n",
      "       -0.0092192 , -0.01067056, -0.00958921, -0.01090417, -0.00347168,\n",
      "       -0.00688655, -0.00918831, -0.00729335, -0.00743272, -0.00976937,\n",
      "       -0.0107465 , -0.01110298, -0.011344  , -0.00173111, -0.00412734,\n",
      "       -0.00633931, -0.00506369, -0.00554963, -0.00789797, -0.00884681,\n",
      "       -0.00884681, -0.00951598, -0.00167554, -0.00448844, -0.00781977,\n",
      "       -0.00576853, -0.00707961, -0.00913681, -0.00992537, -0.00999654,\n",
      "       -0.01132941, -0.00136494, -0.00474552, -0.00737202, -0.00554593,\n",
      "       -0.00695245, -0.00938422, -0.01001818, -0.00992048, -0.01070325]), 'mean_train_score': array([-0.00069755, -0.00331843, -0.00608613, -0.00470766, -0.00538789,\n",
      "       -0.00794414, -0.00920004, -0.00920725, -0.00986845, -0.00069755,\n",
      "       -0.00404682, -0.00693272, -0.00583714, -0.00632065, -0.00908817,\n",
      "       -0.0104155 , -0.01036527, -0.01077253, -0.00069755, -0.00417161,\n",
      "       -0.00710527, -0.00578611, -0.00633959, -0.00923252, -0.01040393,\n",
      "       -0.01020122, -0.01074627, -0.01686018, -0.01708563, -0.01715274,\n",
      "       -0.01714034, -0.01714034, -0.01725415, -0.01721733, -0.01721733,\n",
      "       -0.01727273, -0.01795921, -0.01837321, -0.01822645, -0.01807639,\n",
      "       -0.01818411, -0.0180841 , -0.01804817, -0.01819278, -0.01818074,\n",
      "       -0.01764993, -0.01787234, -0.01794104, -0.0179044 , -0.01803303,\n",
      "       -0.01799843, -0.01839738, -0.01825004, -0.01849497, -0.00962133,\n",
      "       -0.01081315, -0.01167283, -0.0106744 , -0.01095153, -0.01211488,\n",
      "       -0.01223356, -0.01222586, -0.01258886, -0.01008549, -0.0114892 ,\n",
      "       -0.01239184, -0.01133656, -0.01212155, -0.01318345, -0.01332434,\n",
      "       -0.01327793, -0.01356801, -0.00983766, -0.01173602, -0.01338997,\n",
      "       -0.01136702, -0.0114034 , -0.01306837, -0.01352026, -0.01344927,\n",
      "       -0.01390352, -0.00408459, -0.00602427, -0.00819773, -0.00662177,\n",
      "       -0.00715966, -0.0092171 , -0.01003672, -0.01004255, -0.0105877 ,\n",
      "       -0.00366915, -0.00633365, -0.00887986, -0.00713203, -0.00805374,\n",
      "       -0.01023222, -0.01110551, -0.01074427, -0.01129382, -0.0038602 ,\n",
      "       -0.00621237, -0.00936911, -0.007305  , -0.00797547, -0.00995498,\n",
      "       -0.01110931, -0.01123431, -0.01141572, -0.00162568, -0.00406264,\n",
      "       -0.00665287, -0.00515974, -0.00577977, -0.00823795, -0.00938309,\n",
      "       -0.00937897, -0.01003308, -0.00141809, -0.00449745, -0.00753411,\n",
      "       -0.00586187, -0.00650413, -0.00914788, -0.01036409, -0.01052257,\n",
      "       -0.01090132, -0.00160266, -0.00464832, -0.00753558, -0.00583657,\n",
      "       -0.00665846, -0.00923196, -0.01064536, -0.01049529, -0.01098685]), 'std_train_score': array([6.42012380e-05, 1.56625324e-04, 5.05464213e-04, 3.02909088e-04,\n",
      "       4.28913563e-04, 5.39425936e-04, 3.46940713e-04, 3.54232686e-04,\n",
      "       3.67683815e-04, 6.42012380e-05, 3.80638256e-04, 6.89200063e-04,\n",
      "       1.92011280e-04, 2.64654363e-04, 3.25685495e-04, 3.33796124e-04,\n",
      "       4.34358567e-04, 3.58219050e-04, 6.42012380e-05, 1.26037274e-04,\n",
      "       3.20849629e-04, 2.45039444e-04, 2.68100923e-04, 4.92405480e-04,\n",
      "       4.60479284e-04, 3.39626073e-04, 3.78588092e-04, 9.50452787e-04,\n",
      "       8.28956481e-04, 8.93212091e-04, 8.00981028e-04, 8.00979865e-04,\n",
      "       8.91704832e-04, 6.61701610e-04, 6.61701610e-04, 7.06024562e-04,\n",
      "       6.82483465e-04, 5.72382136e-04, 1.08930546e-03, 6.77954532e-04,\n",
      "       9.19623545e-04, 7.59590703e-04, 5.59177905e-04, 7.44278346e-04,\n",
      "       3.92791548e-04, 7.57229048e-04, 6.25614388e-04, 4.74947523e-04,\n",
      "       8.04790583e-04, 7.17967334e-04, 8.53572649e-04, 4.96033645e-04,\n",
      "       5.21415427e-04, 6.82486807e-04, 1.00215526e-03, 8.60090302e-04,\n",
      "       1.09732981e-03, 5.52397031e-04, 6.27725367e-04, 9.21945706e-04,\n",
      "       5.65825082e-04, 5.57710014e-04, 5.86104758e-04, 9.54293234e-04,\n",
      "       7.98703104e-04, 8.33180209e-04, 5.67122244e-04, 7.54929634e-04,\n",
      "       7.43729150e-04, 8.38975571e-04, 7.05951716e-04, 6.38684789e-04,\n",
      "       9.16190384e-04, 7.70032689e-04, 5.67960466e-04, 1.55918087e-03,\n",
      "       7.94866247e-04, 1.06654765e-03, 4.17512726e-04, 6.64703145e-04,\n",
      "       1.27385012e-03, 6.15592532e-04, 4.92816600e-04, 7.59211935e-04,\n",
      "       6.87635069e-04, 7.78748818e-04, 7.39563509e-04, 4.05685537e-04,\n",
      "       4.10769277e-04, 4.42594795e-04, 7.70014741e-04, 1.06213506e-03,\n",
      "       3.66999025e-04, 6.53955940e-04, 6.05388227e-04, 6.32939524e-04,\n",
      "       3.55617616e-04, 7.03004480e-04, 4.72428417e-04, 8.97207832e-04,\n",
      "       7.88501861e-04, 1.02599086e-03, 5.15138187e-04, 5.18513389e-04,\n",
      "       2.52447658e-04, 3.68119366e-04, 2.72909733e-04, 7.38073057e-05,\n",
      "       3.32800301e-04, 3.86781018e-04, 4.94322097e-04, 4.13674418e-04,\n",
      "       5.73067703e-04, 5.63610680e-04, 3.26140514e-04, 3.20184030e-04,\n",
      "       3.53060616e-04, 2.36977669e-04, 3.14004666e-04, 7.57599239e-04,\n",
      "       3.14809079e-04, 4.28051572e-04, 4.18496449e-04, 4.91873739e-04,\n",
      "       3.66665567e-04, 5.27843493e-04, 6.63337792e-04, 5.58155640e-04,\n",
      "       4.75739140e-04, 4.28013701e-04, 3.28310382e-04, 5.38973232e-04,\n",
      "       4.42618314e-04, 3.93333421e-04, 3.62729351e-04])}\n"
     ]
    }
   ],
   "source": [
    "# Access the full results\n",
    "cv_results = grid_CV.cv_results_\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "# Right now (temporary) we will this hyperparameters as the best one:\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_score</th>\n",
       "      <th>sign_fscore</th>\n",
       "      <th>sign_fscore_0_1</th>\n",
       "      <th>corr</th>\n",
       "      <th>EN_coef</th>\n",
       "      <th>boruta_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>etr_y_past</th>\n",
       "      <td>1.009402</td>\n",
       "      <td>1.304040e-84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etr_y_ma</th>\n",
       "      <td>0.825650</td>\n",
       "      <td>2.473770e-125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt</th>\n",
       "      <td>0.633067</td>\n",
       "      <td>5.246456e-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.368732</td>\n",
       "      <td>1.466269e-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>0.632640</td>\n",
       "      <td>2.257712e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.291716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>0.613297</td>\n",
       "      <td>1.747230e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.263458</td>\n",
       "      <td>-3.442000e-07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mi_score    sign_fscore  sign_fscore_0_1      corr       EN_coef  \\\n",
       "etr_y_past  1.009402   1.304040e-84                1  0.520405           NaN   \n",
       "etr_y_ma    0.825650  2.473770e-125                1  0.526871           NaN   \n",
       "txt         0.633067   5.246456e-13                1  0.368732  1.466269e-05   \n",
       "diff        0.632640   2.257712e-02                1 -0.291716           NaN   \n",
       "ni          0.613297   1.747230e-09                1  0.263458 -3.442000e-07   \n",
       "\n",
       "            boruta_rank  \n",
       "etr_y_past            1  \n",
       "etr_y_ma              1  \n",
       "txt                   1  \n",
       "diff                  1  \n",
       "ni                    7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature ranking\n",
    "fr.sort_values(\"mi_score\", ascending=False, inplace=True)\n",
    "fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_features = fr[fr.boruta_rank.isin([1, 2, 3])].index.tolist()\n",
    "mi_features = fr.iloc[0:20].index.tolist()\n",
    "mi_features_25 = fr.iloc[0:25].index.tolist()\n",
    "mi_features_35 = fr.iloc[0:35].index.tolist()\n",
    "mi_features_50 = fr.iloc[0:50].index.tolist()\n",
    "fr[\"corr_abs\"] = np.abs(fr[\"corr\"])\n",
    "fr.sort_values(\"corr_abs\", ascending=False, inplace=True)\n",
    "corr_features = fr.iloc[0:20].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use our intuition and create two additional benchmark sets of variables:\n",
    "benchmark = [\n",
    "    \"rok\",\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"capex2_scaled\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"y_e_p_polity\",\n",
    "    \"y_BR_Democracy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"sektor_consumer discretionary\",\n",
    "    \"sektor_consumer staples\",\n",
    "    \"sektor_energy\",\n",
    "    \"sektor_health care\",\n",
    "    \"sektor_industrials\",\n",
    "    \"sektor_materials\",\n",
    "    \"sektor_real estate\",\n",
    "    \"sektor_technology\",\n",
    "    \"sektor_utilities\",\n",
    "    \"gielda_2\",\n",
    "    \"gielda_3\",\n",
    "    \"gielda_4\",\n",
    "    \"gielda_5\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"max_depth\": [None, 5, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = [\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward elimination\n",
    "forward_elimination = [\n",
    "    \"rok\",\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"capex2_scaled\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"y_e_p_polity\",\n",
    "    \"y_BR_Democracy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"sektor_consumer discretionary\",\n",
    "    \"sektor_consumer staples\",\n",
    "    \"sektor_energy\",\n",
    "    \"sektor_health care\",\n",
    "    \"sektor_industrials\",\n",
    "    \"sektor_materials\",\n",
    "    \"sektor_real estate\",\n",
    "    \"sektor_technology\",\n",
    "    \"sektor_utilities\",\n",
    "    \"gielda_2\",\n",
    "    \"gielda_3\",\n",
    "    \"gielda_4\",\n",
    "    \"gielda_5\",\n",
    "    \"ta_log\",\n",
    "    \"txt_cat_(-63.011, -34.811]\",\n",
    "    \"txt_cat_(-34.811, 0.488]\",\n",
    "    \"txt_cat_(0.488, 24.415]\",\n",
    "    \"txt_cat_(24.415, 25.05]\",\n",
    "    \"txt_cat_(25.05, 308.55]\",\n",
    "    \"txt_cat_(308.55, 327.531]\",\n",
    "    \"txt_cat_(327.531, inf]\",\n",
    "    \"pi_cat_(-8975.0, -1.523]\",\n",
    "    \"pi_cat_(-1.523, 157.119]\",\n",
    "    \"pi_cat_(157.119, 465.9]\",\n",
    "    \"pi_cat_(465.9, 7875.5]\",\n",
    "    \"pi_cat_(7875.5, 8108.5]\",\n",
    "    \"pi_cat_(8108.5, inf]\",\n",
    "    \"str_cat_(0.0875, 0.192]\",\n",
    "    \"str_cat_(0.192, 0.28]\",\n",
    "    \"str_cat_(0.28, inf]\",\n",
    "    \"xrd_exists\",\n",
    "    \"ni_profit\",\n",
    "    \"ni_profit_20000\",\n",
    "    \"ppent_sqrt\",\n",
    "    \"intant_sqrt\",\n",
    "    \"dlc_cat_(42.262, 176.129]\",\n",
    "    \"dlc_cat_(176.129, 200.9]\",\n",
    "    \"dlc_cat_(200.9, inf]\",\n",
    "    \"dltt_cat_(39.38, 327.85]\",\n",
    "    \"dltt_cat_(327.85, 876.617]\",\n",
    "    \"dltt_cat_(876.617, inf]\",\n",
    "    \"capex_cat_(7.447, 79.55]\",\n",
    "    \"capex_cat_(79.55, 5451.0]\",\n",
    "    \"capex_cat_(5451.0, inf]\",\n",
    "    \"revenue_cat_(0.174, 1248.817]\",\n",
    "    \"revenue_cat_(1248.817, 4233.587]\",\n",
    "    \"revenue_cat_(4233.587, inf]\",\n",
    "    \"cce_cat_(5.619, 63.321]\",\n",
    "    \"cce_cat_(63.321, inf]\",\n",
    "    \"adv_cat_(0.3, 874.5]\",\n",
    "    \"adv_cat_(874.5, inf]\",\n",
    "    \"diff_positive\",\n",
    "    \"roa_clip\",\n",
    "    \"lev_sqrt\",\n",
    "    \"intan_pow2\",\n",
    "    \"rd_sqrt\",\n",
    "    \"ppe_clip\",\n",
    "    \"cash_holdings_sqrt\",\n",
    "    \"adv_expenditure_positive\",\n",
    "    \"diff_dta\",\n",
    "    \"cfc_dta\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]\n",
    "forward_elimination.remove(\"ta_log\")\n",
    "forward_elimination.remove(\"ppent_sqrt\")\n",
    "forward_elimination.remove(\"intant_sqrt\")\n",
    "forward_elimination.remove(\"roa\")\n",
    "forward_elimination.remove(\"lev\")\n",
    "forward_elimination.remove(\"intan\")\n",
    "forward_elimination.remove(\"rd_sqrt\")\n",
    "forward_elimination.remove(\"ppe\")\n",
    "forward_elimination.remove(\"cash_holdings_sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_withoud_discr = [i for i in forward_elimination if \"]\" not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(**grid_CV.best_params_)\n",
    "\n",
    "sf = SFS(\n",
    "    model,\n",
    "    n_features_to_select=(15),\n",
    "    direction='forward',\n",
    "    scoring=mse,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['intant', 'adv', 'y_e_p_polity', 'WB_GDPgrowth', 'WB_GDPpc',\n",
      "       'WB_Inflation', 'rr_per_country', 'sektor_consumer staples',\n",
      "       'sektor_industrials', 'sektor_real estate', 'sektor_technology',\n",
      "       'ni_profit_20000', 'etr_y_past', 'etr_y_ma', 'sale_past'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sffit = sf.fit(\n",
    "    df.loc[:, candidates_withoud_discr].values, df.loc[:, \"etr\"].values.ravel()\n",
    ")\n",
    "\n",
    "sf_features = df.loc[:, candidates_withoud_discr].columns[sffit.support_]\n",
    "\n",
    "print(sf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(**grid_CV.best_params_)\n",
    "\n",
    "sf = SFS(\n",
    "    model,\n",
    "    n_features_to_select=(10),\n",
    "    direction='forward',\n",
    "    scoring=mse,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rok', 'y_e_p_polity', 'WB_GDPpc', 'sektor_consumer discretionary',\n",
       "       'txt_cat_(0.488, 24.415]', 'pi_cat_(7875.5, 8108.5]',\n",
       "       'str_cat_(0.0875, 0.192]', 'capex_cat_(5451.0, inf]', 'diff_dta',\n",
       "       'etr_y_past'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sffit = sf.fit(\n",
    "    df.loc[:, forward_elimination].values, df.loc[:, \"etr\"].values.ravel()\n",
    ")\n",
    "\n",
    "sf_features2 = df.loc[:, forward_elimination].columns[sffit.support_]\n",
    "\n",
    "sf_features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_one_more = [\n",
    "    'rok', \n",
    "    'cfc', \n",
    "    'txt_cat_(0.488, 24.415]', \n",
    "    'pi_cat_(465.9, 7875.5]',\n",
    "    'pi_cat_(8108.5, inf]', \n",
    "    'str_cat_(0.192, 0.28]',\n",
    "    'dltt_cat_(876.617, inf]', \n",
    "    'adv_cat_(0.3, 874.5]', \n",
    "    'etr_y_ma',\n",
    "    'ppe_past'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(**grid_CV.best_params_)\n",
    "\n",
    "sf = SFS(\n",
    "    model,\n",
    "    n_features_to_select=(5),\n",
    "    direction='forward',\n",
    "    scoring=mse,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rok', 'pi_cat_(8108.5, inf]', 'str_cat_(0.192, 0.28]',\n",
       "       'adv_cat_(0.3, 874.5]', 'etr_y_ma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sffit = sf.fit(df.loc[:, sf_one_more].values, df.loc[:, \"etr\"].values.ravel())\n",
    "\n",
    "sf_features3 = df.loc[:, sf_one_more].columns[sffit.support_]\n",
    "\n",
    "sf_features3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters Tunning for each group of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"max_depth\": [None, 5, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_proc(var):\n",
    "    model = DecisionTreeRegressor()\n",
    "    grid_CV = GridSearchCV(\n",
    "        model, param, cv=5, scoring=mse, return_train_score=True, n_jobs=-1\n",
    "    )\n",
    "    grid_CV.fit(df.loc[:, var].values, df.loc[:, \"etr\"].values.ravel())\n",
    "    print(grid_CV.best_params_)\n",
    "    print(grid_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "-0.02156730749916607\n"
     ]
    }
   ],
   "source": [
    "cv_proc(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "-0.022059378918544977\n"
     ]
    }
   ],
   "source": [
    "cv_proc(benchmark2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "-0.021914459209412727\n"
     ]
    }
   ],
   "source": [
    "cv_proc(mi_features_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "-0.02210318493800648\n"
     ]
    }
   ],
   "source": [
    "cv_proc(mi_features_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "-0.022137314205407092\n"
     ]
    }
   ],
   "source": [
    "cv_proc(mi_features_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "-0.020990002202181522\n"
     ]
    }
   ],
   "source": [
    "cv_proc(br_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "-0.02146164370160841\n"
     ]
    }
   ],
   "source": [
    "cv_proc(mi_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "-0.02140368711964956\n"
     ]
    }
   ],
   "source": [
    "cv_proc(corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "-0.02075306122641788\n"
     ]
    }
   ],
   "source": [
    "cv_proc(sf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "-0.020079508184476312\n"
     ]
    }
   ],
   "source": [
    "cv_proc(sf_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "-0.02028598370494811\n"
     ]
    }
   ],
   "source": [
    "cv_proc(sf_features3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"rok\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper_CV(x, y, model, display_res=False):\n",
    "    train_score = list()\n",
    "    valid_score = list()\n",
    "    train_indexes = [0, 1452]\n",
    "    valid_indexes = [1452, 1815]\n",
    "    for i in range(0, 6):\n",
    "        train_x = x[x.index.isin(range(train_indexes[0], train_indexes[1]))]\n",
    "        train_y = y[y.index.isin(range(train_indexes[0], train_indexes[1]))]\n",
    "        valid_x = x[x.index.isin(range(valid_indexes[0], valid_indexes[1]))]\n",
    "        valid_y = y[y.index.isin(range(valid_indexes[0], valid_indexes[1]))]\n",
    "\n",
    "        model.fit(train_x.values, train_y.values.ravel())\n",
    "\n",
    "        pred_y_train = model.predict(train_x.values)\n",
    "        rmse = np.sqrt(mean_squared_error(train_y, pred_y_train))\n",
    "        train_score.append(rmse)\n",
    "\n",
    "        pred_y_val = model.predict(valid_x.values)\n",
    "        rmse = np.sqrt(mean_squared_error(valid_y, pred_y_val))\n",
    "        valid_score.append(rmse)\n",
    "\n",
    "        train_indexes = [0, valid_indexes[1]]\n",
    "        valid_indexes = [train_indexes[1], valid_indexes[1] + 363]\n",
    "\n",
    "    if display_res == True:\n",
    "        view = pd.DataFrame([train_score, valid_score]).T.rename(\n",
    "            columns={0: \"cv_train\", 1: \"cv_val\"}\n",
    "        )\n",
    "        display(view)\n",
    "        return train_score, valid_score, view\n",
    "    else:\n",
    "        return train_score, valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = [\n",
    "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5},\n",
    "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5},\n",
    "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10},\n",
    "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2},\n",
    "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2},\n",
    "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10},\n",
    "{'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10},\n",
    "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10},\n",
    "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10},\n",
    "{'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10},\n",
    "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.150388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.128872</td>\n",
       "      <td>0.146382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133823</td>\n",
       "      <td>0.154904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130055</td>\n",
       "      <td>0.152610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.134062</td>\n",
       "      <td>0.139657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.137623</td>\n",
       "      <td>0.147233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.131908  0.150388\n",
       "1  0.128872  0.146382\n",
       "2  0.133823  0.154904\n",
       "3  0.130055  0.152610\n",
       "4  0.134062  0.139657\n",
       "5  0.137623  0.147233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[0])\n",
    "var = benchmark\n",
    "cv_output0 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.129655</td>\n",
       "      <td>0.149905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.131438</td>\n",
       "      <td>0.142111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133549</td>\n",
       "      <td>0.153194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.138385</td>\n",
       "      <td>0.151916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135632</td>\n",
       "      <td>0.130939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.136535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.129655  0.149905\n",
       "1  0.131438  0.142111\n",
       "2  0.133549  0.153194\n",
       "3  0.138385  0.151916\n",
       "4  0.135632  0.130939\n",
       "5  0.136300  0.136535"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[1])\n",
    "\n",
    "var = benchmark2\n",
    "cv_output1 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.126587</td>\n",
       "      <td>0.150841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.126100</td>\n",
       "      <td>0.137786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.123488</td>\n",
       "      <td>0.163627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.129012</td>\n",
       "      <td>0.155394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.131241</td>\n",
       "      <td>0.136144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.131782</td>\n",
       "      <td>0.136893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.126587  0.150841\n",
       "1  0.126100  0.137786\n",
       "2  0.123488  0.163627\n",
       "3  0.129012  0.155394\n",
       "4  0.131241  0.136144\n",
       "5  0.131782  0.136893"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[2])\n",
    "var = br_features\n",
    "cv_output2 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137960</td>\n",
       "      <td>0.155636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.128846</td>\n",
       "      <td>0.143088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131270</td>\n",
       "      <td>0.150514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130765</td>\n",
       "      <td>0.162522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130059</td>\n",
       "      <td>0.143946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.132479</td>\n",
       "      <td>0.146429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.137960  0.155636\n",
       "1  0.128846  0.143088\n",
       "2  0.131270  0.150514\n",
       "3  0.130765  0.162522\n",
       "4  0.130059  0.143946\n",
       "5  0.132479  0.146429"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[3])\n",
    "var = mi_features\n",
    "cv_output3 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139110</td>\n",
       "      <td>0.142560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.137694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.159603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131838</td>\n",
       "      <td>0.143071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133632</td>\n",
       "      <td>0.130649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.133404</td>\n",
       "      <td>0.142581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.139110  0.142560\n",
       "1  0.132317  0.137694\n",
       "2  0.131908  0.159603\n",
       "3  0.131838  0.143071\n",
       "4  0.133632  0.130649\n",
       "5  0.133404  0.142581"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[4])\n",
    "var = corr_features\n",
    "cv_output4 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.141044</td>\n",
       "      <td>0.141810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133139</td>\n",
       "      <td>0.136733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132875</td>\n",
       "      <td>0.154946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.146098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137651</td>\n",
       "      <td>0.149342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.138568</td>\n",
       "      <td>0.134895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.141044  0.141810\n",
       "1  0.133139  0.136733\n",
       "2  0.132875  0.154946\n",
       "3  0.136300  0.146098\n",
       "4  0.137651  0.149342\n",
       "5  0.138568  0.134895"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[5])\n",
    "var = sf_features\n",
    "cv_output5 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127880</td>\n",
       "      <td>0.143306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129065</td>\n",
       "      <td>0.138939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128832</td>\n",
       "      <td>0.157145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.132375</td>\n",
       "      <td>0.147543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.134232</td>\n",
       "      <td>0.127828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.132661</td>\n",
       "      <td>0.143597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.127880  0.143306\n",
       "1  0.129065  0.138939\n",
       "2  0.128832  0.157145\n",
       "3  0.132375  0.147543\n",
       "4  0.134232  0.127828\n",
       "5  0.132661  0.143597"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[6])\n",
    "var = sf_features2\n",
    "cv_output6 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135890</td>\n",
       "      <td>0.160455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129836</td>\n",
       "      <td>0.135739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135765</td>\n",
       "      <td>0.154066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.136319</td>\n",
       "      <td>0.147127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.143364</td>\n",
       "      <td>0.132629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135338</td>\n",
       "      <td>0.134670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.135890  0.160455\n",
       "1  0.129836  0.135739\n",
       "2  0.135765  0.154066\n",
       "3  0.136319  0.147127\n",
       "4  0.143364  0.132629\n",
       "5  0.135338  0.134670"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[7])\n",
    "var = sf_features3\n",
    "cv_output7 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.149998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.132379</td>\n",
       "      <td>0.145440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128965</td>\n",
       "      <td>0.165134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.136269</td>\n",
       "      <td>0.148789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.136247</td>\n",
       "      <td>0.135186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135077</td>\n",
       "      <td>0.142592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.127106  0.149998\n",
       "1  0.132379  0.145440\n",
       "2  0.128965  0.165134\n",
       "3  0.136269  0.148789\n",
       "4  0.136247  0.135186\n",
       "5  0.135077  0.142592"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[8])\n",
    "var = mi_features_25\n",
    "cv_output8 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115583</td>\n",
       "      <td>0.171699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.120059</td>\n",
       "      <td>0.148289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.118023</td>\n",
       "      <td>0.177080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.122318</td>\n",
       "      <td>0.142885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122851</td>\n",
       "      <td>0.130068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.150695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.115583  0.171699\n",
       "1  0.120059  0.148289\n",
       "2  0.118023  0.177080\n",
       "3  0.122318  0.142885\n",
       "4  0.122851  0.130068\n",
       "5  0.125900  0.150695"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[9])\n",
    "var = mi_features_35\n",
    "cv_output9 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_train</th>\n",
       "      <th>cv_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127049</td>\n",
       "      <td>0.156941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.132061</td>\n",
       "      <td>0.147437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.129691</td>\n",
       "      <td>0.156891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131554</td>\n",
       "      <td>0.150111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.134636</td>\n",
       "      <td>0.140419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135664</td>\n",
       "      <td>0.139682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_train    cv_val\n",
       "0  0.127049  0.156941\n",
       "1  0.132061  0.147437\n",
       "2  0.129691  0.156891\n",
       "3  0.131554  0.150111\n",
       "4  0.134636  0.140419\n",
       "5  0.135664  0.139682"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[10])\n",
    "var = mi_features_50\n",
    "cv_output10 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_mean</th>\n",
       "      <th>test_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.132724</td>\n",
       "      <td>0.148529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134160</td>\n",
       "      <td>0.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128035</td>\n",
       "      <td>0.146781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131897</td>\n",
       "      <td>0.150356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133701</td>\n",
       "      <td>0.142693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.136596</td>\n",
       "      <td>0.143971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.130841</td>\n",
       "      <td>0.143059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.136085</td>\n",
       "      <td>0.144114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.132674</td>\n",
       "      <td>0.147856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.120789</td>\n",
       "      <td>0.153453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.131776</td>\n",
       "      <td>0.148580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_mean  test_mean\n",
       "0     0.132724   0.148529\n",
       "1     0.134160   0.144100\n",
       "2     0.128035   0.146781\n",
       "3     0.131897   0.150356\n",
       "4     0.133701   0.142693\n",
       "5     0.136596   0.143971\n",
       "6     0.130841   0.143059\n",
       "7     0.136085   0.144114\n",
       "8     0.132674   0.147856\n",
       "9     0.120789   0.153453\n",
       "10    0.131776   0.148580"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        cv_output0[2].mean().tolist(),\n",
    "        cv_output1[2].mean().tolist(),\n",
    "        cv_output2[2].mean().tolist(),\n",
    "        cv_output3[2].mean().tolist(),\n",
    "        cv_output4[2].mean().tolist(),\n",
    "        cv_output5[2].mean().tolist(),\n",
    "        cv_output6[2].mean().tolist(),\n",
    "        cv_output7[2].mean().tolist(),\n",
    "        cv_output8[2].mean().tolist(),\n",
    "        cv_output9[2].mean().tolist(),\n",
    "        cv_output10[2].mean().tolist(),\n",
    "    ],\n",
    "    columns=[\"train_mean\", \"test_mean\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_std</th>\n",
       "      <th>test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.005399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.009076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.011544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.007553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.009552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.007658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.009673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.011545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.009980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.017799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.007595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_std  test_std\n",
       "0    0.003150  0.005399\n",
       "1    0.003246  0.009076\n",
       "2    0.003218  0.011544\n",
       "3    0.003208  0.007553\n",
       "4    0.002755  0.009552\n",
       "5    0.003183  0.007658\n",
       "6    0.002574  0.009673\n",
       "7    0.004308  0.011545\n",
       "8    0.003907  0.009980\n",
       "9    0.003688  0.017799\n",
       "10   0.003166  0.007595"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        cv_output0[2].std().tolist(),\n",
    "        cv_output1[2].std().tolist(),\n",
    "        cv_output2[2].std().tolist(),\n",
    "        cv_output3[2].std().tolist(),\n",
    "        cv_output4[2].std().tolist(),\n",
    "        cv_output5[2].std().tolist(),\n",
    "        cv_output6[2].std().tolist(),\n",
    "        cv_output7[2].std().tolist(),\n",
    "        cv_output8[2].std().tolist(),\n",
    "        cv_output9[2].std().tolist(),\n",
    "        cv_output10[2].std().tolist(),\n",
    "    ],\n",
    "    columns=[\"train_std\", \"test_std\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['etr_y_ma', 'etr_y_past', 'str', 'txt', 'str_cat_(0.0875, 0.192]', 'str_cat_(0.28, inf]', 'cfc', 'revenue', 'pi', 'intant', 'intant_sqrt', 'diff', 'revenue_cat_(0.174, 1248.817]', 'WB_GDPpc', 'xrd_exists', 'revenue_cat_(4233.587, inf]', 'ta_log', 'ta', 'ni', 'rd']\n"
     ]
    }
   ],
   "source": [
    "# 4th model\n",
    "print(corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the final model and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=5, max_features='log2', min_samples_leaf=4)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(**hp[4])\n",
    "model.fit(df.loc[:, corr_features].values, df.loc[:, \"etr\"].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"C:/Users/adria/Desktop/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates-main/models/dt.sav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_output_data_path = \"C:/Users/adria/Desktop/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates-main/data/output\"\n",
    "\n",
    "df = pd.read_csv(f\"{preprocessed_output_data_path}/train_fe.csv\", index_col=0)\n",
    "\n",
    "fr = pd.read_excel(f\"{preprocessed_output_data_path}/feature_ranking.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can omit that part in the case of Random Forest\n",
    "# (as stated in the exercise description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['etr_y_past', 'etr_y_ma', 'txt', 'diff', 'ni', 'pi', 'intant', 'intant_sqrt', 'ta', 'revenue']\n"
     ]
    }
   ],
   "source": [
    "var = fr.mi_score.sort_values(ascending=False).index.tolist()[0:10]\n",
    "print(var)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.190189111918315"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Random Forest\n",
    "param = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mean squared error scorer\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RandomForestRegressor model\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object for Random Forest\n",
    "grid_CV = GridSearchCV(\n",
    "    model, param, cv=5, scoring=mse, return_train_score=True, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 5, 10, 15, 20],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             return_train_score=True,\n",
       "             scoring=make_scorer(mean_squared_error, greater_is_better=False))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_CV.fit(df.loc[:, var].values, df.loc[:, \"etr\"].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters for Random Forest\n",
    "best_params = grid_CV.best_params_\n",
    "print(\"Best Parameters for Random Forest:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results for Random Forest: {'mean_fit_time': array([ 3.12979026,  6.07924166, 11.84249115,  2.86561427,  5.64592695,\n",
      "       11.1328774 ,  2.6539835 ,  5.26936913, 10.592663  ,  2.56504064,\n",
      "        5.19139237, 10.10911837,  2.56154957,  5.1132154 , 10.05893764,\n",
      "        2.41306472,  4.88098483,  9.77115369,  2.16736598,  4.32817626,\n",
      "        8.8592803 ,  2.1898397 ,  4.84658518,  9.80136371,  2.19579821,\n",
      "        4.34980798,  8.92995219,  1.0446569 ,  2.03929472,  4.18028388,\n",
      "        1.03478951,  1.85902543,  3.73485236,  0.89391856,  1.78487091,\n",
      "        3.96064234,  0.93804498,  2.53969111,  4.31987877,  0.96147327,\n",
      "        1.76400447,  3.48815451,  0.81049652,  1.62631507,  3.32972336,\n",
      "        0.74158645,  1.54494038,  3.67325044,  0.89525027,  1.80698237,\n",
      "        3.03597531,  0.74284658,  1.49051361,  2.99201989,  1.00471053,\n",
      "        2.16411037,  4.50301423,  0.98942866,  1.92906051,  3.73368683,\n",
      "        0.86895599,  1.75601592,  3.48738046,  0.88069196,  1.75453467,\n",
      "        3.50995774,  0.84945774,  1.714498  ,  3.40953217,  0.8280426 ,\n",
      "        1.61046815,  3.27351952,  0.74610853,  1.49056382,  3.01016989,\n",
      "        0.73776393,  1.51552639,  3.01090274,  0.72471614,  1.48783364,\n",
      "        2.96425695,  0.97519059,  1.94371171,  3.91926956,  0.97243142,\n",
      "        1.95453491,  4.01746764,  0.992137  ,  1.99777789,  3.94059381,\n",
      "        0.95956788,  1.93923998,  4.02215667,  0.96820621,  1.97754669,\n",
      "        3.90749316,  0.96858907,  1.98624082,  3.86833577,  0.9513907 ,\n",
      "        2.02341847,  4.06907301,  0.97543497,  2.2382144 ,  3.89707751,\n",
      "        0.96886783,  1.95177417,  3.88509307,  0.39596453,  0.8518517 ,\n",
      "        1.6000083 ,  0.4011477 ,  0.79000592,  1.70399861,  0.40381589,\n",
      "        0.83462758,  1.75716529,  0.44719467,  0.83713908,  1.66178641,\n",
      "        0.39377675,  0.82115932,  1.65608225,  0.39468908,  0.85046997,\n",
      "        1.78990526,  0.40126038,  0.88849421,  1.82165999,  0.41426229,\n",
      "        0.84168057,  1.7256753 ,  0.41503143,  0.87843146,  1.74998951,\n",
      "        0.42696042,  0.85194049,  1.73211117,  0.41217036,  0.83615475,\n",
      "        1.75858998,  0.4072453 ,  1.06827669,  2.31830463,  0.51923623,\n",
      "        0.92408605,  1.85082989,  0.44603186,  0.84753776,  1.76398764,\n",
      "        0.45818048,  0.92566767,  2.07642517,  0.49719248,  0.95873194,\n",
      "        1.89734907,  0.43031201,  0.86822467,  1.87634716,  0.42280765,\n",
      "        0.8642364 ,  1.59636774,  1.71968393,  3.38978963,  6.98397985,\n",
      "        1.82460723,  4.43677263,  7.99602561,  1.88529267,  3.97438602,\n",
      "       10.75618343,  2.43832583,  4.5675868 ,  8.34935985,  2.77213111,\n",
      "        4.41822181,  7.65996704,  1.92029705,  3.60394516,  6.6272521 ,\n",
      "        1.61648698,  3.23569603,  6.94428635,  1.66192999,  3.84749322,\n",
      "        8.8314086 ,  1.96095734,  3.82580605,  7.38580909,  0.639854  ,\n",
      "        1.36712961,  2.76308026,  0.60936852,  1.31108866,  2.60110946,\n",
      "        0.61463518,  1.37922854,  2.92871761,  0.70563254,  1.37960372,\n",
      "        2.99896612,  0.66086602,  1.70162301,  2.79378662,  0.94137311,\n",
      "        1.48645725,  2.96677256,  0.73312135,  1.45102272,  2.80981588,\n",
      "        0.6990942 ,  1.2902523 ,  2.4103961 ,  0.58757734,  1.19678531,\n",
      "        2.43863454,  0.60757704,  1.24153128,  2.51953902,  0.60640821,\n",
      "        1.48863406,  3.13670821,  0.71735582,  1.475003  ,  2.76493192,\n",
      "        0.67360687,  1.50495567,  2.81021924,  0.6367054 ,  1.29489827,\n",
      "        2.57197285,  0.61579289,  1.28458881,  2.64541526,  0.6132792 ,\n",
      "        1.55774889,  2.97032781,  0.67978129,  1.32245536,  2.6477942 ,\n",
      "        0.66326928,  1.31903639,  2.39540086,  2.23568788,  4.74385028,\n",
      "        9.58628278,  2.35934415,  4.51328764,  8.78399105,  2.17256994,\n",
      "        4.42466803, 10.18574247,  2.24275875,  4.5038847 ,  9.00049672,\n",
      "        2.20075955,  4.25782938,  8.6246532 ,  2.11372738,  4.33043857,\n",
      "        9.65580745,  2.21928406,  4.52249517,  8.76421409,  2.35864205,\n",
      "        4.30356016,  8.37803769,  2.07711387,  4.70468163,  9.06992359,\n",
      "        1.02754698,  1.82810245,  3.70656776,  0.79349766,  2.16234283,\n",
      "        3.86624665,  0.95041461,  1.66655788,  3.78353348,  1.21362004,\n",
      "        1.77932248,  3.50705771,  0.84037113,  1.62533007,  3.34399562,\n",
      "        0.76909246,  1.60036988,  3.18300653,  0.76695132,  1.49668765,\n",
      "        2.79764571,  0.69504538,  1.3917778 ,  2.99666538,  0.73058128,\n",
      "        1.61689391,  3.54066362,  0.96067319,  2.03785329,  3.48296762,\n",
      "        0.82529988,  1.61125484,  3.35008178,  0.83734841,  1.90402799,\n",
      "        3.37540812,  0.83123932,  1.75666685,  3.20637631,  0.83266296,\n",
      "        1.5175992 ,  3.04677348,  0.72715406,  1.48415446,  3.17088518,\n",
      "        0.72660251,  1.67486196,  3.05134449,  0.74660349,  1.46971097,\n",
      "        3.16318474,  0.72217607,  1.43933406,  3.09092727,  2.87093544,\n",
      "        6.52080798, 11.04897108,  2.57899384,  5.1113143 , 11.51229744,\n",
      "        2.61967754,  5.41747336, 10.43809633,  2.46730375,  5.0333148 ,\n",
      "        9.8410677 ,  2.4506506 ,  4.79840684, 10.77289109,  2.55312138,\n",
      "        4.90712905, 10.56049304,  2.24842477,  4.83241525,  9.45147114,\n",
      "        2.26766386,  4.67051258,  8.77241292,  2.10314093,  4.22095089,\n",
      "        8.54604955,  0.93824077,  1.85095882,  3.73806925,  0.89106407,\n",
      "        1.78718076,  3.58762279,  0.87414241,  1.71077518,  3.41000924,\n",
      "        0.86309767,  1.68996539,  3.57081995,  0.87884026,  1.69322295,\n",
      "        3.35287476,  0.78155699,  1.59751787,  3.13523283,  0.76067491,\n",
      "        1.50882349,  3.44065771,  0.90544834,  1.82881899,  3.07904935,\n",
      "        0.72793417,  1.49458065,  3.13509793,  0.97925272,  1.94303107,\n",
      "        3.82020693,  0.90085664,  1.78061452,  3.63835516,  1.01008267,\n",
      "        1.74534655,  3.46398907,  0.86939716,  1.70768518,  3.9682488 ,\n",
      "        0.89793968,  1.85211687,  3.49485154,  0.8543673 ,  1.60562387,\n",
      "        3.19932666,  0.73729382,  1.46546683,  3.01023874,  0.73097348,\n",
      "        1.46133227,  3.01651349,  0.72365789,  1.45658803,  3.01149669]), 'std_fit_time': array([0.08791796, 0.17101618, 0.34043515, 0.06457071, 0.09915199,\n",
      "       0.21692487, 0.10631824, 0.19639985, 0.33735401, 0.09855568,\n",
      "       0.19620658, 0.31075299, 0.0561423 , 0.11581226, 0.2215624 ,\n",
      "       0.07062639, 0.10928451, 0.20591182, 0.09063742, 0.12354428,\n",
      "       0.35851059, 0.08841256, 0.0939449 , 0.18589186, 0.08325431,\n",
      "       0.20506009, 0.20719405, 0.05592141, 0.04344334, 0.12683633,\n",
      "       0.10798845, 0.01990583, 0.12148028, 0.03721666, 0.02668043,\n",
      "       0.34904846, 0.07351319, 0.29001526, 0.33724765, 0.10256608,\n",
      "       0.05186324, 0.09548136, 0.02870505, 0.03837284, 0.05851945,\n",
      "       0.00744188, 0.08508528, 0.12508322, 0.1936224 , 0.16928275,\n",
      "       0.04549569, 0.00970645, 0.02425593, 0.09158337, 0.02100585,\n",
      "       0.1480097 , 0.2477668 , 0.04609203, 0.05480837, 0.06642834,\n",
      "       0.01080436, 0.04192948, 0.14488619, 0.02593732, 0.04166832,\n",
      "       0.05916439, 0.01433299, 0.03863442, 0.0455576 , 0.03345482,\n",
      "       0.04089834, 0.08307373, 0.0320365 , 0.03821862, 0.08566029,\n",
      "       0.01518367, 0.0533855 , 0.09045313, 0.01601688, 0.06476439,\n",
      "       0.0631353 , 0.02694466, 0.03093168, 0.10127617, 0.02683758,\n",
      "       0.01718295, 0.11463629, 0.02554286, 0.08309374, 0.06049341,\n",
      "       0.01634568, 0.03953814, 0.10926563, 0.04327558, 0.05334059,\n",
      "       0.06575337, 0.00750912, 0.05301041, 0.05187503, 0.01356805,\n",
      "       0.07808064, 0.16555108, 0.05082425, 0.10250244, 0.07956513,\n",
      "       0.01968674, 0.04541839, 0.10499825, 0.00525677, 0.07302855,\n",
      "       0.03521682, 0.00931261, 0.01132491, 0.08502958, 0.01165765,\n",
      "       0.04427512, 0.0810752 , 0.0183865 , 0.02701191, 0.05122497,\n",
      "       0.00789102, 0.03443163, 0.04527873, 0.00767464, 0.06102772,\n",
      "       0.10555967, 0.02023078, 0.08295228, 0.09736272, 0.01959306,\n",
      "       0.02627292, 0.08757596, 0.01935063, 0.04154983, 0.10086463,\n",
      "       0.01426047, 0.03579285, 0.08823371, 0.00880661, 0.03811821,\n",
      "       0.06787194, 0.01076706, 0.3719441 , 0.32308078, 0.13305677,\n",
      "       0.09827166, 0.08399996, 0.0215021 , 0.03400021, 0.02513673,\n",
      "       0.01472332, 0.05374423, 0.21242793, 0.07131042, 0.10762892,\n",
      "       0.12776411, 0.03125612, 0.0331235 , 0.10224153, 0.01305152,\n",
      "       0.07186035, 0.01955351, 0.04909232, 0.0742485 , 0.18124754,\n",
      "       0.15120978, 0.36749309, 0.47190518, 0.145877  , 0.55385022,\n",
      "       0.9105387 , 0.55864593, 0.48252483, 0.97452881, 0.46558416,\n",
      "       0.87658963, 0.25132918, 0.07690686, 0.17369882, 0.11063452,\n",
      "       0.03161177, 0.06891912, 0.30395289, 0.08040661, 0.24425174,\n",
      "       0.50129771, 0.29777788, 0.56205329, 0.30844197, 0.02028237,\n",
      "       0.1002193 , 0.16073766, 0.01775646, 0.03035077, 0.1050835 ,\n",
      "       0.01506635, 0.17121541, 0.29470416, 0.04157846, 0.11628499,\n",
      "       0.32066031, 0.04080295, 0.18274657, 0.10420711, 0.17979614,\n",
      "       0.03416705, 0.08355344, 0.03640194, 0.10925324, 0.24758296,\n",
      "       0.11091465, 0.0796832 , 0.05395528, 0.01128651, 0.03311898,\n",
      "       0.07330702, 0.01201386, 0.03739017, 0.04057274, 0.01500752,\n",
      "       0.29364479, 0.29739854, 0.06247217, 0.12379407, 0.23272574,\n",
      "       0.0413408 , 0.15773272, 0.07857413, 0.00676239, 0.0284649 ,\n",
      "       0.11692038, 0.02850072, 0.05283747, 0.19886031, 0.0531489 ,\n",
      "       0.26836731, 0.31815349, 0.07972922, 0.07615797, 0.17151394,\n",
      "       0.02907692, 0.10335327, 0.02864442, 0.03617078, 0.08724911,\n",
      "       0.18236489, 0.10840141, 0.07916981, 0.2261607 , 0.03915733,\n",
      "       0.02634679, 0.60076235, 0.06412251, 0.20290172, 0.26274353,\n",
      "       0.10023298, 0.08383221, 0.21487561, 0.05146036, 0.05536705,\n",
      "       0.34634607, 0.16842364, 0.29978256, 0.46256772, 0.15311992,\n",
      "       0.25977522, 0.39115848, 0.07728211, 0.53372315, 0.57139107,\n",
      "       0.13046831, 0.19691049, 0.33807188, 0.02329916, 0.35725052,\n",
      "       0.26873761, 0.17162737, 0.09073604, 0.63299269, 0.32593202,\n",
      "       0.17904332, 0.17673576, 0.04135493, 0.08161995, 0.12875332,\n",
      "       0.05675985, 0.15627201, 0.22284399, 0.11188729, 0.0709942 ,\n",
      "       0.03301565, 0.01479325, 0.01719268, 0.12388508, 0.07270866,\n",
      "       0.17241184, 0.43753939, 0.13896161, 0.14421654, 0.18233876,\n",
      "       0.04971699, 0.07194085, 0.21673527, 0.0690077 , 0.12758286,\n",
      "       0.28496576, 0.05625157, 0.122879  , 0.09272698, 0.06403043,\n",
      "       0.04649598, 0.0333649 , 0.01860502, 0.03299197, 0.24214105,\n",
      "       0.03992634, 0.16831291, 0.06633539, 0.02184157, 0.06298614,\n",
      "       0.08639067, 0.02191578, 0.13560771, 0.13512092, 0.28473915,\n",
      "       0.38368726, 0.31618917, 0.08366998, 0.12798818, 0.57672919,\n",
      "       0.13937567, 0.35171946, 0.33284754, 0.07730148, 0.22974717,\n",
      "       0.29209333, 0.08045521, 0.1482072 , 0.73395777, 0.22119068,\n",
      "       0.13611074, 0.52604814, 0.12219091, 0.24967846, 0.26977911,\n",
      "       0.17687501, 0.26117   , 0.36637846, 0.03264903, 0.11511307,\n",
      "       0.0733605 , 0.01942382, 0.02648698, 0.06267981, 0.03251485,\n",
      "       0.02075614, 0.08709235, 0.0379736 , 0.02172697, 0.05792067,\n",
      "       0.04811081, 0.02388321, 0.07780434, 0.02213822, 0.05008667,\n",
      "       0.04316027, 0.01859523, 0.01655844, 0.05331114, 0.00734727,\n",
      "       0.0490599 , 0.32213376, 0.13883444, 0.18928955, 0.09430088,\n",
      "       0.01190412, 0.02234057, 0.06455357, 0.06242628, 0.03461647,\n",
      "       0.07185153, 0.03972062, 0.01429237, 0.12117616, 0.10513319,\n",
      "       0.04936973, 0.11279338, 0.05278208, 0.03205954, 0.12145857,\n",
      "       0.02418684, 0.08092461, 0.06535935, 0.09212868, 0.02745635,\n",
      "       0.07142275, 0.01982581, 0.01715722, 0.04587871, 0.01046138,\n",
      "       0.01490699, 0.07774969, 0.00999421, 0.02493432, 0.07625654]), 'mean_score_time': array([0.02331715, 0.03971405, 0.08991146, 0.0199142 , 0.04510093,\n",
      "       0.07258234, 0.0162765 , 0.03556619, 0.07695122, 0.02175393,\n",
      "       0.03758736, 0.07413878, 0.01667399, 0.04383273, 0.06848311,\n",
      "       0.01297312, 0.03474436, 0.06778836, 0.01619186, 0.03001089,\n",
      "       0.0791563 , 0.01499491, 0.03077455, 0.06906219, 0.01779757,\n",
      "       0.03132553, 0.06624045, 0.0222558 , 0.03949914, 0.08670998,\n",
      "       0.02822399, 0.04137058, 0.07945533, 0.01648507, 0.03983712,\n",
      "       0.13106928, 0.02514038, 0.04658451, 0.0746676 , 0.01973419,\n",
      "       0.03909793, 0.06982546, 0.01631455, 0.03482475, 0.066745  ,\n",
      "       0.01646013, 0.03638654, 0.07026253, 0.02034683, 0.0338306 ,\n",
      "       0.06330247, 0.01958528, 0.0330379 , 0.07021108, 0.02200856,\n",
      "       0.05080824, 0.08187032, 0.02653546, 0.04055762, 0.07739558,\n",
      "       0.01805854, 0.04054646, 0.07331104, 0.02271094, 0.0362752 ,\n",
      "       0.07555714, 0.01846981, 0.03630323, 0.07746072, 0.01758409,\n",
      "       0.04005332, 0.0710259 , 0.01650624, 0.03265228, 0.07124887,\n",
      "       0.01630034, 0.03301511, 0.06067448, 0.01495633, 0.03332334,\n",
      "       0.06665468, 0.00962148, 0.01945701, 0.03582029, 0.00994124,\n",
      "       0.02005172, 0.03670554, 0.00998578, 0.01850934, 0.04040599,\n",
      "       0.01140504, 0.01912985, 0.03687916, 0.0090095 , 0.0204031 ,\n",
      "       0.03571577, 0.0072042 , 0.02312217, 0.04850559, 0.00995488,\n",
      "       0.0196527 , 0.06603537, 0.01512966, 0.02585826, 0.04045033,\n",
      "       0.00954032, 0.01999373, 0.04734397, 0.00684662, 0.02090702,\n",
      "       0.03957248, 0.00809631, 0.02031918, 0.04498234, 0.01343288,\n",
      "       0.0184876 , 0.04706841, 0.01651773, 0.02515969, 0.04465289,\n",
      "       0.0130023 , 0.02570701, 0.04369059, 0.01513162, 0.02508473,\n",
      "       0.04167881, 0.01429935, 0.01645584, 0.04636083, 0.00979142,\n",
      "       0.02472177, 0.04522228, 0.01100812, 0.02156324, 0.04716215,\n",
      "       0.01374574, 0.02374401, 0.04755788, 0.0084703 , 0.02395172,\n",
      "       0.04731507, 0.01308513, 0.03510156, 0.04410434, 0.01336322,\n",
      "       0.02563305, 0.04467349, 0.01593971, 0.0268549 , 0.05162535,\n",
      "       0.01164122, 0.02176666, 0.05237093, 0.01594496, 0.03073101,\n",
      "       0.05706306, 0.0137713 , 0.02492909, 0.04657712, 0.01095524,\n",
      "       0.02419195, 0.04223166, 0.00949793, 0.0301477 , 0.07463765,\n",
      "       0.01361556, 0.05692549, 0.05155158, 0.00937562, 0.03379841,\n",
      "       0.08461852, 0.01887083, 0.03796844, 0.07326851, 0.01556115,\n",
      "       0.04136553, 0.06247125, 0.01371269, 0.02643552, 0.05009785,\n",
      "       0.01702108, 0.02809968, 0.0611546 , 0.01496816, 0.03933458,\n",
      "       0.05186505, 0.01420455, 0.02416773, 0.06411128, 0.01497293,\n",
      "       0.03544006, 0.07060909, 0.01282263, 0.03850589, 0.054599  ,\n",
      "       0.01091442, 0.04193044, 0.06247263, 0.01805801, 0.03249464,\n",
      "       0.07472062, 0.01384807, 0.03646421, 0.06882329, 0.01964879,\n",
      "       0.03493123, 0.05713568, 0.01866555, 0.04193077, 0.06555548,\n",
      "       0.01462269, 0.02688494, 0.05219159, 0.01563687, 0.03161278,\n",
      "       0.05804396, 0.01476774, 0.02768517, 0.08014812, 0.01640038,\n",
      "       0.03031745, 0.06219916, 0.02202039, 0.03580918, 0.06317749,\n",
      "       0.02423124, 0.03227878, 0.06790004, 0.01512394, 0.03124924,\n",
      "       0.05957499, 0.01486225, 0.02211552, 0.07584863, 0.0136816 ,\n",
      "       0.04580822, 0.06683364, 0.01415553, 0.03313522, 0.05834718,\n",
      "       0.01715183, 0.03135538, 0.05275054, 0.01635985, 0.062397  ,\n",
      "       0.07554817, 0.01807451, 0.02837315, 0.06667719, 0.01562719,\n",
      "       0.03795366, 0.06583953, 0.01742644, 0.03345418, 0.06258368,\n",
      "       0.01410251, 0.03366694, 0.06877632, 0.01875091, 0.03804293,\n",
      "       0.07530727, 0.02557535, 0.0418623 , 0.06503391, 0.01480341,\n",
      "       0.03169723, 0.06508589, 0.01752982, 0.0343914 , 0.07151937,\n",
      "       0.02364922, 0.04206014, 0.10816255, 0.02540536, 0.03680482,\n",
      "       0.07853723, 0.02222261, 0.04880433, 0.07969794, 0.01702952,\n",
      "       0.03789716, 0.0776485 , 0.02028408, 0.04879427, 0.06965919,\n",
      "       0.01562634, 0.0406507 , 0.06798468, 0.01562691, 0.03077717,\n",
      "       0.06562991, 0.01562696, 0.02822795, 0.08276472, 0.02014999,\n",
      "       0.03646936, 0.09062362, 0.02671595, 0.03586383, 0.06884227,\n",
      "       0.0161531 , 0.03690133, 0.07225008, 0.01896114, 0.03785157,\n",
      "       0.0701314 , 0.01856961, 0.03538637, 0.06562977, 0.01641579,\n",
      "       0.03336029, 0.0656301 , 0.0207458 , 0.03018751, 0.07810116,\n",
      "       0.01790981, 0.03788667, 0.06209917, 0.01889563, 0.03436036,\n",
      "       0.06250486, 0.01778316, 0.03821511, 0.07299228, 0.02087607,\n",
      "       0.0536396 , 0.08062787, 0.02145529, 0.04224367, 0.07878246,\n",
      "       0.01734681, 0.0344377 , 0.07351451, 0.01875086, 0.03437934,\n",
      "       0.07188191, 0.01562848, 0.03139987, 0.08267045, 0.01773272,\n",
      "       0.03467951, 0.10090952, 0.02307653, 0.03228917, 0.07137723,\n",
      "       0.02196679, 0.03929853, 0.07072067, 0.01634469, 0.03130689,\n",
      "       0.06230817, 0.02075739, 0.03904572, 0.07872267, 0.02241106,\n",
      "       0.03685451, 0.08009663, 0.01635432, 0.03613505, 0.06858444,\n",
      "       0.01947365, 0.03425727, 0.07140751, 0.01700044, 0.04000959,\n",
      "       0.06866503, 0.01929083, 0.03086944, 0.06808233, 0.01669102,\n",
      "       0.03915582, 0.07496691, 0.02620955, 0.04529839, 0.06731763,\n",
      "       0.01634312, 0.03018103, 0.07733064, 0.02498069, 0.04132466,\n",
      "       0.07413135, 0.02128735, 0.03506684, 0.07525864, 0.01646357,\n",
      "       0.03741312, 0.07266808, 0.02011299, 0.04094243, 0.0954299 ,\n",
      "       0.01965456, 0.03982606, 0.07404184, 0.02149997, 0.03355889,\n",
      "       0.06709766, 0.0166893 , 0.03112068, 0.07250271, 0.01814766,\n",
      "       0.03243289, 0.06513824, 0.0145421 , 0.03333311, 0.07544403]), 'std_score_time': array([6.21392457e-03, 6.18996736e-03, 8.10180984e-03, 4.12722567e-03,\n",
      "       1.22682812e-02, 6.10346410e-03, 4.87551050e-04, 3.70367619e-03,\n",
      "       6.23440688e-03, 6.65871103e-03, 5.40211069e-03, 4.88003527e-03,\n",
      "       5.37483747e-03, 3.77702145e-03, 3.62269499e-03, 4.14641098e-03,\n",
      "       3.88203749e-03, 6.13084340e-03, 4.49568299e-04, 2.99744826e-03,\n",
      "       8.97282813e-03, 3.41604422e-03, 6.52650988e-03, 4.81752789e-03,\n",
      "       2.79036467e-03, 3.59732386e-03, 9.08755596e-04, 3.51701383e-03,\n",
      "       7.84726477e-03, 5.44600673e-03, 1.14867238e-02, 7.17548368e-03,\n",
      "       6.50942759e-03, 3.94759559e-04, 5.69244843e-03, 8.03111959e-02,\n",
      "       7.18268535e-03, 1.05213704e-02, 7.48977561e-03, 4.20333576e-03,\n",
      "       7.16538857e-03, 6.75794310e-03, 6.98971280e-04, 2.70120091e-03,\n",
      "       6.91140183e-03, 3.71036684e-04, 5.07046623e-03, 4.54805719e-03,\n",
      "       4.48205461e-03, 1.84908072e-03, 4.03314042e-03, 4.46786461e-03,\n",
      "       6.23300314e-04, 1.26382147e-02, 6.60849177e-03, 2.90915830e-03,\n",
      "       1.05430150e-02, 5.15411324e-03, 6.44056534e-03, 8.82703100e-03,\n",
      "       3.32686834e-03, 1.44611597e-02, 8.18305021e-03, 6.56426692e-03,\n",
      "       3.87402793e-03, 5.80846307e-03, 2.76699942e-03, 4.72864679e-03,\n",
      "       6.14030869e-03, 1.85877795e-03, 1.33227727e-02, 6.13514218e-03,\n",
      "       4.30821288e-04, 1.36484000e-03, 5.96380209e-03, 4.81034512e-04,\n",
      "       5.55354300e-04, 6.20656312e-03, 3.38780817e-03, 3.52148035e-05,\n",
      "       2.02894071e-05, 6.51675509e-03, 4.22136206e-03, 5.01362681e-03,\n",
      "       5.32933723e-03, 6.62241107e-03, 3.25198779e-03, 3.85775099e-03,\n",
      "       3.61333479e-03, 6.55127359e-03, 6.52581035e-03, 3.49684623e-03,\n",
      "       5.15980326e-03, 5.26030844e-03, 4.56834441e-03, 3.25742072e-03,\n",
      "       4.51263179e-03, 6.06675692e-03, 1.51854317e-02, 8.12845683e-03,\n",
      "       4.14978589e-03, 1.66587015e-02, 2.20674044e-03, 7.64920259e-03,\n",
      "       7.83712264e-03, 6.53974220e-03, 6.66886361e-03, 6.22299303e-03,\n",
      "       6.36273845e-03, 5.61234960e-03, 5.38395311e-03, 5.71357263e-03,\n",
      "       4.49274876e-03, 3.21532174e-03, 4.30424428e-03, 3.69503237e-03,\n",
      "       8.00824546e-03, 3.43019086e-04, 8.37369827e-03, 3.37942647e-03,\n",
      "       6.51261987e-03, 7.05409886e-03, 7.68865690e-03, 4.31135580e-03,\n",
      "       5.39209084e-03, 8.24098486e-03, 7.14180006e-03, 8.72151349e-03,\n",
      "       4.33551521e-03, 7.16668367e-03, 4.94195115e-03, 4.99028701e-03,\n",
      "       4.00288167e-03, 1.04179595e-02, 5.94910862e-03, 4.81840710e-03,\n",
      "       4.33888375e-03, 5.91384651e-03, 7.95170898e-03, 3.41924865e-03,\n",
      "       6.27332445e-03, 5.19934432e-03, 6.02983397e-03, 6.28541543e-03,\n",
      "       8.08223911e-03, 7.46867214e-03, 1.10516193e-02, 4.52435326e-03,\n",
      "       6.37774334e-03, 1.10231457e-02, 4.49732268e-03, 2.90622116e-03,\n",
      "       1.12625688e-02, 5.86625817e-03, 6.86908267e-03, 2.28043721e-02,\n",
      "       9.60358445e-03, 7.12283352e-03, 1.35426458e-02, 7.03030196e-03,\n",
      "       4.02183641e-03, 7.52172083e-03, 6.12629977e-03, 2.84886019e-03,\n",
      "       3.26898385e-02, 6.68337878e-03, 3.09246958e-02, 9.34517393e-03,\n",
      "       7.65516160e-03, 2.82185613e-03, 3.12705120e-02, 7.03856782e-03,\n",
      "       1.73991623e-02, 1.37996067e-02, 1.53569256e-03, 1.53126024e-02,\n",
      "       1.91132799e-02, 3.55385628e-03, 3.88382685e-03, 7.14251911e-03,\n",
      "       6.81448341e-04, 5.43063721e-03, 4.17950091e-03, 3.87428891e-03,\n",
      "       1.79619973e-02, 2.80499542e-03, 8.34514754e-03, 7.59799210e-03,\n",
      "       2.82530274e-03, 1.17473241e-02, 4.38514670e-03, 1.55933052e-02,\n",
      "       4.79336396e-03, 9.95867803e-03, 5.67955264e-03, 7.17729070e-03,\n",
      "       1.65504163e-02, 6.98549603e-03, 2.98804818e-03, 6.38554600e-04,\n",
      "       1.57505982e-02, 6.78292161e-03, 9.77200118e-03, 1.19438550e-02,\n",
      "       3.84319563e-03, 5.23357451e-03, 9.25902517e-03, 2.92842581e-03,\n",
      "       1.34347332e-02, 9.56395434e-03, 3.58330867e-03, 5.45674996e-03,\n",
      "       2.11989615e-03, 1.60324325e-03, 2.08777244e-03, 5.38223338e-03,\n",
      "       3.34845160e-03, 6.24445174e-03, 4.55386705e-02, 5.69007698e-03,\n",
      "       8.36167570e-03, 6.74037534e-03, 7.14642324e-03, 7.12314984e-03,\n",
      "       9.08259514e-03, 2.01611296e-02, 1.29823228e-03, 1.31620917e-02,\n",
      "       3.88906992e-03, 7.16567321e-03, 1.25123251e-02, 3.63561176e-03,\n",
      "       4.74255166e-03, 1.93956806e-02, 5.66299456e-03, 2.79736738e-02,\n",
      "       6.92669282e-03, 4.59498984e-03, 4.22707117e-03, 5.57632381e-03,\n",
      "       4.08548208e-03, 1.12632221e-02, 7.08638769e-03, 4.13370141e-04,\n",
      "       2.24744853e-02, 1.29743749e-02, 2.98838206e-03, 3.74109706e-03,\n",
      "       1.68548092e-02, 1.40969710e-06, 1.19248326e-02, 3.68891374e-03,\n",
      "       5.65036672e-03, 2.50592388e-03, 1.57237803e-04, 3.04689419e-03,\n",
      "       4.58017973e-03, 1.25426293e-02, 6.25216965e-03, 1.67958700e-02,\n",
      "       1.89663442e-02, 1.23619091e-02, 1.39475728e-02, 4.58566813e-03,\n",
      "       2.55729447e-03, 2.04567140e-03, 1.34935349e-03, 5.12981858e-03,\n",
      "       4.20271903e-03, 1.44643294e-02, 1.22084811e-02, 5.46005968e-03,\n",
      "       2.60877170e-02, 1.32114555e-02, 4.06332352e-03, 8.90945042e-03,\n",
      "       5.89906944e-03, 2.72450108e-02, 2.09212242e-02, 7.89845549e-03,\n",
      "       4.99446069e-03, 1.13808499e-02, 4.79330342e-03, 2.02432878e-02,\n",
      "       1.38937065e-02, 1.29362678e-06, 1.28057330e-02, 6.37674599e-03,\n",
      "       6.74349576e-07, 8.49998157e-03, 6.25064398e-03, 1.40160927e-06,\n",
      "       6.30361990e-03, 1.80955205e-02, 6.17605631e-03, 5.41566680e-03,\n",
      "       1.42249209e-02, 1.37201635e-02, 5.47443087e-03, 7.76344771e-03,\n",
      "       4.12025601e-03, 7.09075661e-03, 1.01134922e-02, 4.31428011e-03,\n",
      "       1.10667379e-02, 6.92728039e-03, 3.86944926e-03, 5.02310447e-03,\n",
      "       6.25262273e-03, 8.94712997e-03, 4.21140385e-03, 6.24923710e-03,\n",
      "       9.25437633e-03, 1.67131336e-03, 1.58833227e-02, 3.36807922e-03,\n",
      "       6.26920058e-03, 1.00462232e-02, 6.19703681e-03, 6.29545331e-03,\n",
      "       9.24621555e-07, 4.31501873e-03, 8.60196534e-03, 6.78489290e-03,\n",
      "       6.98020723e-03, 2.06519202e-02, 4.99429706e-03, 7.16882922e-03,\n",
      "       9.06085361e-03, 2.51739108e-03, 3.43742478e-03, 6.22076921e-03,\n",
      "       5.93012878e-03, 6.25278964e-03, 6.24914253e-03, 1.25021459e-02,\n",
      "       2.34863479e-06, 2.92246823e-04, 1.82503945e-02, 3.10379851e-03,\n",
      "       3.06410490e-03, 1.65570969e-02, 3.34961850e-03, 8.93396501e-04,\n",
      "       6.46405781e-03, 6.41190845e-03, 1.15912334e-02, 1.33780584e-02,\n",
      "       3.97765359e-04, 3.30788419e-03, 7.50583690e-03, 5.04701550e-03,\n",
      "       5.50585277e-03, 4.63772846e-03, 7.19114896e-03, 6.04115067e-03,\n",
      "       6.06714688e-03, 4.39692032e-04, 4.63615155e-03, 7.68574997e-03,\n",
      "       3.81583463e-03, 7.33891804e-03, 6.51694278e-03, 5.41263198e-03,\n",
      "       8.14483649e-03, 4.01485053e-03, 5.20438097e-03, 3.18378013e-03,\n",
      "       7.57671620e-03, 7.77113500e-05, 7.24043818e-03, 7.13004024e-03,\n",
      "       1.63736661e-02, 6.23060045e-03, 3.31838497e-03, 2.33464963e-03,\n",
      "       6.25797117e-03, 5.81527957e-03, 5.60068675e-03, 5.28091943e-03,\n",
      "       2.59483201e-03, 5.65897388e-03, 3.46841427e-03, 7.78531751e-03,\n",
      "       4.25129874e-04, 3.46204808e-03, 7.26418379e-03, 2.95781020e-03,\n",
      "       1.12679948e-02, 2.20744671e-02, 5.44082601e-03, 7.57844187e-03,\n",
      "       6.56736437e-03, 6.37376749e-03, 5.24784529e-04, 4.52441498e-03,\n",
      "       9.46937213e-04, 3.69965964e-03, 5.01146166e-03, 2.93679570e-03,\n",
      "       9.10839355e-03, 5.51929262e-03, 3.29883176e-03, 3.90105256e-05,\n",
      "       5.68883715e-03]), 'param_max_depth': masked_array(data=[None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   None, None, None, None, None, None, None, None, None,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "                   15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
      "                   'log2', 'log2', 'log2', 'log2', 'log2', 'log2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                   4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
      "                   10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
      "                   10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
      "                   10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5,\n",
      "                   5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2,\n",
      "                   2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10,\n",
      "                   2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
      "                   10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
      "                   10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
      "                   10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5,\n",
      "                   5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2,\n",
      "                   2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10,\n",
      "                   2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
      "                   10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
      "                   10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
      "                   10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5,\n",
      "                   5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2,\n",
      "                   2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10,\n",
      "                   2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10,\n",
      "                   10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10,\n",
      "                   10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5,\n",
      "                   10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5,\n",
      "                   5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10, 2, 2,\n",
      "                   2, 5, 5, 5, 10, 10, 10, 2, 2, 2, 5, 5, 5, 10, 10, 10,\n",
      "                   2, 2, 2, 5, 5, 5, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200, 50, 100, 200,\n",
      "                   50, 100, 200, 50, 100, 200, 50, 100, 200],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}, {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}], 'split0_test_score': array([-0.02070266, -0.02008018, -0.02034996, -0.02026151, -0.02051395,\n",
      "       -0.02010988, -0.01990146, -0.01998291, -0.0196892 , -0.01917267,\n",
      "       -0.01897485, -0.01896676, -0.01909942, -0.01926168, -0.01893805,\n",
      "       -0.01881173, -0.01893823, -0.0188337 , -0.01817115, -0.01811911,\n",
      "       -0.01826051, -0.01818069, -0.01835239, -0.01835511, -0.0188605 ,\n",
      "       -0.01844983, -0.01838608, -0.01901441, -0.01968457, -0.01905841,\n",
      "       -0.01957022, -0.01876119, -0.0188039 , -0.01872032, -0.01856686,\n",
      "       -0.01850241, -0.01859888, -0.01838633, -0.01828742, -0.01808177,\n",
      "       -0.01786579, -0.01808914, -0.01803401, -0.01851998, -0.01793624,\n",
      "       -0.01794075, -0.01785893, -0.01771175, -0.01767264, -0.0178998 ,\n",
      "       -0.01779409, -0.01764165, -0.01778813, -0.01782064, -0.01942983,\n",
      "       -0.01882644, -0.01901275, -0.0193114 , -0.01890129, -0.01887176,\n",
      "       -0.01929346, -0.01889436, -0.01837286, -0.01790959, -0.01885265,\n",
      "       -0.01826642, -0.01853733, -0.01832209, -0.01838328, -0.01775131,\n",
      "       -0.01775367, -0.01780307, -0.01771534, -0.01772597, -0.0176597 ,\n",
      "       -0.01840419, -0.01784036, -0.01783313, -0.0177941 , -0.01778752,\n",
      "       -0.0176883 , -0.01785738, -0.01780635, -0.01775092, -0.01799237,\n",
      "       -0.01792858, -0.01799445, -0.01786619, -0.01796774, -0.01807861,\n",
      "       -0.01736812, -0.01718035, -0.01729371, -0.01745681, -0.01738167,\n",
      "       -0.01732235, -0.01720575, -0.01724983, -0.01733391, -0.01706243,\n",
      "       -0.01743154, -0.01728766, -0.01742223, -0.01744658, -0.01726654,\n",
      "       -0.01733843, -0.01714068, -0.01723535, -0.0170706 , -0.0172381 ,\n",
      "       -0.01712702, -0.0170617 , -0.01707319, -0.0171408 , -0.01718905,\n",
      "       -0.01731343, -0.01716628, -0.01726831, -0.01706673, -0.01714486,\n",
      "       -0.01701859, -0.01694169, -0.01691975, -0.01697261, -0.01699062,\n",
      "       -0.01703548, -0.01703234, -0.01709735, -0.01708843, -0.01712018,\n",
      "       -0.01719967, -0.01716304, -0.01692699, -0.01718364, -0.016929  ,\n",
      "       -0.01725679, -0.0171244 , -0.01721805, -0.01707921, -0.01711895,\n",
      "       -0.01692479, -0.01711997, -0.01712769, -0.01695037, -0.01713047,\n",
      "       -0.01711594, -0.0169517 , -0.01716057, -0.01704281, -0.01703   ,\n",
      "       -0.01705708, -0.01707665, -0.01706316, -0.01713941, -0.01714383,\n",
      "       -0.01697617, -0.01716048, -0.01703301, -0.01697079, -0.01704994,\n",
      "       -0.01685391, -0.01709048, -0.01969539, -0.01922726, -0.01921678,\n",
      "       -0.01902027, -0.01926244, -0.01912967, -0.01889513, -0.0190369 ,\n",
      "       -0.01899942, -0.01868398, -0.01882895, -0.01861622, -0.01878168,\n",
      "       -0.01867741, -0.01849804, -0.01885064, -0.01834109, -0.01816512,\n",
      "       -0.01829648, -0.01816186, -0.01802071, -0.01815929, -0.01791964,\n",
      "       -0.01817776, -0.01768089, -0.01782009, -0.01791769, -0.0184421 ,\n",
      "       -0.01802024, -0.01790229, -0.01807779, -0.01811973, -0.01818479,\n",
      "       -0.01860463, -0.01839025, -0.01807961, -0.0181111 , -0.01787472,\n",
      "       -0.01787619, -0.01808661, -0.01807622, -0.0176602 , -0.0177538 ,\n",
      "       -0.01731363, -0.01750004, -0.01780136, -0.0178014 , -0.01755006,\n",
      "       -0.01767029, -0.01739791, -0.01765647, -0.017712  , -0.01759593,\n",
      "       -0.01769956, -0.01871809, -0.0181533 , -0.0181991 , -0.01798578,\n",
      "       -0.0180596 , -0.01821128, -0.01808288, -0.01802906, -0.01807475,\n",
      "       -0.01820709, -0.01815361, -0.01774152, -0.01845788, -0.01794878,\n",
      "       -0.01769208, -0.01793676, -0.01767922, -0.01775926, -0.01762118,\n",
      "       -0.01764542, -0.01766257, -0.01754806, -0.01741726, -0.01751421,\n",
      "       -0.01735796, -0.01766211, -0.01732195, -0.02028911, -0.01995905,\n",
      "       -0.02003622, -0.02030063, -0.02018134, -0.01975942, -0.01922434,\n",
      "       -0.01968593, -0.01958035, -0.0193234 , -0.01888304, -0.01904296,\n",
      "       -0.01913385, -0.01900282, -0.01880453, -0.01843943, -0.01894194,\n",
      "       -0.01852875, -0.01797295, -0.0185904 , -0.01825923, -0.01878628,\n",
      "       -0.01853306, -0.01797268, -0.01857318, -0.0181441 , -0.01797674,\n",
      "       -0.01832935, -0.01951538, -0.01852312, -0.01889652, -0.01829616,\n",
      "       -0.01852532, -0.01879575, -0.01863884, -0.01854052, -0.01841551,\n",
      "       -0.01831079, -0.01799831, -0.01823785, -0.01818122, -0.01796637,\n",
      "       -0.01777133, -0.01800223, -0.01783705, -0.0181678 , -0.01774523,\n",
      "       -0.0177971 , -0.0176859 , -0.01757134, -0.0176529 , -0.0181522 ,\n",
      "       -0.01767004, -0.01762796, -0.01920766, -0.01860461, -0.01869496,\n",
      "       -0.01943053, -0.01870046, -0.01868415, -0.01865092, -0.0183914 ,\n",
      "       -0.01839461, -0.01865892, -0.01841983, -0.01811195, -0.01786711,\n",
      "       -0.01817877, -0.0182236 , -0.01794572, -0.01789326, -0.01780611,\n",
      "       -0.01796121, -0.0178253 , -0.01785996, -0.01827536, -0.01764371,\n",
      "       -0.01768084, -0.01780236, -0.01755735, -0.01771401, -0.02050239,\n",
      "       -0.02034816, -0.02018295, -0.0202497 , -0.01999553, -0.02000669,\n",
      "       -0.02024076, -0.01938053, -0.019715  , -0.01925208, -0.01934635,\n",
      "       -0.01925323, -0.01924009, -0.01897543, -0.01920222, -0.01909103,\n",
      "       -0.01892794, -0.01868793, -0.01838134, -0.01854517, -0.0182462 ,\n",
      "       -0.01850635, -0.01828003, -0.01835758, -0.01796298, -0.01797064,\n",
      "       -0.01818566, -0.01928199, -0.01872291, -0.01948893, -0.01876974,\n",
      "       -0.01861008, -0.01848247, -0.01893954, -0.01847841, -0.01825014,\n",
      "       -0.01826776, -0.01835571, -0.01831598, -0.01850852, -0.0184874 ,\n",
      "       -0.01835017, -0.01885542, -0.01809792, -0.01780537, -0.01768415,\n",
      "       -0.01784809, -0.01761456, -0.01835615, -0.01764908, -0.0178266 ,\n",
      "       -0.01774424, -0.01772619, -0.01785754, -0.01892815, -0.01897074,\n",
      "       -0.01875971, -0.01929832, -0.01848486, -0.0186402 , -0.01812924,\n",
      "       -0.0184012 , -0.0182134 , -0.01862016, -0.01851949, -0.01807302,\n",
      "       -0.01841272, -0.01835074, -0.01833326, -0.01846115, -0.01797138,\n",
      "       -0.0182181 , -0.01727339, -0.01786651, -0.01779411, -0.01785365,\n",
      "       -0.01782204, -0.01768949, -0.01778786, -0.01752788, -0.01771469]), 'split1_test_score': array([-0.02191831, -0.0216895 , -0.02078378, -0.02116239, -0.02125819,\n",
      "       -0.02104543, -0.02100131, -0.02075038, -0.0207497 , -0.02022097,\n",
      "       -0.02034215, -0.02050211, -0.02045074, -0.02068783, -0.02053834,\n",
      "       -0.02066963, -0.02008241, -0.02034364, -0.0201535 , -0.01968098,\n",
      "       -0.01999845, -0.01975612, -0.01984076, -0.01986491, -0.0200047 ,\n",
      "       -0.01991168, -0.01979637, -0.02009772, -0.0199955 , -0.020017  ,\n",
      "       -0.02044195, -0.01945582, -0.02005481, -0.01975585, -0.01953403,\n",
      "       -0.0197378 , -0.01999844, -0.01953814, -0.01947805, -0.01947996,\n",
      "       -0.01958277, -0.01935148, -0.01969003, -0.01948708, -0.01949492,\n",
      "       -0.01935636, -0.01936581, -0.01917545, -0.01927502, -0.01914069,\n",
      "       -0.01912358, -0.01935802, -0.0190073 , -0.01902114, -0.02000666,\n",
      "       -0.01993136, -0.01979372, -0.02011587, -0.01948827, -0.01976274,\n",
      "       -0.0199126 , -0.01950819, -0.01956286, -0.01909648, -0.01987027,\n",
      "       -0.01953438, -0.0198664 , -0.01998891, -0.01978696, -0.01979151,\n",
      "       -0.01929323, -0.01939929, -0.0193373 , -0.01930655, -0.01905697,\n",
      "       -0.01929275, -0.01901639, -0.0189897 , -0.0190339 , -0.01905846,\n",
      "       -0.01917875, -0.01901002, -0.01901588, -0.01932293, -0.01929537,\n",
      "       -0.01964767, -0.01933357, -0.01963959, -0.01937252, -0.01925895,\n",
      "       -0.01951566, -0.01927035, -0.01908714, -0.01921837, -0.01906512,\n",
      "       -0.01889756, -0.01896998, -0.01912501, -0.01890957, -0.01879957,\n",
      "       -0.01866729, -0.01877818, -0.01878936, -0.01871035, -0.01885539,\n",
      "       -0.01866733, -0.01868495, -0.01877834, -0.0184341 , -0.01841408,\n",
      "       -0.0184427 , -0.01852457, -0.0183175 , -0.01843855, -0.01842172,\n",
      "       -0.01855837, -0.01847006, -0.0185047 , -0.0184575 , -0.01830022,\n",
      "       -0.01837478, -0.01823268, -0.01840013, -0.01849142, -0.01848809,\n",
      "       -0.01850716, -0.01841991, -0.01835498, -0.01834185, -0.01821146,\n",
      "       -0.01850435, -0.0182025 , -0.01835594, -0.01827017, -0.01834637,\n",
      "       -0.01844749, -0.01841889, -0.01829975, -0.01816334, -0.01838707,\n",
      "       -0.01839674, -0.01850683, -0.01833452, -0.01845044, -0.01860416,\n",
      "       -0.0184419 , -0.01830071, -0.01841519, -0.01839865, -0.01843649,\n",
      "       -0.01834652, -0.01841253, -0.01833535, -0.01804024, -0.01822302,\n",
      "       -0.01828743, -0.0183883 , -0.01843005, -0.01842993, -0.0182433 ,\n",
      "       -0.01836641, -0.0183566 , -0.02075187, -0.02043655, -0.02054359,\n",
      "       -0.02001737, -0.02036647, -0.02058263, -0.02050265, -0.02071373,\n",
      "       -0.02032513, -0.0202141 , -0.02010722, -0.02012895, -0.02005882,\n",
      "       -0.02024186, -0.01992058, -0.02021857, -0.02034814, -0.02000845,\n",
      "       -0.02012963, -0.01964583, -0.01956027, -0.01958205, -0.01964354,\n",
      "       -0.01954636, -0.01982624, -0.0195886 , -0.01948663, -0.01893795,\n",
      "       -0.01930568, -0.01923342, -0.01939725, -0.01958602, -0.01942226,\n",
      "       -0.01929267, -0.01951833, -0.01894095, -0.01935046, -0.01925709,\n",
      "       -0.01894989, -0.01928276, -0.01929796, -0.01902593, -0.01909243,\n",
      "       -0.01872869, -0.01905491, -0.01912198, -0.01873038, -0.01882903,\n",
      "       -0.01904078, -0.01888535, -0.01903084, -0.01913132, -0.01888392,\n",
      "       -0.01897372, -0.01946198, -0.01915064, -0.01917208, -0.01891657,\n",
      "       -0.01923447, -0.01930341, -0.02002433, -0.01921604, -0.01929079,\n",
      "       -0.01927511, -0.01923979, -0.01921206, -0.01947665, -0.01935011,\n",
      "       -0.0190264 , -0.01888204, -0.01900402, -0.01902726, -0.01900295,\n",
      "       -0.01910349, -0.01888229, -0.01933427, -0.01918577, -0.01891667,\n",
      "       -0.0185761 , -0.01880851, -0.01889178, -0.02146311, -0.02069414,\n",
      "       -0.02090455, -0.02035961, -0.02090981, -0.02104834, -0.02071382,\n",
      "       -0.02109895, -0.02063705, -0.02098911, -0.0205164 , -0.0201544 ,\n",
      "       -0.02051347, -0.02058135, -0.02042149, -0.0205863 , -0.02030004,\n",
      "       -0.02015608, -0.02018953, -0.01978025, -0.01974921, -0.01926757,\n",
      "       -0.01964172, -0.01980452, -0.02006124, -0.01988379, -0.01966902,\n",
      "       -0.0197655 , -0.02001029, -0.01942264, -0.0201664 , -0.01976983,\n",
      "       -0.01976541, -0.01979111, -0.01955063, -0.01943142, -0.01920618,\n",
      "       -0.01973479, -0.01948299, -0.01993104, -0.01954656, -0.0194425 ,\n",
      "       -0.01954114, -0.01927962, -0.01902212, -0.01945264, -0.01922267,\n",
      "       -0.0190532 , -0.01918917, -0.01902038, -0.01902874, -0.01910014,\n",
      "       -0.01924826, -0.01916158, -0.01991141, -0.01965981, -0.01956783,\n",
      "       -0.01995931, -0.0195341 , -0.01956138, -0.01914311, -0.0196881 ,\n",
      "       -0.01948945, -0.01945791, -0.01881443, -0.01935324, -0.01966825,\n",
      "       -0.01954261, -0.01939843, -0.01928933, -0.01964408, -0.01925865,\n",
      "       -0.01891604, -0.0192568 , -0.01918984, -0.01921467, -0.01937722,\n",
      "       -0.01900433, -0.01889808, -0.01929644, -0.01901439, -0.02150005,\n",
      "       -0.02111362, -0.02086244, -0.02042404, -0.02109592, -0.02112954,\n",
      "       -0.02107977, -0.02053058, -0.02091435, -0.02068271, -0.02040484,\n",
      "       -0.02048858, -0.02067154, -0.02073071, -0.02066735, -0.02032271,\n",
      "       -0.02012073, -0.02027464, -0.01990194, -0.02014135, -0.01987602,\n",
      "       -0.02035717, -0.02004702, -0.01989945, -0.02032377, -0.01975162,\n",
      "       -0.01976617, -0.02010523, -0.02006618, -0.01977233, -0.0195191 ,\n",
      "       -0.02002013, -0.01968891, -0.01962853, -0.01984768, -0.01935494,\n",
      "       -0.02012009, -0.01960823, -0.01946719, -0.01994103, -0.01949884,\n",
      "       -0.01947936, -0.01965589, -0.01955388, -0.01946557, -0.0192988 ,\n",
      "       -0.01950735, -0.01914596, -0.01926418, -0.01920919, -0.01918326,\n",
      "       -0.01935013, -0.01901117, -0.01905934, -0.02049753, -0.02048414,\n",
      "       -0.01987096, -0.01983887, -0.01990302, -0.01974651, -0.01992122,\n",
      "       -0.01955558, -0.01952607, -0.01948621, -0.01950017, -0.01963968,\n",
      "       -0.01926992, -0.01982357, -0.01950674, -0.0194899 , -0.01962577,\n",
      "       -0.01948759, -0.01896935, -0.01919892, -0.01926659, -0.01956001,\n",
      "       -0.01924624, -0.01931336, -0.01893051, -0.01904511, -0.01904663]), 'split2_test_score': array([-0.01901558, -0.01881335, -0.01904667, -0.01889832, -0.01863211,\n",
      "       -0.01866783, -0.01846913, -0.01890945, -0.01874595, -0.01882115,\n",
      "       -0.01893046, -0.01864277, -0.01907878, -0.01876105, -0.01857845,\n",
      "       -0.0191227 , -0.01881299, -0.01844012, -0.0183457 , -0.01847212,\n",
      "       -0.01871255, -0.01859357, -0.01841174, -0.01859039, -0.01887572,\n",
      "       -0.01843857, -0.01851351, -0.01951313, -0.01942209, -0.01933939,\n",
      "       -0.0191885 , -0.01912765, -0.01931808, -0.01905778, -0.01871271,\n",
      "       -0.01875571, -0.01886753, -0.01929723, -0.01909416, -0.0188298 ,\n",
      "       -0.01894505, -0.01882561, -0.01888893, -0.01877666, -0.01882172,\n",
      "       -0.01872513, -0.0187774 , -0.0186776 , -0.01888284, -0.01864893,\n",
      "       -0.0186881 , -0.01873735, -0.01870935, -0.01841161, -0.01958291,\n",
      "       -0.01927615, -0.01918219, -0.01938087, -0.01943795, -0.01925276,\n",
      "       -0.01946193, -0.01931732, -0.01882761, -0.01939399, -0.01889987,\n",
      "       -0.01911298, -0.01929578, -0.01896913, -0.01890585, -0.01879667,\n",
      "       -0.01873947, -0.01882849, -0.01921098, -0.01878788, -0.01857712,\n",
      "       -0.01912534, -0.01897774, -0.01862344, -0.01860094, -0.0186138 ,\n",
      "       -0.01861343, -0.01814651, -0.01831368, -0.01837509, -0.01848232,\n",
      "       -0.01826032, -0.0183826 , -0.01840034, -0.01805727, -0.01832895,\n",
      "       -0.01845898, -0.01838598, -0.01832025, -0.01854108, -0.01832404,\n",
      "       -0.0183796 , -0.01851015, -0.01832476, -0.01843628, -0.01829389,\n",
      "       -0.01852271, -0.01842017, -0.01851153, -0.01846794, -0.01851496,\n",
      "       -0.01860478, -0.01845845, -0.01861772, -0.01885881, -0.01854263,\n",
      "       -0.01852371, -0.01853197, -0.01865104, -0.01842121, -0.01859874,\n",
      "       -0.01858652, -0.01856184, -0.01864858, -0.01846386, -0.01853333,\n",
      "       -0.01862726, -0.01868922, -0.01853805, -0.01864306, -0.01853614,\n",
      "       -0.01860195, -0.01857506, -0.01858178, -0.01852755, -0.01842376,\n",
      "       -0.01851917, -0.01839057, -0.01847679, -0.01854715, -0.01854087,\n",
      "       -0.01889582, -0.01868447, -0.01866851, -0.01884536, -0.01856674,\n",
      "       -0.01866851, -0.01888286, -0.01858353, -0.01871912, -0.01869774,\n",
      "       -0.01868979, -0.01858183, -0.01856588, -0.0186076 , -0.01852206,\n",
      "       -0.01863863, -0.01855464, -0.01854827, -0.01867023, -0.01858505,\n",
      "       -0.01849113, -0.01859448, -0.01861788, -0.01851574, -0.01875907,\n",
      "       -0.018499  , -0.01854763, -0.01891343, -0.0185002 , -0.01854778,\n",
      "       -0.01870791, -0.01862898, -0.01865519, -0.0189744 , -0.01856004,\n",
      "       -0.01883944, -0.01890603, -0.01882437, -0.01852365, -0.01900606,\n",
      "       -0.01911277, -0.01863975, -0.01876203, -0.01866658, -0.0184644 ,\n",
      "       -0.01842488, -0.01878795, -0.01838667, -0.01851841, -0.0185182 ,\n",
      "       -0.01851859, -0.0184707 , -0.01872831, -0.01859779, -0.01907504,\n",
      "       -0.01913322, -0.01898177, -0.01917533, -0.0188994 , -0.01889708,\n",
      "       -0.01901195, -0.01880752, -0.01884033, -0.01891053, -0.01874955,\n",
      "       -0.01874815, -0.01911092, -0.01862178, -0.01875484, -0.01872444,\n",
      "       -0.01891326, -0.01872419, -0.01873103, -0.0187751 , -0.01850677,\n",
      "       -0.01903467, -0.01855545, -0.01866378, -0.0185776 , -0.01857887,\n",
      "       -0.01860399, -0.01864514, -0.01891183, -0.01896564, -0.01873498,\n",
      "       -0.01871332, -0.01905565, -0.01874335, -0.01864647, -0.01895405,\n",
      "       -0.0186152 , -0.0189275 , -0.01876138, -0.01893362, -0.01901968,\n",
      "       -0.0187586 , -0.01846564, -0.01857189, -0.01870738, -0.01861993,\n",
      "       -0.01875991, -0.01857257, -0.0185559 , -0.0186653 , -0.01867454,\n",
      "       -0.01858613, -0.01859856, -0.01857632, -0.01921669, -0.01884478,\n",
      "       -0.01880499, -0.01923297, -0.01914002, -0.01877878, -0.01914864,\n",
      "       -0.0191846 , -0.01887063, -0.01918124, -0.01899104, -0.01851679,\n",
      "       -0.01865646, -0.01881198, -0.01883806, -0.01881083, -0.01876918,\n",
      "       -0.01862885, -0.01871802, -0.01860957, -0.01860961, -0.01885442,\n",
      "       -0.01859991, -0.0184464 , -0.0185472 , -0.01853955, -0.01837356,\n",
      "       -0.01947691, -0.01925961, -0.01943648, -0.01924525, -0.01894173,\n",
      "       -0.01901474, -0.0187115 , -0.01874211, -0.01896552, -0.019134  ,\n",
      "       -0.01922469, -0.01890402, -0.01953258, -0.01864578, -0.01888603,\n",
      "       -0.01891641, -0.01890221, -0.01878672, -0.01901118, -0.01874022,\n",
      "       -0.01876133, -0.01895212, -0.01862279, -0.01861312, -0.0189691 ,\n",
      "       -0.01877026, -0.01842919, -0.01935139, -0.01981592, -0.0189527 ,\n",
      "       -0.01943819, -0.019234  , -0.0190937 , -0.01922424, -0.01876641,\n",
      "       -0.01899271, -0.01915188, -0.01916298, -0.01885024, -0.01914589,\n",
      "       -0.01919401, -0.0188951 , -0.01897787, -0.0188014 , -0.01876217,\n",
      "       -0.01900637, -0.01874743, -0.01867636, -0.01849076, -0.01856026,\n",
      "       -0.01861697, -0.01860989, -0.01848709, -0.0185018 , -0.01963043,\n",
      "       -0.01935397, -0.01907978, -0.01959855, -0.01885996, -0.01861388,\n",
      "       -0.01871046, -0.01877954, -0.01851466, -0.01866946, -0.0186242 ,\n",
      "       -0.01889507, -0.01886461, -0.01882097, -0.01861039, -0.01887313,\n",
      "       -0.01853817, -0.01873977, -0.01881803, -0.01866439, -0.01852702,\n",
      "       -0.01895222, -0.01880324, -0.01858928, -0.01872516, -0.01856353,\n",
      "       -0.01861051, -0.01956665, -0.01944816, -0.01917673, -0.0190425 ,\n",
      "       -0.01901319, -0.01911283, -0.01887183, -0.01900752, -0.0189445 ,\n",
      "       -0.0191966 , -0.01896466, -0.01880861, -0.01891725, -0.01896329,\n",
      "       -0.01889121, -0.0188148 , -0.01892819, -0.01871705, -0.01865083,\n",
      "       -0.01870304, -0.01881029, -0.01881185, -0.01874407, -0.0187188 ,\n",
      "       -0.01877054, -0.01850541, -0.0186741 , -0.01917614, -0.01917063,\n",
      "       -0.01936786, -0.01912011, -0.01899787, -0.01912377, -0.01918954,\n",
      "       -0.01894014, -0.01899158, -0.0193317 , -0.0191985 , -0.01910573,\n",
      "       -0.0193666 , -0.01932603, -0.01880688, -0.01886036, -0.01881095,\n",
      "       -0.01882995, -0.01876104, -0.01890753, -0.0185854 , -0.0190188 ,\n",
      "       -0.01898069, -0.01876824, -0.01871866, -0.01874709, -0.01862934]), 'split3_test_score': array([-0.02715043, -0.02595819, -0.02644982, -0.02626011, -0.02660161,\n",
      "       -0.02599943, -0.02594265, -0.02608776, -0.02568363, -0.02584745,\n",
      "       -0.02518685, -0.02536868, -0.02532718, -0.02544499, -0.02523914,\n",
      "       -0.02554089, -0.02534694, -0.02515569, -0.02500484, -0.02483716,\n",
      "       -0.02492895, -0.02494797, -0.02481469, -0.02481401, -0.02508399,\n",
      "       -0.02491564, -0.02489244, -0.02511543, -0.02528065, -0.02525288,\n",
      "       -0.02500499, -0.02516271, -0.02447006, -0.02486626, -0.0250236 ,\n",
      "       -0.02480142, -0.02455698, -0.02469456, -0.02455084, -0.0248363 ,\n",
      "       -0.02448297, -0.02487113, -0.02442249, -0.02449424, -0.02449647,\n",
      "       -0.02466654, -0.02412204, -0.02430104, -0.02463581, -0.02443704,\n",
      "       -0.02437218, -0.02427301, -0.02470752, -0.0244051 , -0.0250359 ,\n",
      "       -0.02495791, -0.02523996, -0.02556851, -0.02504218, -0.02502569,\n",
      "       -0.02531764, -0.02484512, -0.02511229, -0.02515774, -0.02471984,\n",
      "       -0.02475845, -0.02501128, -0.02467759, -0.02446617, -0.02504205,\n",
      "       -0.02444856, -0.02443484, -0.02473599, -0.02458528, -0.02440372,\n",
      "       -0.02477852, -0.02443258, -0.0245183 , -0.02461848, -0.02452999,\n",
      "       -0.02431267, -0.02494627, -0.0252374 , -0.0250254 , -0.02531831,\n",
      "       -0.02514656, -0.02502284, -0.02510109, -0.02505636, -0.02504255,\n",
      "       -0.02454606, -0.0245422 , -0.02464156, -0.02481305, -0.02475448,\n",
      "       -0.02458771, -0.02467334, -0.02477514, -0.02454123, -0.0243742 ,\n",
      "       -0.02463329, -0.02446042, -0.02490777, -0.02440566, -0.02442574,\n",
      "       -0.0244772 , -0.02426041, -0.02469323, -0.02497761, -0.02457278,\n",
      "       -0.02434287, -0.02435516, -0.02435289, -0.02443281, -0.02435579,\n",
      "       -0.02439563, -0.0243321 , -0.0242745 , -0.02421266, -0.02406874,\n",
      "       -0.02449242, -0.02437722, -0.02458623, -0.02425962, -0.02410094,\n",
      "       -0.02425415, -0.02418485, -0.02430126, -0.02447748, -0.02433796,\n",
      "       -0.02426264, -0.0241917 , -0.0242275 , -0.02439852, -0.02428121,\n",
      "       -0.02440382, -0.02433751, -0.02445114, -0.02454971, -0.02436608,\n",
      "       -0.02437177, -0.02468184, -0.02444648, -0.02434418, -0.02451224,\n",
      "       -0.02418788, -0.02425036, -0.02435293, -0.02426704, -0.02424738,\n",
      "       -0.02440135, -0.02432556, -0.02424388, -0.02427044, -0.0242883 ,\n",
      "       -0.02428086, -0.0244074 , -0.02441662, -0.02431862, -0.02411075,\n",
      "       -0.02422679, -0.02416197, -0.02560871, -0.02572831, -0.02529057,\n",
      "       -0.02547797, -0.02569572, -0.0255318 , -0.02557128, -0.02534643,\n",
      "       -0.02520465, -0.02516013, -0.02521342, -0.02465953, -0.02543733,\n",
      "       -0.02517546, -0.0252741 , -0.02525892, -0.0250886 , -0.025038  ,\n",
      "       -0.02493706, -0.0250892 , -0.02475345, -0.0248149 , -0.02509189,\n",
      "       -0.02484651, -0.0247334 , -0.02473191, -0.02473306, -0.02470273,\n",
      "       -0.0248299 , -0.02457909, -0.02445527, -0.02485841, -0.02462077,\n",
      "       -0.02501992, -0.02474393, -0.0244851 , -0.02478769, -0.02408848,\n",
      "       -0.02435282, -0.02476304, -0.02453875, -0.02426293, -0.02458268,\n",
      "       -0.0245281 , -0.02433097, -0.02411533, -0.02445029, -0.02432749,\n",
      "       -0.02413086, -0.02466682, -0.02421034, -0.02441064, -0.02435493,\n",
      "       -0.02419932, -0.02514215, -0.02451352, -0.02464224, -0.02486427,\n",
      "       -0.02474514, -0.02472111, -0.02445777, -0.02470407, -0.02482701,\n",
      "       -0.02477592, -0.02440713, -0.02428635, -0.02486423, -0.02459055,\n",
      "       -0.02435594, -0.02430953, -0.02436578, -0.02429796, -0.02445487,\n",
      "       -0.02436422, -0.02419054, -0.02422353, -0.02433514, -0.02444052,\n",
      "       -0.02433726, -0.02407051, -0.02417513, -0.02577082, -0.02593011,\n",
      "       -0.02570469, -0.02529591, -0.02546704, -0.02560861, -0.02574997,\n",
      "       -0.02569699, -0.02560252, -0.02593787, -0.02519483, -0.02512226,\n",
      "       -0.02595525, -0.02524564, -0.02533165, -0.02523601, -0.02536859,\n",
      "       -0.02531428, -0.0251311 , -0.02501347, -0.02479331, -0.02518698,\n",
      "       -0.02484278, -0.02485507, -0.02503434, -0.02482272, -0.02485045,\n",
      "       -0.0248262 , -0.02455589, -0.02476063, -0.02517215, -0.02490115,\n",
      "       -0.02483377, -0.02492642, -0.02491739, -0.02456423, -0.02476433,\n",
      "       -0.02470448, -0.02451125, -0.02483425, -0.02464945, -0.02429817,\n",
      "       -0.02459942, -0.02483793, -0.02439895, -0.02454204, -0.02444961,\n",
      "       -0.02440598, -0.02450208, -0.02453803, -0.02426979, -0.02455947,\n",
      "       -0.02414124, -0.02433699, -0.02560719, -0.02478094, -0.02494267,\n",
      "       -0.02520226, -0.02460589, -0.0250807 , -0.02461983, -0.02479632,\n",
      "       -0.02478382, -0.02481342, -0.02458068, -0.02460773, -0.02508961,\n",
      "       -0.02453974, -0.0247406 , -0.0247161 , -0.0242347 , -0.02433105,\n",
      "       -0.02476235, -0.02457829, -0.02433572, -0.02481631, -0.02439739,\n",
      "       -0.02421923, -0.02431443, -0.02438897, -0.02433619, -0.0263347 ,\n",
      "       -0.02547191, -0.0260694 , -0.0260036 , -0.02593028, -0.0257754 ,\n",
      "       -0.02651788, -0.02584603, -0.02580417, -0.02530896, -0.02546278,\n",
      "       -0.02531144, -0.02527264, -0.02543417, -0.02549412, -0.02518703,\n",
      "       -0.02552263, -0.02540205, -0.02533668, -0.02484048, -0.0250495 ,\n",
      "       -0.02504313, -0.02503902, -0.02494795, -0.02536792, -0.02506747,\n",
      "       -0.02496311, -0.02515546, -0.02522384, -0.02523588, -0.02525136,\n",
      "       -0.02500041, -0.02492733, -0.02518484, -0.02493082, -0.02516034,\n",
      "       -0.02457385, -0.02467028, -0.02444246, -0.02469827, -0.02439403,\n",
      "       -0.02465893, -0.02446476, -0.02452107, -0.02447893, -0.02483077,\n",
      "       -0.02440351, -0.02436739, -0.02469985, -0.02397579, -0.02427332,\n",
      "       -0.02468785, -0.02452982, -0.02434242, -0.0262332 , -0.02517628,\n",
      "       -0.02493048, -0.02510788, -0.02504088, -0.02476167, -0.02502139,\n",
      "       -0.02471405, -0.02477249, -0.02493077, -0.02451573, -0.02461418,\n",
      "       -0.02418645, -0.02438191, -0.02490834, -0.02501523, -0.02452145,\n",
      "       -0.02451859, -0.02449867, -0.02423904, -0.02463085, -0.02471127,\n",
      "       -0.02498305, -0.02450844, -0.02450597, -0.02454821, -0.02414006]), 'split4_test_score': array([-0.02371469, -0.02325256, -0.02317368, -0.0235334 , -0.02274593,\n",
      "       -0.0229723 , -0.02323771, -0.02345511, -0.02295932, -0.02312296,\n",
      "       -0.02299079, -0.02329578, -0.02304144, -0.02291745, -0.02294513,\n",
      "       -0.02299134, -0.02267466, -0.02258634, -0.0229076 , -0.02280052,\n",
      "       -0.02285355, -0.02313932, -0.02304874, -0.02265292, -0.02276642,\n",
      "       -0.02262573, -0.02266075, -0.02370826, -0.02315131, -0.02280954,\n",
      "       -0.02312985, -0.0226679 , -0.02285256, -0.02289506, -0.02301055,\n",
      "       -0.02264759, -0.02291146, -0.02281872, -0.02281066, -0.02311619,\n",
      "       -0.02278204, -0.02287507, -0.02266066, -0.02251724, -0.02265373,\n",
      "       -0.02266394, -0.02262208, -0.02268665, -0.02306785, -0.02254231,\n",
      "       -0.02270846, -0.02233328, -0.02240087, -0.02252526, -0.0233135 ,\n",
      "       -0.02289684, -0.02289661, -0.02276674, -0.02292925, -0.02277967,\n",
      "       -0.02286239, -0.02265   , -0.02247474, -0.02304723, -0.02323097,\n",
      "       -0.02285403, -0.02314566, -0.02292778, -0.02275313, -0.02289104,\n",
      "       -0.02252779, -0.02253764, -0.02271561, -0.02281775, -0.02268559,\n",
      "       -0.02287425, -0.02274258, -0.02253485, -0.02294164, -0.02278408,\n",
      "       -0.02260638, -0.02202958, -0.02207688, -0.02217091, -0.0219008 ,\n",
      "       -0.0221367 , -0.02201507, -0.02222409, -0.02200282, -0.02210292,\n",
      "       -0.02204719, -0.022006  , -0.02205038, -0.02222672, -0.02218681,\n",
      "       -0.02206824, -0.02219161, -0.02203688, -0.02201073, -0.02218398,\n",
      "       -0.02216978, -0.02205396, -0.02209884, -0.02205377, -0.02207218,\n",
      "       -0.02219716, -0.02213416, -0.02207955, -0.02218244, -0.02212055,\n",
      "       -0.02215724, -0.02216285, -0.02206971, -0.02214616, -0.02233568,\n",
      "       -0.02215712, -0.02206176, -0.02230968, -0.02226875, -0.02208962,\n",
      "       -0.02204858, -0.02209682, -0.02205412, -0.02217256, -0.02204014,\n",
      "       -0.02217453, -0.02234686, -0.02229459, -0.02220045, -0.02220745,\n",
      "       -0.02230067, -0.02221263, -0.02209159, -0.0221265 , -0.02211128,\n",
      "       -0.02240391, -0.0222307 , -0.02221053, -0.02205371, -0.0221759 ,\n",
      "       -0.02215812, -0.02230137, -0.02224938, -0.02219762, -0.02208437,\n",
      "       -0.02218643, -0.02213874, -0.02204347, -0.02213826, -0.02214127,\n",
      "       -0.0222652 , -0.02217178, -0.0222881 , -0.0219544 , -0.02196889,\n",
      "       -0.0220755 , -0.02236955, -0.02215129, -0.02212484, -0.02205188,\n",
      "       -0.02200184, -0.02202825, -0.02253452, -0.02231615, -0.02246969,\n",
      "       -0.02231179, -0.02274788, -0.02235788, -0.02249662, -0.02267881,\n",
      "       -0.02242277, -0.02296425, -0.02243736, -0.02254619, -0.022723  ,\n",
      "       -0.02249862, -0.02254289, -0.02233675, -0.02219546, -0.02235488,\n",
      "       -0.02260197, -0.02255729, -0.02257459, -0.02253023, -0.02243428,\n",
      "       -0.02248698, -0.02257174, -0.02261238, -0.02237375, -0.02274564,\n",
      "       -0.02242205, -0.02226512, -0.02264225, -0.02247217, -0.02266417,\n",
      "       -0.02240111, -0.0224547 , -0.02226594, -0.02255119, -0.02262439,\n",
      "       -0.0224724 , -0.0230101 , -0.0224822 , -0.02239805, -0.02258424,\n",
      "       -0.02231468, -0.02220531, -0.02276343, -0.02283564, -0.0223699 ,\n",
      "       -0.0223121 , -0.02244706, -0.02247959, -0.02254426, -0.02233066,\n",
      "       -0.02235173, -0.0223689 , -0.02276115, -0.0222855 , -0.02252885,\n",
      "       -0.02267162, -0.02232353, -0.02262347, -0.02254599, -0.02234062,\n",
      "       -0.02271109, -0.0225125 , -0.02224328, -0.02239743, -0.02243458,\n",
      "       -0.02250636, -0.02253822, -0.02231459, -0.02246167, -0.02233945,\n",
      "       -0.02247709, -0.02234358, -0.02237907, -0.02264104, -0.02231955,\n",
      "       -0.02251404, -0.02234453, -0.02248284, -0.02347882, -0.02310221,\n",
      "       -0.02315027, -0.02311127, -0.02302705, -0.02283451, -0.02260718,\n",
      "       -0.02277466, -0.02281969, -0.0231239 , -0.0229434 , -0.0230649 ,\n",
      "       -0.02300755, -0.02301301, -0.0230317 , -0.02319349, -0.02274981,\n",
      "       -0.02244633, -0.02263715, -0.0228063 , -0.02250342, -0.02279888,\n",
      "       -0.022661  , -0.02272514, -0.02285131, -0.022569  , -0.02259684,\n",
      "       -0.02303473, -0.02323277, -0.02265664, -0.02282862, -0.02288394,\n",
      "       -0.0228053 , -0.02279356, -0.02254221, -0.02267773, -0.02322557,\n",
      "       -0.0229045 , -0.022532  , -0.02292492, -0.02260334, -0.02290309,\n",
      "       -0.02244793, -0.02259958, -0.02248814, -0.02247739, -0.02257516,\n",
      "       -0.02264888, -0.02253546, -0.02260783, -0.02241417, -0.02276868,\n",
      "       -0.02240966, -0.02249299, -0.02264273, -0.02265828, -0.02278187,\n",
      "       -0.02319814, -0.02315842, -0.02272183, -0.02253662, -0.02261909,\n",
      "       -0.02263226, -0.0229428 , -0.02272417, -0.02271744, -0.02295287,\n",
      "       -0.02239579, -0.02279116, -0.02288306, -0.02261948, -0.02271629,\n",
      "       -0.02288303, -0.02237074, -0.0226358 , -0.02263504, -0.02279621,\n",
      "       -0.02263052, -0.02277185, -0.02249971, -0.0224642 , -0.02337386,\n",
      "       -0.02329282, -0.02302396, -0.02304508, -0.02297258, -0.02307437,\n",
      "       -0.02343529, -0.02311139, -0.02276625, -0.02286159, -0.02326938,\n",
      "       -0.02307324, -0.02279096, -0.02287178, -0.0231015 , -0.02289556,\n",
      "       -0.02243657, -0.02265412, -0.02312229, -0.02295628, -0.02271869,\n",
      "       -0.0231862 , -0.02270784, -0.02284228, -0.02274478, -0.02284303,\n",
      "       -0.02247365, -0.02280314, -0.02326726, -0.02262842, -0.02290358,\n",
      "       -0.02315113, -0.02275674, -0.022464  , -0.02289611, -0.02257219,\n",
      "       -0.02311692, -0.02286531, -0.02302784, -0.02238021, -0.02267999,\n",
      "       -0.02278266, -0.02267533, -0.02252246, -0.02277617, -0.02301454,\n",
      "       -0.0224557 , -0.02276253, -0.02262469, -0.02255953, -0.02239738,\n",
      "       -0.02275236, -0.02259827, -0.02256052, -0.02354446, -0.02342745,\n",
      "       -0.02300231, -0.02257812, -0.0230664 , -0.02280335, -0.02321001,\n",
      "       -0.02270393, -0.02255924, -0.02295195, -0.02302082, -0.02298617,\n",
      "       -0.02299143, -0.02277663, -0.02285238, -0.02286676, -0.02237427,\n",
      "       -0.02259809, -0.02279343, -0.02252459, -0.02267294, -0.0224894 ,\n",
      "       -0.022632  , -0.02259718, -0.02249151, -0.02262599, -0.02248858]), 'mean_test_score': array([-0.02250033, -0.02195876, -0.02196078, -0.02202315, -0.02195036,\n",
      "       -0.02175897, -0.02171045, -0.02183712, -0.02156556, -0.02143704,\n",
      "       -0.02128502, -0.02135522, -0.02139951, -0.0214146 , -0.02124782,\n",
      "       -0.02142726, -0.02117105, -0.0210719 , -0.02091656, -0.02078198,\n",
      "       -0.0209508 , -0.02092353, -0.02089366, -0.02085547, -0.02111827,\n",
      "       -0.02086829, -0.02084983, -0.02148979, -0.02150683, -0.02129545,\n",
      "       -0.0214671 , -0.02103505, -0.02109989, -0.02105905, -0.02096955,\n",
      "       -0.02088899, -0.02098666, -0.020947  , -0.02084422, -0.0208688 ,\n",
      "       -0.02073172, -0.02080248, -0.02073922, -0.02075904, -0.02068062,\n",
      "       -0.02067055, -0.02054925, -0.0205105 , -0.02070683, -0.02053375,\n",
      "       -0.02053728, -0.02046866, -0.02052264, -0.02043675, -0.02147376,\n",
      "       -0.02117774, -0.02122505, -0.02142868, -0.02115979, -0.02113852,\n",
      "       -0.0213696 , -0.021043  , -0.02087007, -0.02092101, -0.02111472,\n",
      "       -0.02090525, -0.02117129, -0.0209771 , -0.02085908, -0.02085452,\n",
      "       -0.02055254, -0.02060067, -0.02074304, -0.02064468, -0.02047662,\n",
      "       -0.02089501, -0.02060193, -0.02049988, -0.02059781, -0.02055477,\n",
      "       -0.02047991, -0.02039795, -0.02049004, -0.02052905, -0.02059784,\n",
      "       -0.02062397, -0.02054971, -0.02064626, -0.02049134, -0.0205624 ,\n",
      "       -0.0203872 , -0.02027698, -0.02027861, -0.02045121, -0.02034243,\n",
      "       -0.02025109, -0.02031016, -0.02030233, -0.02024634, -0.02014281,\n",
      "       -0.02028492, -0.02020008, -0.02034595, -0.02021686, -0.02022696,\n",
      "       -0.02025698, -0.02013573, -0.02028084, -0.02030471, -0.02017763,\n",
      "       -0.02011871, -0.02012725, -0.02009287, -0.02011591, -0.0201802 ,\n",
      "       -0.02020221, -0.02011841, -0.02020115, -0.0200939 , -0.02002735,\n",
      "       -0.02011233, -0.02006753, -0.02009965, -0.02010785, -0.02003119,\n",
      "       -0.02011465, -0.02011181, -0.02012599, -0.02012715, -0.02006016,\n",
      "       -0.0201573 , -0.02003209, -0.02001576, -0.0201052 , -0.02004175,\n",
      "       -0.02028157, -0.0201592 , -0.0201696 , -0.02013827, -0.02012295,\n",
      "       -0.02010399, -0.02029857, -0.02014832, -0.02013234, -0.0202058 ,\n",
      "       -0.02012439, -0.02004467, -0.02010761, -0.02009087, -0.02007544,\n",
      "       -0.02014175, -0.02010823, -0.02009575, -0.02001494, -0.02004182,\n",
      "       -0.02002222, -0.02018404, -0.02012977, -0.02007199, -0.02004299,\n",
      "       -0.01998959, -0.02003698, -0.02150078, -0.02124169, -0.02121368,\n",
      "       -0.02110706, -0.0213403 , -0.02125143, -0.02128801, -0.02126718,\n",
      "       -0.02115828, -0.0211857 , -0.02108227, -0.02089491, -0.02120138,\n",
      "       -0.02114122, -0.02097507, -0.02108538, -0.02092797, -0.02080617,\n",
      "       -0.02087801, -0.02084843, -0.02065914, -0.02072097, -0.02072151,\n",
      "       -0.02071524, -0.02065659, -0.02069626, -0.02062178, -0.02078069,\n",
      "       -0.02074222, -0.02059234, -0.02074958, -0.02078715, -0.02075782,\n",
      "       -0.02086606, -0.02078295, -0.02052239, -0.02074219, -0.02051885,\n",
      "       -0.02047989, -0.02085068, -0.02060338, -0.02042039, -0.02054752,\n",
      "       -0.02035967, -0.02036308, -0.02050663, -0.02051856, -0.02031665,\n",
      "       -0.02043774, -0.02039052, -0.0204082 , -0.02047516, -0.02034886,\n",
      "       -0.02036567, -0.02086725, -0.02069809, -0.02065291, -0.02060609,\n",
      "       -0.02068483, -0.020723  , -0.02078636, -0.02062833, -0.02069744,\n",
      "       -0.02071688, -0.02064811, -0.02044892, -0.02082596, -0.02066874,\n",
      "       -0.02046787, -0.02042644, -0.0203871 , -0.02045071, -0.02040768,\n",
      "       -0.02047003, -0.02033031, -0.02040817, -0.0204489 , -0.0203731 ,\n",
      "       -0.0202743 , -0.02029685, -0.0202896 , -0.02204371, -0.02170606,\n",
      "       -0.02172015, -0.02166008, -0.02174505, -0.02160593, -0.02148879,\n",
      "       -0.02168822, -0.02150205, -0.0217111 , -0.02130574, -0.02118026,\n",
      "       -0.02145331, -0.02133096, -0.02128549, -0.02125321, -0.02122591,\n",
      "       -0.02101486, -0.02092975, -0.02096   , -0.02078295, -0.02097883,\n",
      "       -0.02085569, -0.02076076, -0.02101345, -0.02079183, -0.02069332,\n",
      "       -0.02108654, -0.02131479, -0.0209599 , -0.02126179, -0.02095856,\n",
      "       -0.02098891, -0.02100367, -0.02087824, -0.02083588, -0.02094912,\n",
      "       -0.02097585, -0.02068571, -0.02109213, -0.02072527, -0.02069923,\n",
      "       -0.02065525, -0.02072432, -0.0205066 , -0.02073021, -0.02054658,\n",
      "       -0.0205333 , -0.02057295, -0.02047207, -0.02039574, -0.02070992,\n",
      "       -0.02044789, -0.02040974, -0.02134408, -0.02110391, -0.020988  ,\n",
      "       -0.02144568, -0.02104658, -0.02102835, -0.02083494, -0.02085226,\n",
      "       -0.02085857, -0.02100498, -0.02074042, -0.02072812, -0.02094475,\n",
      "       -0.02077018, -0.02080978, -0.02076242, -0.02063859, -0.02057485,\n",
      "       -0.0207058 , -0.02055571, -0.02053954, -0.02068643, -0.02055496,\n",
      "       -0.02043038, -0.02047932, -0.02044591, -0.02040612, -0.02226829,\n",
      "       -0.0219161 , -0.02184371, -0.02186419, -0.02177086, -0.02171998,\n",
      "       -0.02199683, -0.02152961, -0.02154288, -0.02135496, -0.02142151,\n",
      "       -0.02140431, -0.02136797, -0.02136661, -0.02141511, -0.02127389,\n",
      "       -0.02110921, -0.0211517 , -0.02111206, -0.02102953, -0.02088348,\n",
      "       -0.02120902, -0.02097543, -0.02092731, -0.02102492, -0.02083926,\n",
      "       -0.02079982, -0.02138249, -0.02134567, -0.02126046, -0.02109725,\n",
      "       -0.02115899, -0.02099366, -0.02101775, -0.02103211, -0.02085642,\n",
      "       -0.02105505, -0.02089284, -0.02081242, -0.02088906, -0.02080471,\n",
      "       -0.02083247, -0.02089324, -0.0207247 , -0.02064862, -0.02069582,\n",
      "       -0.02058354, -0.02054015, -0.02075134, -0.02042753, -0.02047987,\n",
      "       -0.02066102, -0.02047417, -0.02049879, -0.02167589, -0.02144585,\n",
      "       -0.02118626, -0.02118866, -0.02109861, -0.0210151 , -0.02109428,\n",
      "       -0.02086298, -0.02081255, -0.02106416, -0.02095094, -0.02088375,\n",
      "       -0.02084542, -0.02093178, -0.02088152, -0.02093868, -0.02066076,\n",
      "       -0.02073047, -0.02045918, -0.02054732, -0.02058998, -0.02072662,\n",
      "       -0.0207328 , -0.02057534, -0.0204869 , -0.02049886, -0.02040386]), 'std_test_score': array([0.00278611, 0.00249658, 0.00261131, 0.00260159, 0.00267658,\n",
      "       0.00253919, 0.00262776, 0.00260293, 0.00249149, 0.00267369,\n",
      "       0.00244556, 0.00259475, 0.00243716, 0.00247819, 0.00252093,\n",
      "       0.00253355, 0.00250719, 0.00250747, 0.0026611 , 0.00261371,\n",
      "       0.00255345, 0.0026616 , 0.0025979 , 0.00250058, 0.00244172,\n",
      "       0.00253524, 0.00254009, 0.0024511 , 0.00231935, 0.00238406,\n",
      "       0.00224154, 0.00249024, 0.00218945, 0.00240993, 0.00258951,\n",
      "       0.00244833, 0.00235035, 0.00240047, 0.00241132, 0.00263233,\n",
      "       0.00249004, 0.0026163 , 0.00241251, 0.00234964, 0.00248382,\n",
      "       0.00256535, 0.00240163, 0.00253293, 0.00266813, 0.00251797,\n",
      "       0.00254415, 0.00245653, 0.00261162, 0.00257134, 0.00227942,\n",
      "       0.00236403, 0.00245071, 0.00242192, 0.00241095, 0.00238288,\n",
      "       0.00236169, 0.00232331, 0.00255687, 0.00272764, 0.00241025,\n",
      "       0.0024779 , 0.002482  , 0.00243131, 0.00235341, 0.00270841,\n",
      "       0.0025214 , 0.00248448, 0.00258166, 0.00260798, 0.00260231,\n",
      "       0.00248605, 0.00253119, 0.0025769 , 0.00268155, 0.00262435,\n",
      "       0.002537  , 0.00271291, 0.00279884, 0.00271017, 0.00271812,\n",
      "       0.0027036 , 0.00264049, 0.0026878 , 0.0027081 , 0.00265712,\n",
      "       0.002594  , 0.00265932, 0.00269588, 0.00269492, 0.00273274,\n",
      "       0.00268404, 0.00272949, 0.00274333, 0.00264971, 0.00271229,\n",
      "       0.00269536, 0.00265554, 0.00276474, 0.00260473, 0.002631  ,\n",
      "       0.00265892, 0.00264178, 0.0027204 , 0.00287789, 0.00273921,\n",
      "       0.00269453, 0.00270296, 0.00269833, 0.0027311 , 0.00270636,\n",
      "       0.00264818, 0.00266033, 0.00264303, 0.00269046, 0.00261188,\n",
      "       0.002747  , 0.00274695, 0.00280671, 0.00268658, 0.00262527,\n",
      "       0.00267328, 0.00269416, 0.00271402, 0.00276419, 0.00274406,\n",
      "       0.00266875, 0.00269557, 0.00270968, 0.00271472, 0.00272295,\n",
      "       0.0026807 , 0.00268935, 0.00271876, 0.00275897, 0.00270843,\n",
      "       0.0027392 , 0.00277641, 0.00274777, 0.00271867, 0.00269709,\n",
      "       0.00263452, 0.0027137 , 0.00267195, 0.00268278, 0.00268502,\n",
      "       0.00274411, 0.00270273, 0.00270938, 0.00267758, 0.00266739,\n",
      "       0.00271971, 0.00273885, 0.00272868, 0.0027197 , 0.00262404,\n",
      "       0.00270895, 0.00263455, 0.00238572, 0.00258867, 0.00243895,\n",
      "       0.00252406, 0.00259106, 0.00249942, 0.00251008, 0.00249968,\n",
      "       0.00239599, 0.00250435, 0.00245067, 0.00237912, 0.00253923,\n",
      "       0.00241294, 0.00259388, 0.0024547 , 0.00249236, 0.00258466,\n",
      "       0.00255696, 0.00260053, 0.00259866, 0.00255908, 0.00267958,\n",
      "       0.00256269, 0.00263099, 0.00258186, 0.00255614, 0.00249068,\n",
      "       0.00251367, 0.00246452, 0.00239833, 0.00251141, 0.0024667 ,\n",
      "       0.00247541, 0.00243765, 0.00245114, 0.00252401, 0.00240373,\n",
      "       0.00249354, 0.00257274, 0.00249137, 0.00249052, 0.00259525,\n",
      "       0.00265437, 0.00251922, 0.00246999, 0.00262479, 0.00258632,\n",
      "       0.00239713, 0.00272415, 0.00250036, 0.00256167, 0.00256256,\n",
      "       0.00248155, 0.00253224, 0.00248495, 0.00243479, 0.00264766,\n",
      "       0.00258131, 0.00243518, 0.0024049 , 0.00256779, 0.00251595,\n",
      "       0.00257866, 0.00239886, 0.00243529, 0.00244076, 0.00246395,\n",
      "       0.00252891, 0.00252849, 0.0025332 , 0.00249618, 0.00257081,\n",
      "       0.00252837, 0.00250032, 0.00249823, 0.00260292, 0.0025889 ,\n",
      "       0.00267443, 0.00246879, 0.00259245, 0.00233917, 0.00253199,\n",
      "       0.00244625, 0.0022251 , 0.00225503, 0.00241843, 0.00247439,\n",
      "       0.00236115, 0.00244604, 0.00254889, 0.00243546, 0.00252213,\n",
      "       0.00271178, 0.00246907, 0.00254213, 0.00260594, 0.0025137 ,\n",
      "       0.0025747 , 0.00263624, 0.00254444, 0.00249817, 0.00257953,\n",
      "       0.00249451, 0.0026331 , 0.00254909, 0.00254221, 0.00263497,\n",
      "       0.00243798, 0.00216087, 0.00236416, 0.00239193, 0.0025227 ,\n",
      "       0.00243088, 0.00245727, 0.00246674, 0.0023678 , 0.00254911,\n",
      "       0.00242205, 0.00244486, 0.00242032, 0.00249448, 0.0024554 ,\n",
      "       0.00250408, 0.00257897, 0.0025046 , 0.00239733, 0.00253819,\n",
      "       0.00254128, 0.0025364 , 0.00264707, 0.00251603, 0.00249885,\n",
      "       0.00242732, 0.00256835, 0.00246772, 0.00227717, 0.00246068,\n",
      "       0.00234449, 0.00237511, 0.00247708, 0.00234297, 0.00246735,\n",
      "       0.0024487 , 0.00243272, 0.00246032, 0.00250079, 0.00266644,\n",
      "       0.00234772, 0.00251887, 0.00258523, 0.00239821, 0.00250515,\n",
      "       0.00263894, 0.00252538, 0.00250114, 0.00259435, 0.0025934 ,\n",
      "       0.00253291, 0.00257391, 0.00257945, 0.00254919, 0.00238432,\n",
      "       0.00220028, 0.00247426, 0.00238088, 0.00248297, 0.00249851,\n",
      "       0.00272888, 0.00261966, 0.00255192, 0.00244908, 0.00256559,\n",
      "       0.00244184, 0.0023896 , 0.00250651, 0.00256143, 0.00242387,\n",
      "       0.00259173, 0.00256825, 0.00268597, 0.00248155, 0.00261713,\n",
      "       0.00251924, 0.002544  , 0.00256745, 0.0027194 , 0.00270125,\n",
      "       0.00256242, 0.00226249, 0.00248392, 0.00233966, 0.00255536,\n",
      "       0.00249494, 0.00245471, 0.00246212, 0.00247781, 0.0026142 ,\n",
      "       0.00239709, 0.00244805, 0.00245529, 0.00233184, 0.00231802,\n",
      "       0.00245789, 0.00227751, 0.00241423, 0.00254607, 0.00274511,\n",
      "       0.00246066, 0.00257224, 0.00248235, 0.00241552, 0.00244497,\n",
      "       0.00262255, 0.00262784, 0.00250607, 0.00280884, 0.00245237,\n",
      "       0.00237664, 0.00232229, 0.00253329, 0.00236902, 0.00259592,\n",
      "       0.00243667, 0.00246814, 0.00244863, 0.0023698 , 0.00248779,\n",
      "       0.00229586, 0.00227047, 0.00256076, 0.00256485, 0.00243174,\n",
      "       0.00242102, 0.00272099, 0.00241794, 0.0026174 , 0.00251064,\n",
      "       0.00266172, 0.00255904, 0.00256925, 0.00264313, 0.00247095]), 'rank_test_score': array([405, 399, 400, 402, 398, 392, 387, 394, 381, 368, 345, 356, 361,\n",
      "       363, 338, 366, 325, 304, 262, 213, 273, 264, 258, 238, 318, 246,\n",
      "       234, 375, 378, 348, 372, 298, 312, 302, 278, 254, 284, 271, 231,\n",
      "       247, 198, 220, 200, 208, 173, 172, 138, 124, 184, 131, 132, 106,\n",
      "       128,  96, 373, 327, 335, 367, 324, 319, 359, 299, 248, 263, 317,\n",
      "       261, 326, 282, 242, 237, 140, 153, 204, 161, 111, 260, 154, 121,\n",
      "       151, 141, 115,  85, 117, 129, 152, 158, 139, 162, 118, 144,  82,\n",
      "        61,  62, 103,  74,  58,  71,  69,  57,  43,  65,  51,  75,  55,\n",
      "        56,  59,  40,  63,  70,  48,  32,  37,  18,  30,  49,  53,  31,\n",
      "        52,  19,   5,  28,  14,  21,  25,   6,  29,  27,  35,  36,  13,\n",
      "        45,   7,   3,  23,   9,  64,  46,  47,  41,  33,  22,  68,  44,\n",
      "        39,  54,  34,  12,  24,  17,  16,  42,  26,  20,   2,  10,   4,\n",
      "        50,  38,  15,  11,   1,   8, 376, 337, 334, 314, 352, 339, 347,\n",
      "       343, 322, 329, 305, 259, 332, 320, 279, 306, 266, 222, 249, 233,\n",
      "       168, 188, 189, 186, 167, 179, 157, 212, 203, 150, 205, 217, 207,\n",
      "       244, 214, 127, 202, 126, 114, 235, 155,  92, 137,  77,  78, 123,\n",
      "       125,  72,  97,  83,  90, 110,  76,  79, 245, 181, 165, 156, 174,\n",
      "       190, 216, 159, 180, 187, 163, 101, 226, 171, 105,  93,  81, 102,\n",
      "        88, 107,  73,  89, 100,  80,  60,  67,  66, 403, 386, 390, 383,\n",
      "       391, 382, 374, 385, 377, 388, 349, 328, 371, 351, 346, 340, 336,\n",
      "       291, 267, 277, 215, 283, 239, 209, 290, 218, 177, 307, 350, 276,\n",
      "       342, 275, 286, 288, 250, 229, 272, 281, 175, 308, 193, 182, 166,\n",
      "       191, 122, 196, 135, 130, 145, 108,  84, 185,  99,  91, 353, 313,\n",
      "       285, 369, 300, 295, 228, 236, 241, 289, 201, 195, 270, 211, 223,\n",
      "       210, 160, 146, 183, 143, 133, 176, 142,  95, 112,  98,  87, 404,\n",
      "       397, 395, 396, 393, 389, 401, 379, 380, 355, 365, 362, 358, 357,\n",
      "       364, 344, 315, 321, 316, 296, 252, 333, 280, 265, 294, 230, 219,\n",
      "       360, 354, 341, 310, 323, 287, 293, 297, 240, 301, 256, 224, 255,\n",
      "       221, 227, 257, 192, 164, 178, 148, 134, 206,  94, 113, 170, 109,\n",
      "       119, 384, 370, 330, 331, 311, 292, 309, 243, 225, 303, 274, 253,\n",
      "       232, 268, 251, 269, 169, 197, 104, 136, 149, 194, 199, 147, 116,\n",
      "       120,  86]), 'split0_train_score': array([-0.00363165, -0.00365208, -0.00351441, -0.00509441, -0.0049814 ,\n",
      "       -0.00497452, -0.00718031, -0.00712165, -0.0070928 , -0.00648176,\n",
      "       -0.00615529, -0.0062614 , -0.00681547, -0.00670179, -0.00662798,\n",
      "       -0.00891837, -0.00873869, -0.00867291, -0.01005883, -0.00983685,\n",
      "       -0.00990658, -0.01007668, -0.00989373, -0.00989839, -0.01047645,\n",
      "       -0.01054558, -0.01038802, -0.00362783, -0.00351627, -0.00349362,\n",
      "       -0.00550436, -0.00565238, -0.00550818, -0.00804796, -0.00789708,\n",
      "       -0.00780967, -0.00711786, -0.00696018, -0.00688644, -0.00730244,\n",
      "       -0.00739183, -0.00736655, -0.00979811, -0.00960773, -0.00951127,\n",
      "       -0.01110685, -0.0108937 , -0.01078186, -0.01083558, -0.01088034,\n",
      "       -0.01082054, -0.01151592, -0.01132741, -0.01136706, -0.00366251,\n",
      "       -0.00357587, -0.00353025, -0.00568051, -0.00541377, -0.00545516,\n",
      "       -0.00789209, -0.00783475, -0.00779342, -0.00717233, -0.00689629,\n",
      "       -0.00687961, -0.00755929, -0.00737571, -0.00729066, -0.00967938,\n",
      "       -0.00961168, -0.009562  , -0.01105407, -0.01096086, -0.01081696,\n",
      "       -0.01085535, -0.01093796, -0.0109013 , -0.01139325, -0.0113262 ,\n",
      "       -0.01131318, -0.01694538, -0.01677743, -0.0168653 , -0.01699233,\n",
      "       -0.0170407 , -0.01695173, -0.01712209, -0.01708364, -0.01716241,\n",
      "       -0.01697469, -0.01692993, -0.01692753, -0.01692825, -0.01703238,\n",
      "       -0.01692625, -0.01721481, -0.01727215, -0.01715414, -0.01719634,\n",
      "       -0.01717421, -0.01717397, -0.01722466, -0.01716926, -0.0171742 ,\n",
      "       -0.01722971, -0.01720301, -0.01718799, -0.01729337, -0.01730239,\n",
      "       -0.0172311 , -0.01730173, -0.01746131, -0.01746413, -0.01761254,\n",
      "       -0.0175744 , -0.01756709, -0.01751903, -0.0174963 , -0.01749819,\n",
      "       -0.0176721 , -0.01760347, -0.0175141 , -0.01778812, -0.01776158,\n",
      "       -0.01770349, -0.01771978, -0.01783295, -0.01786727, -0.01798333,\n",
      "       -0.01785641, -0.01786103, -0.01795756, -0.01780266, -0.01791126,\n",
      "       -0.0172252 , -0.01725073, -0.01723023, -0.01739023, -0.01746246,\n",
      "       -0.0174464 , -0.01760455, -0.01752117, -0.01758527, -0.01763718,\n",
      "       -0.01766579, -0.01754369, -0.01766629, -0.01749557, -0.01754618,\n",
      "       -0.01767084, -0.01779152, -0.01771499, -0.0179567 , -0.01783702,\n",
      "       -0.01786118, -0.01794613, -0.01783064, -0.01786405, -0.01808072,\n",
      "       -0.01780429, -0.01785169, -0.00976994, -0.00972815, -0.00956739,\n",
      "       -0.01054616, -0.01032346, -0.01035582, -0.0116063 , -0.01157337,\n",
      "       -0.01171144, -0.01039106, -0.01054346, -0.01048344, -0.01099773,\n",
      "       -0.0108536 , -0.01090735, -0.01220473, -0.01214452, -0.0121096 ,\n",
      "       -0.01235251, -0.01220678, -0.01232985, -0.01241523, -0.01228781,\n",
      "       -0.01225395, -0.01264927, -0.01272809, -0.01265261, -0.00964399,\n",
      "       -0.00936623, -0.0093435 , -0.01068396, -0.01067623, -0.0104702 ,\n",
      "       -0.01201984, -0.01166728, -0.01184702, -0.01072785, -0.01101991,\n",
      "       -0.01085028, -0.01141889, -0.01110158, -0.01120984, -0.01240411,\n",
      "       -0.01264715, -0.01258357, -0.01292473, -0.01304074, -0.01301253,\n",
      "       -0.01298048, -0.01307951, -0.01294337, -0.01329167, -0.01334823,\n",
      "       -0.01324855, -0.00932286, -0.00933762, -0.00932208, -0.01068609,\n",
      "       -0.01050999, -0.01042189, -0.01204761, -0.01191439, -0.01184991,\n",
      "       -0.01101766, -0.01096597, -0.01102037, -0.01135836, -0.01129346,\n",
      "       -0.01120857, -0.01275941, -0.01263267, -0.01242903, -0.01308097,\n",
      "       -0.01309497, -0.01308832, -0.01316926, -0.01297507, -0.01297167,\n",
      "       -0.01355222, -0.01339716, -0.01331701, -0.00553954, -0.00547867,\n",
      "       -0.00546274, -0.0068701 , -0.00676312, -0.00669656, -0.00858124,\n",
      "       -0.00858124, -0.00848301, -0.00751485, -0.00737179, -0.00740544,\n",
      "       -0.00783772, -0.00791758, -0.00784101, -0.0098024 , -0.00960005,\n",
      "       -0.00962321, -0.01062572, -0.01034703, -0.01026224, -0.01056304,\n",
      "       -0.01040358, -0.01041384, -0.01099359, -0.01090993, -0.01094204,\n",
      "       -0.00525665, -0.00513789, -0.00512537, -0.00717901, -0.00695108,\n",
      "       -0.00685294, -0.00907308, -0.00901623, -0.00893598, -0.00787072,\n",
      "       -0.00784173, -0.00777143, -0.00851386, -0.00831379, -0.00824364,\n",
      "       -0.01021863, -0.01033234, -0.01021072, -0.01130554, -0.01122575,\n",
      "       -0.01131662, -0.01146232, -0.01125088, -0.01116723, -0.01189498,\n",
      "       -0.01171306, -0.01172904, -0.00513821, -0.0051483 , -0.00503268,\n",
      "       -0.00700121, -0.00683286, -0.00681591, -0.00903585, -0.00907987,\n",
      "       -0.00901591, -0.00786595, -0.00775265, -0.00781981, -0.00841073,\n",
      "       -0.00829865, -0.00820691, -0.01057579, -0.01032709, -0.01030095,\n",
      "       -0.01131929, -0.01129549, -0.01118018, -0.0113653 , -0.01127089,\n",
      "       -0.0111588 , -0.01170824, -0.01169591, -0.01167381, -0.00416616,\n",
      "       -0.00411209, -0.00392083, -0.0055354 , -0.00559443, -0.00544228,\n",
      "       -0.00752357, -0.00740441, -0.00746634, -0.00664481, -0.00647177,\n",
      "       -0.00636864, -0.00699722, -0.00696236, -0.00691347, -0.00877986,\n",
      "       -0.00881411, -0.00876099, -0.01003611, -0.0100412 , -0.00992335,\n",
      "       -0.00992312, -0.01005276, -0.00986191, -0.01052461, -0.01050076,\n",
      "       -0.01042378, -0.00408618, -0.00387936, -0.00373462, -0.00602241,\n",
      "       -0.00585892, -0.00580876, -0.00817958, -0.00812478, -0.00802142,\n",
      "       -0.00720987, -0.00707127, -0.00706138, -0.00767016, -0.00767811,\n",
      "       -0.00745332, -0.00982115, -0.00962696, -0.00958176, -0.01094838,\n",
      "       -0.0109404 , -0.01082094, -0.0109785 , -0.0109434 , -0.01089833,\n",
      "       -0.01146631, -0.01146609, -0.01140673, -0.00395544, -0.00389995,\n",
      "       -0.0038642 , -0.00582699, -0.00590786, -0.00584608, -0.00811476,\n",
      "       -0.00812734, -0.00812072, -0.00714587, -0.00707484, -0.00694435,\n",
      "       -0.00774137, -0.00750198, -0.00759198, -0.0097793 , -0.00969564,\n",
      "       -0.0096566 , -0.0110298 , -0.01095445, -0.01090633, -0.0111378 ,\n",
      "       -0.01090244, -0.01088029, -0.01149761, -0.01136015, -0.01138569]), 'split1_train_score': array([-0.00384458, -0.00358025, -0.00362281, -0.00507225, -0.00515584,\n",
      "       -0.00501381, -0.00714844, -0.0070484 , -0.00702866, -0.00643011,\n",
      "       -0.00613162, -0.00617252, -0.00671744, -0.00676059, -0.00665472,\n",
      "       -0.00872156, -0.00863953, -0.00864262, -0.009911  , -0.00994654,\n",
      "       -0.00980538, -0.00993512, -0.01000594, -0.00981187, -0.01051223,\n",
      "       -0.01039718, -0.01030408, -0.00380074, -0.00358634, -0.00346048,\n",
      "       -0.00554368, -0.00551574, -0.00543478, -0.00782105, -0.00774535,\n",
      "       -0.00769523, -0.00702457, -0.00695284, -0.00690784, -0.00732316,\n",
      "       -0.00754999, -0.00738159, -0.00943146, -0.00950797, -0.00951374,\n",
      "       -0.01067663, -0.01084857, -0.01075123, -0.01093872, -0.01085298,\n",
      "       -0.01070797, -0.01124241, -0.01127753, -0.01125132, -0.00377861,\n",
      "       -0.00367636, -0.00353331, -0.0056952 , -0.0055459 , -0.0054016 ,\n",
      "       -0.00799335, -0.00777234, -0.00776017, -0.00693448, -0.00691086,\n",
      "       -0.00686404, -0.00758071, -0.00748425, -0.00731827, -0.00969489,\n",
      "       -0.00949459, -0.00941566, -0.01089175, -0.01081704, -0.01074055,\n",
      "       -0.01084733, -0.01069855, -0.01073625, -0.01143619, -0.0112166 ,\n",
      "       -0.01130911, -0.01619069, -0.01617481, -0.01613726, -0.01631724,\n",
      "       -0.01620368, -0.0162625 , -0.01647551, -0.01637638, -0.01646014,\n",
      "       -0.01622762, -0.01620603, -0.01615905, -0.01627449, -0.01616665,\n",
      "       -0.01617563, -0.01643273, -0.01645664, -0.01643263, -0.01645559,\n",
      "       -0.01648227, -0.0165048 , -0.01649904, -0.01648322, -0.01651576,\n",
      "       -0.01671347, -0.01658597, -0.01652456, -0.016944  , -0.01663817,\n",
      "       -0.01679626, -0.01699722, -0.01710486, -0.01690097, -0.0172009 ,\n",
      "       -0.01717981, -0.01711601, -0.01700642, -0.01695321, -0.01707649,\n",
      "       -0.01709024, -0.01708644, -0.01705727, -0.01737212, -0.01733728,\n",
      "       -0.01731213, -0.01741721, -0.01734626, -0.01742245, -0.01751593,\n",
      "       -0.01748875, -0.01741479, -0.01757641, -0.01753736, -0.01744168,\n",
      "       -0.01666264, -0.01675192, -0.01684499, -0.01704435, -0.01688263,\n",
      "       -0.01694884, -0.01719056, -0.0172148 , -0.01712092, -0.01710404,\n",
      "       -0.01701924, -0.01709088, -0.01715027, -0.01713936, -0.01706585,\n",
      "       -0.01726155, -0.01732009, -0.0172995 , -0.01758088, -0.01729381,\n",
      "       -0.01744575, -0.01744115, -0.01734223, -0.01740616, -0.017534  ,\n",
      "       -0.01737475, -0.01744399, -0.0092051 , -0.00896625, -0.00903654,\n",
      "       -0.00985782, -0.00976614, -0.00973985, -0.0109258 , -0.01091276,\n",
      "       -0.01088576, -0.00996754, -0.01000349, -0.0098515 , -0.01040614,\n",
      "       -0.01034953, -0.01012246, -0.01149669, -0.0113645 , -0.01135764,\n",
      "       -0.01203203, -0.01181572, -0.0118684 , -0.01181554, -0.01187039,\n",
      "       -0.01188304, -0.01237509, -0.01218701, -0.01212495, -0.00908888,\n",
      "       -0.00917631, -0.00902685, -0.01012919, -0.01014715, -0.01011571,\n",
      "       -0.01159562, -0.01125403, -0.01143821, -0.01057153, -0.01063034,\n",
      "       -0.01070992, -0.01101945, -0.01086207, -0.01088509, -0.01227289,\n",
      "       -0.0122354 , -0.01219976, -0.01276703, -0.01265878, -0.01277012,\n",
      "       -0.01267365, -0.01276014, -0.01260505, -0.01311345, -0.01304201,\n",
      "       -0.0128644 , -0.0094541 , -0.00913523, -0.00905979, -0.01034789,\n",
      "       -0.01019008, -0.01026282, -0.01156156, -0.01135617, -0.01140571,\n",
      "       -0.01055081, -0.01061385, -0.01052942, -0.01115315, -0.01087952,\n",
      "       -0.01089902, -0.01219766, -0.01211897, -0.01214118, -0.01277225,\n",
      "       -0.0127863 , -0.01260376, -0.0130393 , -0.01263061, -0.01266404,\n",
      "       -0.01318316, -0.01307362, -0.01300979, -0.00504557, -0.00523218,\n",
      "       -0.00504007, -0.00645382, -0.00643173, -0.00628665, -0.00793159,\n",
      "       -0.0082941 , -0.00821658, -0.00716628, -0.00706704, -0.00701596,\n",
      "       -0.0074096 , -0.00748734, -0.00753268, -0.00945212, -0.00935301,\n",
      "       -0.0092569 , -0.01035987, -0.01025628, -0.01016765, -0.01024788,\n",
      "       -0.01020373, -0.01019072, -0.01085379, -0.01058163, -0.01074679,\n",
      "       -0.00509671, -0.00497677, -0.00491532, -0.00673657, -0.00667663,\n",
      "       -0.00662502, -0.00860169, -0.00871249, -0.00866291, -0.00775999,\n",
      "       -0.00771058, -0.00769989, -0.00823552, -0.00827885, -0.00817696,\n",
      "       -0.01021182, -0.00999282, -0.01003162, -0.01114507, -0.01103438,\n",
      "       -0.01107092, -0.01114939, -0.01104049, -0.01102504, -0.01168268,\n",
      "       -0.01149536, -0.01138654, -0.00508261, -0.0048809 , -0.0050052 ,\n",
      "       -0.00669116, -0.00673549, -0.00665197, -0.00874635, -0.00884367,\n",
      "       -0.008562  , -0.00794595, -0.00763714, -0.00769318, -0.00822375,\n",
      "       -0.00815322, -0.00817999, -0.01025667, -0.01009485, -0.00998218,\n",
      "       -0.01114304, -0.01097399, -0.01094482, -0.01105961, -0.01103795,\n",
      "       -0.01110177, -0.01145439, -0.01142957, -0.01146748, -0.00402054,\n",
      "       -0.0038813 , -0.00390685, -0.00556679, -0.00531939, -0.00524593,\n",
      "       -0.00725466, -0.00733217, -0.00722753, -0.00632415, -0.00637366,\n",
      "       -0.0063295 , -0.00706098, -0.00689161, -0.00673269, -0.00882077,\n",
      "       -0.00883502, -0.00873221, -0.00984908, -0.00992839, -0.00982889,\n",
      "       -0.00999657, -0.00983022, -0.00987588, -0.01048852, -0.01043587,\n",
      "       -0.01041356, -0.00379792, -0.00391381, -0.00379002, -0.00599118,\n",
      "       -0.00575876, -0.00566896, -0.00794197, -0.00794056, -0.00791537,\n",
      "       -0.00726026, -0.00703739, -0.00693648, -0.00748089, -0.00756655,\n",
      "       -0.00745674, -0.00977837, -0.00948603, -0.00949916, -0.01088286,\n",
      "       -0.0107521 , -0.01079302, -0.01081324, -0.01079255, -0.01076071,\n",
      "       -0.01148963, -0.0113696 , -0.01121834, -0.0039774 , -0.00377473,\n",
      "       -0.00382794, -0.0059014 , -0.00568514, -0.0056404 , -0.0082105 ,\n",
      "       -0.00797118, -0.0078555 , -0.00696942, -0.00707697, -0.00697314,\n",
      "       -0.00765179, -0.00760134, -0.00746675, -0.00959454, -0.00947956,\n",
      "       -0.00943052, -0.01073811, -0.01071709, -0.01081554, -0.01085   ,\n",
      "       -0.01076716, -0.01068198, -0.01147267, -0.01129973, -0.01125173]), 'split2_train_score': array([-0.00365271, -0.00354858, -0.0035678 , -0.00514999, -0.00500159,\n",
      "       -0.00507074, -0.00732176, -0.00709544, -0.00707699, -0.00627163,\n",
      "       -0.00615978, -0.0060434 , -0.00667785, -0.00670626, -0.00668247,\n",
      "       -0.00866588, -0.00868595, -0.00855359, -0.00993885, -0.00965353,\n",
      "       -0.00973599, -0.01000963, -0.00972527, -0.00972371, -0.01038615,\n",
      "       -0.01026346, -0.01025023, -0.00362719, -0.00342892, -0.0034635 ,\n",
      "       -0.00557152, -0.00532379, -0.00537753, -0.00787318, -0.00767737,\n",
      "       -0.0075647 , -0.00686015, -0.0066407 , -0.00677513, -0.00722874,\n",
      "       -0.00725376, -0.00724524, -0.00929641, -0.00946272, -0.0092524 ,\n",
      "       -0.01060473, -0.01063959, -0.01054295, -0.01061995, -0.01056015,\n",
      "       -0.01064893, -0.01106099, -0.01103766, -0.01112443, -0.00357222,\n",
      "       -0.00341398, -0.00336509, -0.00541082, -0.00542176, -0.00531288,\n",
      "       -0.00784357, -0.00771482, -0.00766241, -0.00666585, -0.00667172,\n",
      "       -0.00666736, -0.00729888, -0.00731792, -0.00714987, -0.00932677,\n",
      "       -0.00930353, -0.00916001, -0.01076245, -0.01065726, -0.01056739,\n",
      "       -0.01081606, -0.01069046, -0.01061414, -0.01125586, -0.01110523,\n",
      "       -0.0111164 , -0.01619986, -0.01624493, -0.01632979, -0.016543  ,\n",
      "       -0.01644195, -0.0164148 , -0.01655672, -0.01661318, -0.01658871,\n",
      "       -0.01635638, -0.01622084, -0.01623757, -0.016363  , -0.01635895,\n",
      "       -0.01638803, -0.0165581 , -0.01648561, -0.01649178, -0.01660062,\n",
      "       -0.01646571, -0.01654238, -0.01652475, -0.01661529, -0.01650538,\n",
      "       -0.01664555, -0.01666624, -0.01665656, -0.01679745, -0.0167506 ,\n",
      "       -0.01675599, -0.01691261, -0.01704789, -0.01687313, -0.01708937,\n",
      "       -0.0172082 , -0.01715434, -0.01709668, -0.01699866, -0.01703507,\n",
      "       -0.01709148, -0.0170793 , -0.0170891 , -0.0173668 , -0.01730108,\n",
      "       -0.0171951 , -0.01742225, -0.01735044, -0.01744256, -0.01731377,\n",
      "       -0.01740316, -0.01731787, -0.01746492, -0.01748968, -0.01742239,\n",
      "       -0.01683412, -0.01678332, -0.01680895, -0.01709322, -0.01702115,\n",
      "       -0.01691349, -0.01718917, -0.01710765, -0.01705367, -0.01697194,\n",
      "       -0.01712736, -0.01699991, -0.01708402, -0.01709828, -0.01707075,\n",
      "       -0.01719062, -0.01725293, -0.01723058, -0.01739497, -0.01731298,\n",
      "       -0.01732356, -0.01748013, -0.01734053, -0.01733041, -0.01737769,\n",
      "       -0.01735404, -0.01742239, -0.00878447, -0.00879543, -0.00880087,\n",
      "       -0.00976517, -0.00984019, -0.00969809, -0.01110778, -0.01092421,\n",
      "       -0.01091038, -0.00996875, -0.00984412, -0.00971077, -0.01012732,\n",
      "       -0.01017322, -0.01006242, -0.01145617, -0.01145957, -0.01150306,\n",
      "       -0.01163144, -0.01185049, -0.01184985, -0.01180089, -0.0117241 ,\n",
      "       -0.01185935, -0.0123472 , -0.01214711, -0.01217722, -0.00903859,\n",
      "       -0.00879979, -0.00864142, -0.00999294, -0.01006117, -0.00996142,\n",
      "       -0.01131501, -0.0112609 , -0.0112012 , -0.01044371, -0.01047805,\n",
      "       -0.01033946, -0.01055192, -0.01075201, -0.01062049, -0.012011  ,\n",
      "       -0.01195962, -0.01190861, -0.012704  , -0.01236284, -0.01250551,\n",
      "       -0.01250826, -0.01254349, -0.01242116, -0.01292722, -0.01282194,\n",
      "       -0.0127059 , -0.00913532, -0.00890702, -0.00876058, -0.01020672,\n",
      "       -0.00998977, -0.00990605, -0.01137761, -0.01135142, -0.01122973,\n",
      "       -0.01026963, -0.01028522, -0.01046309, -0.01102421, -0.0107739 ,\n",
      "       -0.01072529, -0.01204619, -0.01200276, -0.01180194, -0.01252865,\n",
      "       -0.01242793, -0.01244651, -0.01259626, -0.01239026, -0.01244877,\n",
      "       -0.01277902, -0.01287794, -0.01276831, -0.00529033, -0.00518629,\n",
      "       -0.0050678 , -0.00636884, -0.00630466, -0.00633287, -0.00834526,\n",
      "       -0.00813909, -0.0082648 , -0.00724958, -0.00712516, -0.00703256,\n",
      "       -0.00769305, -0.00743313, -0.0074061 , -0.00933278, -0.00941069,\n",
      "       -0.00938551, -0.01008481, -0.01015727, -0.01013615, -0.01014951,\n",
      "       -0.01016606, -0.01008659, -0.01075522, -0.01075855, -0.01061776,\n",
      "       -0.00492005, -0.00479739, -0.00465923, -0.00659212, -0.00659348,\n",
      "       -0.00648599, -0.00857643, -0.00869122, -0.00852802, -0.00756898,\n",
      "       -0.00736147, -0.00734884, -0.00790012, -0.00787891, -0.00785348,\n",
      "       -0.00997023, -0.00985247, -0.0098016 , -0.01096255, -0.01083633,\n",
      "       -0.01082741, -0.01075946, -0.01087065, -0.0108016 , -0.01127025,\n",
      "       -0.01135342, -0.01128842, -0.0048167 , -0.00475493, -0.00477937,\n",
      "       -0.0066898 , -0.00648808, -0.00645195, -0.0087279 , -0.00856101,\n",
      "       -0.00847711, -0.00750242, -0.00745356, -0.00739409, -0.00810985,\n",
      "       -0.00791686, -0.00785347, -0.01000558, -0.00969533, -0.00978002,\n",
      "       -0.01100022, -0.01094439, -0.0108288 , -0.01095817, -0.01092911,\n",
      "       -0.01084166, -0.01130189, -0.01122653, -0.01133679, -0.00408009,\n",
      "       -0.00389905, -0.00384046, -0.00551014, -0.00537503, -0.00519837,\n",
      "       -0.00749863, -0.00740055, -0.00737402, -0.006395  , -0.00636701,\n",
      "       -0.00616443, -0.00686161, -0.00670833, -0.00669069, -0.00906766,\n",
      "       -0.00885059, -0.00875176, -0.00975851, -0.00983931, -0.00976889,\n",
      "       -0.00974285, -0.00981861, -0.00975215, -0.01044578, -0.01042322,\n",
      "       -0.01021769, -0.00380919, -0.00376864, -0.00363004, -0.00578177,\n",
      "       -0.00552682, -0.00545369, -0.00801015, -0.00787592, -0.00776033,\n",
      "       -0.00688784, -0.00683769, -0.00674151, -0.00740976, -0.00737734,\n",
      "       -0.00724492, -0.00937801, -0.00931745, -0.00938409, -0.01079543,\n",
      "       -0.01055743, -0.01058838, -0.01064321, -0.01060929, -0.01066468,\n",
      "       -0.01127584, -0.01119672, -0.0111147 , -0.0038308 , -0.00362054,\n",
      "       -0.00365041, -0.00565889, -0.00556484, -0.00554066, -0.00787122,\n",
      "       -0.00776645, -0.00778593, -0.00694089, -0.00677114, -0.00679098,\n",
      "       -0.00728047, -0.0072589 , -0.00728827, -0.00944216, -0.00938917,\n",
      "       -0.00933907, -0.01087582, -0.01065746, -0.01061339, -0.01065737,\n",
      "       -0.0105966 , -0.01056183, -0.01121667, -0.01113796, -0.01106713]), 'split3_train_score': array([-0.00342495, -0.00338893, -0.00320957, -0.00478166, -0.00467749,\n",
      "       -0.00463279, -0.00659917, -0.00655159, -0.00659493, -0.00598805,\n",
      "       -0.00577866, -0.00574657, -0.00630247, -0.00628318, -0.0063101 ,\n",
      "       -0.00831865, -0.00813849, -0.00798983, -0.00901234, -0.0091974 ,\n",
      "       -0.00921314, -0.00922044, -0.009245  , -0.00916305, -0.00981529,\n",
      "       -0.0097935 , -0.00963283, -0.00340473, -0.00323592, -0.00321218,\n",
      "       -0.00518574, -0.00504527, -0.00513781, -0.00743773, -0.00731777,\n",
      "       -0.00712436, -0.00653245, -0.00639393, -0.00643494, -0.00692013,\n",
      "       -0.00680913, -0.00685952, -0.00897113, -0.00886738, -0.00872227,\n",
      "       -0.0100829 , -0.01002306, -0.01001756, -0.01016099, -0.01005508,\n",
      "       -0.00998576, -0.01056319, -0.01045797, -0.01043143, -0.00346156,\n",
      "       -0.00331264, -0.0031696 , -0.00509094, -0.00507264, -0.00505569,\n",
      "       -0.0071278 , -0.00719071, -0.00724642, -0.00633932, -0.00631055,\n",
      "       -0.00638275, -0.00697866, -0.00698055, -0.00690016, -0.00885326,\n",
      "       -0.0087768 , -0.00876556, -0.01021274, -0.01001375, -0.0099908 ,\n",
      "       -0.01015345, -0.00999952, -0.0100514 , -0.01054391, -0.01049023,\n",
      "       -0.01046788, -0.01502238, -0.01502673, -0.01503918, -0.0151912 ,\n",
      "       -0.01512618, -0.01514839, -0.01539905, -0.01537352, -0.01534761,\n",
      "       -0.01514714, -0.01512409, -0.01517894, -0.01514915, -0.01511619,\n",
      "       -0.01513309, -0.01544471, -0.0153509 , -0.01543611, -0.01546294,\n",
      "       -0.01551587, -0.01542802, -0.01556968, -0.01545071, -0.01547547,\n",
      "       -0.01566313, -0.01556747, -0.01552479, -0.01572039, -0.01555808,\n",
      "       -0.0155663 , -0.01582613, -0.0158264 , -0.01569409, -0.01591343,\n",
      "       -0.01589319, -0.01588927, -0.01580245, -0.01589419, -0.01584357,\n",
      "       -0.01590894, -0.0159306 , -0.01591831, -0.01611162, -0.01603634,\n",
      "       -0.01600279, -0.01625412, -0.01624631, -0.01620982, -0.01632461,\n",
      "       -0.01628809, -0.01625736, -0.01635861, -0.01619119, -0.01622547,\n",
      "       -0.01567747, -0.01559144, -0.01556312, -0.01565172, -0.01588954,\n",
      "       -0.0156954 , -0.0159742 , -0.01595613, -0.01585932, -0.01592739,\n",
      "       -0.01590008, -0.01585068, -0.01593557, -0.01591443, -0.01583075,\n",
      "       -0.01621601, -0.01599362, -0.01606856, -0.016305  , -0.01621913,\n",
      "       -0.01624682, -0.01620721, -0.01631879, -0.01623968, -0.01621238,\n",
      "       -0.01629923, -0.01624566, -0.00823224, -0.00817995, -0.0082647 ,\n",
      "       -0.0089251 , -0.00905298, -0.0090501 , -0.01043024, -0.01008647,\n",
      "       -0.01002771, -0.0094459 , -0.00931534, -0.00921249, -0.00968751,\n",
      "       -0.00959676, -0.00935588, -0.01090358, -0.0107217 , -0.01054736,\n",
      "       -0.01099348, -0.0111269 , -0.01101449, -0.01107551, -0.01103245,\n",
      "       -0.01089103, -0.01134907, -0.01137977, -0.01125226, -0.00829745,\n",
      "       -0.00806852, -0.00818862, -0.00948056, -0.00927103, -0.0092157 ,\n",
      "       -0.01044556, -0.01055568, -0.01048705, -0.00972311, -0.00978881,\n",
      "       -0.00976561, -0.01008985, -0.01002566, -0.01004199, -0.01149505,\n",
      "       -0.01121884, -0.0111877 , -0.01181336, -0.01164605, -0.01172395,\n",
      "       -0.01171479, -0.01173499, -0.01168816, -0.01220223, -0.01210094,\n",
      "       -0.01197922, -0.0082136 , -0.00842261, -0.00818889, -0.0093809 ,\n",
      "       -0.00933399, -0.00927066, -0.01073557, -0.01060984, -0.01051645,\n",
      "       -0.01000936, -0.00972961, -0.0097232 , -0.01001755, -0.01007745,\n",
      "       -0.00999445, -0.01141147, -0.01128759, -0.01126648, -0.0118833 ,\n",
      "       -0.01174445, -0.01177855, -0.01178544, -0.01179883, -0.01174361,\n",
      "       -0.01215015, -0.0120654 , -0.01205926, -0.0046882 , -0.00467124,\n",
      "       -0.00460023, -0.00597905, -0.00591091, -0.00581836, -0.0076677 ,\n",
      "       -0.00754021, -0.00752387, -0.00682362, -0.00659738, -0.00657601,\n",
      "       -0.00711621, -0.00709014, -0.00703906, -0.00880696, -0.00864367,\n",
      "       -0.00865781, -0.00975332, -0.00953918, -0.00948675, -0.00955292,\n",
      "       -0.00957658, -0.00944112, -0.01011764, -0.00991471, -0.010022  ,\n",
      "       -0.00446077, -0.00439492, -0.00437899, -0.00622515, -0.00608832,\n",
      "       -0.00608177, -0.0080665 , -0.0079525 , -0.00792912, -0.00710194,\n",
      "       -0.00706329, -0.00705072, -0.00765906, -0.0075486 , -0.0074957 ,\n",
      "       -0.00942914, -0.00925219, -0.00919517, -0.01030416, -0.01021522,\n",
      "       -0.01026236, -0.01034384, -0.01030775, -0.01032723, -0.01087903,\n",
      "       -0.01075519, -0.01067723, -0.00461285, -0.00442428, -0.00443937,\n",
      "       -0.00597791, -0.0062132 , -0.00604423, -0.00815488, -0.00793877,\n",
      "       -0.00794554, -0.0073822 , -0.00713502, -0.00706919, -0.00763879,\n",
      "       -0.00754065, -0.00746323, -0.00935903, -0.00927327, -0.00920638,\n",
      "       -0.01036176, -0.01037728, -0.01032425, -0.01032385, -0.01033829,\n",
      "       -0.01032152, -0.01081711, -0.01073832, -0.01071442, -0.00371264,\n",
      "       -0.0036319 , -0.00351823, -0.00512583, -0.00499585, -0.0049361 ,\n",
      "       -0.00671778, -0.00680133, -0.00671801, -0.0061584 , -0.00598196,\n",
      "       -0.00593381, -0.00649319, -0.00636132, -0.00637062, -0.0083169 ,\n",
      "       -0.00819897, -0.00823323, -0.00918281, -0.00926983, -0.00917288,\n",
      "       -0.00941396, -0.00925502, -0.00924692, -0.00973375, -0.00969545,\n",
      "       -0.00970038, -0.00358349, -0.00348028, -0.00338703, -0.0053703 ,\n",
      "       -0.00518963, -0.00520151, -0.00731912, -0.00727319, -0.00730546,\n",
      "       -0.00651624, -0.00659056, -0.00643515, -0.00696488, -0.00699194,\n",
      "       -0.00695907, -0.00880041, -0.00885142, -0.00882007, -0.01018742,\n",
      "       -0.01011421, -0.01005403, -0.01012822, -0.01009871, -0.01003518,\n",
      "       -0.01066033, -0.0104732 , -0.01047697, -0.0035718 , -0.00346401,\n",
      "       -0.00342244, -0.00552279, -0.00514824, -0.00523562, -0.00761671,\n",
      "       -0.00732747, -0.00730334, -0.00660737, -0.00650942, -0.00646181,\n",
      "       -0.00697774, -0.00693443, -0.00688625, -0.00890683, -0.0087966 ,\n",
      "       -0.00883473, -0.01000067, -0.01003806, -0.01008835, -0.01016475,\n",
      "       -0.01018465, -0.01007838, -0.01050862, -0.01054151, -0.0105787 ]), 'split4_train_score': array([-0.00358016, -0.00340013, -0.00336368, -0.00500021, -0.00475639,\n",
      "       -0.00481304, -0.00682316, -0.00676032, -0.00667258, -0.00612386,\n",
      "       -0.00589559, -0.0059138 , -0.00654306, -0.00642503, -0.00637245,\n",
      "       -0.00826348, -0.00822507, -0.00808403, -0.00935396, -0.00929963,\n",
      "       -0.00930315, -0.00935731, -0.00924088, -0.00927552, -0.01001324,\n",
      "       -0.00981119, -0.00973703, -0.00344413, -0.00325025, -0.00326363,\n",
      "       -0.00549637, -0.00533463, -0.00521801, -0.00730186, -0.00744792,\n",
      "       -0.00730173, -0.00675506, -0.00643499, -0.00644391, -0.00706064,\n",
      "       -0.00687033, -0.00692553, -0.00906696, -0.00904873, -0.00887464,\n",
      "       -0.01027795, -0.01023373, -0.01013352, -0.01014143, -0.01020551,\n",
      "       -0.01005255, -0.01077201, -0.01058074, -0.0106789 , -0.00343781,\n",
      "       -0.00334533, -0.00329006, -0.00526572, -0.00515997, -0.00513746,\n",
      "       -0.00752378, -0.00756684, -0.0073367 , -0.00667067, -0.00648658,\n",
      "       -0.00649519, -0.0070027 , -0.00698512, -0.0069306 , -0.00902918,\n",
      "       -0.00900365, -0.00892185, -0.01017488, -0.01024822, -0.01013017,\n",
      "       -0.01022578, -0.01013088, -0.01017796, -0.01069446, -0.01057128,\n",
      "       -0.01061539, -0.01542808, -0.01547655, -0.01544529, -0.01567739,\n",
      "       -0.01572956, -0.0156642 , -0.01578836, -0.01580672, -0.0158243 ,\n",
      "       -0.0157276 , -0.01563499, -0.01551368, -0.01567307, -0.01555161,\n",
      "       -0.01563356, -0.01581864, -0.01576262, -0.01572125, -0.01596214,\n",
      "       -0.01577893, -0.01588194, -0.0158645 , -0.01570575, -0.01584921,\n",
      "       -0.01598942, -0.01597787, -0.0159015 , -0.01590203, -0.01591577,\n",
      "       -0.01585582, -0.01607069, -0.01598797, -0.01599386, -0.01628826,\n",
      "       -0.01617392, -0.01624214, -0.01619611, -0.01619567, -0.01610265,\n",
      "       -0.01623636, -0.0162019 , -0.01612629, -0.01635115, -0.01645067,\n",
      "       -0.01641854, -0.01657387, -0.01645606, -0.01645218, -0.01648671,\n",
      "       -0.01656246, -0.01652911, -0.01667579, -0.01651671, -0.01660507,\n",
      "       -0.0159169 , -0.01594909, -0.01590443, -0.01606409, -0.01607553,\n",
      "       -0.01597162, -0.01622979, -0.0162556 , -0.0162454 , -0.01608707,\n",
      "       -0.01611662, -0.01609973, -0.01623576, -0.01623881, -0.01620118,\n",
      "       -0.01637218, -0.01648614, -0.01639798, -0.01655   , -0.01648881,\n",
      "       -0.0165046 , -0.01646118, -0.01648681, -0.0165578 , -0.01654952,\n",
      "       -0.01663108, -0.01657038, -0.00886388, -0.00885869, -0.00880486,\n",
      "       -0.00954588, -0.00982747, -0.00959076, -0.01065997, -0.01055971,\n",
      "       -0.01052388, -0.0099772 , -0.00979085, -0.00974716, -0.00997473,\n",
      "       -0.01002792, -0.01004003, -0.01122113, -0.01122778, -0.01112969,\n",
      "       -0.01164286, -0.01147501, -0.01143105, -0.0115107 , -0.01141849,\n",
      "       -0.01137778, -0.01185699, -0.01186472, -0.01178852, -0.00869428,\n",
      "       -0.00873682, -0.00847763, -0.00971109, -0.00951725, -0.00947447,\n",
      "       -0.01118433, -0.01089472, -0.01087511, -0.0100202 , -0.00999844,\n",
      "       -0.01015212, -0.01045666, -0.01051272, -0.01028183, -0.011531  ,\n",
      "       -0.01146781, -0.01148884, -0.012173  , -0.01193799, -0.01207635,\n",
      "       -0.01225152, -0.01210445, -0.01200286, -0.01238483, -0.01234924,\n",
      "       -0.01235503, -0.00861033, -0.00859323, -0.0085165 , -0.00971612,\n",
      "       -0.0097575 , -0.00971849, -0.01081026, -0.01086618, -0.01079223,\n",
      "       -0.01017825, -0.00997776, -0.00991034, -0.01048844, -0.01041982,\n",
      "       -0.01039484, -0.01160008, -0.01165926, -0.01157702, -0.01197083,\n",
      "       -0.01196243, -0.0120456 , -0.01218501, -0.01224614, -0.01208818,\n",
      "       -0.01243056, -0.01235428, -0.01232364, -0.00517965, -0.00517439,\n",
      "       -0.00503546, -0.00634167, -0.00638295, -0.00624981, -0.00792792,\n",
      "       -0.00792705, -0.00778405, -0.00706449, -0.00693413, -0.00696493,\n",
      "       -0.00752084, -0.00751858, -0.00733098, -0.00904391, -0.00895862,\n",
      "       -0.00890134, -0.00988516, -0.00978997, -0.00971484, -0.00983732,\n",
      "       -0.00980764, -0.00975149, -0.01040914, -0.01018491, -0.01018659,\n",
      "       -0.00466937, -0.00488436, -0.00462644, -0.00648233, -0.00630977,\n",
      "       -0.00631297, -0.00846675, -0.00821997, -0.0082767 , -0.00743485,\n",
      "       -0.00722009, -0.00726268, -0.00805614, -0.00770016, -0.00771634,\n",
      "       -0.00964309, -0.00944512, -0.00951573, -0.01075112, -0.01054592,\n",
      "       -0.01042043, -0.01061497, -0.01051018, -0.01040518, -0.01105688,\n",
      "       -0.01090395, -0.01092467, -0.00498385, -0.00464768, -0.0046612 ,\n",
      "       -0.00641493, -0.00628985, -0.00640339, -0.00846405, -0.00836419,\n",
      "       -0.00827072, -0.00763603, -0.00736346, -0.00730017, -0.00791024,\n",
      "       -0.00769957, -0.00773183, -0.00952619, -0.00947521, -0.00950038,\n",
      "       -0.01053446, -0.0104653 , -0.01042611, -0.01051684, -0.01058477,\n",
      "       -0.01049142, -0.01089729, -0.01102899, -0.01085146, -0.00385616,\n",
      "       -0.0037744 , -0.00373986, -0.00535915, -0.00518056, -0.00521654,\n",
      "       -0.00720217, -0.0070019 , -0.00690015, -0.00620307, -0.00610121,\n",
      "       -0.00609863, -0.00665407, -0.00664941, -0.00657737, -0.00838595,\n",
      "       -0.00845378, -0.00833918, -0.00938129, -0.00939584, -0.00941714,\n",
      "       -0.00944262, -0.00932071, -0.00936507, -0.00987372, -0.00980874,\n",
      "       -0.00988961, -0.00370455, -0.00367443, -0.00351218, -0.00553262,\n",
      "       -0.00533212, -0.00545701, -0.0076563 , -0.00753574, -0.00749165,\n",
      "       -0.0067304 , -0.00658141, -0.00655465, -0.00718665, -0.00699078,\n",
      "       -0.0069918 , -0.00911717, -0.00905865, -0.00899333, -0.01021648,\n",
      "       -0.01026842, -0.01013018, -0.01028426, -0.01020975, -0.01015834,\n",
      "       -0.0106635 , -0.01065073, -0.01063269, -0.0038531 , -0.00361221,\n",
      "       -0.0036472 , -0.00545521, -0.00542018, -0.00536621, -0.00735789,\n",
      "       -0.00750468, -0.00753718, -0.00668847, -0.00654434, -0.00658504,\n",
      "       -0.00710251, -0.0070428 , -0.00705521, -0.00899109, -0.0089485 ,\n",
      "       -0.00897984, -0.01011607, -0.01036302, -0.01020932, -0.0102915 ,\n",
      "       -0.01017743, -0.01020121, -0.01066863, -0.01064647, -0.01064144]), 'mean_train_score': array([-0.00362681, -0.003514  , -0.00345565, -0.0050197 , -0.00491454,\n",
      "       -0.00490098, -0.00701457, -0.00691548, -0.00689319, -0.00625908,\n",
      "       -0.00602419, -0.00602754, -0.00661126, -0.00657537, -0.00652955,\n",
      "       -0.00857759, -0.00848555, -0.0083886 , -0.009655  , -0.00958679,\n",
      "       -0.00959285, -0.00971983, -0.00962216, -0.00957451, -0.01024067,\n",
      "       -0.01016218, -0.01006244, -0.00358092, -0.00340354, -0.00337868,\n",
      "       -0.00546033, -0.00537436, -0.00533526, -0.00769636, -0.0076171 ,\n",
      "       -0.00749914, -0.00685802, -0.00667653, -0.00668965, -0.00716702,\n",
      "       -0.00717501, -0.00715568, -0.00931281, -0.00929891, -0.00917486,\n",
      "       -0.01054981, -0.01052773, -0.01044542, -0.01053933, -0.01051081,\n",
      "       -0.01044315, -0.0110309 , -0.01093626, -0.01097063, -0.00358254,\n",
      "       -0.00346484, -0.00337766, -0.00542864, -0.00532281, -0.00527256,\n",
      "       -0.00767612, -0.00761589, -0.00755983, -0.00675653, -0.0066552 ,\n",
      "       -0.00665779, -0.00728405, -0.00722871, -0.00711791, -0.0093167 ,\n",
      "       -0.00923805, -0.00916502, -0.01061918, -0.01053943, -0.01044917,\n",
      "       -0.01057959, -0.01049147, -0.01049621, -0.01106473, -0.01094191,\n",
      "       -0.01096439, -0.01595728, -0.01594009, -0.01596337, -0.01614423,\n",
      "       -0.01610842, -0.01608833, -0.01626835, -0.01625069, -0.01627663,\n",
      "       -0.01608669, -0.01602318, -0.01600335, -0.01607759, -0.01604516,\n",
      "       -0.01605131, -0.0162938 , -0.01626558, -0.01624718, -0.01633553,\n",
      "       -0.0162834 , -0.01630622, -0.01633653, -0.01628485, -0.016304  ,\n",
      "       -0.01644826, -0.01640011, -0.01635908, -0.01653145, -0.016433  ,\n",
      "       -0.01644109, -0.01662168, -0.01668569, -0.01658523, -0.0168209 ,\n",
      "       -0.0168059 , -0.01679377, -0.01672414, -0.01670761, -0.0167112 ,\n",
      "       -0.01679983, -0.01678034, -0.01674101, -0.01699796, -0.01697739,\n",
      "       -0.01692641, -0.01707745, -0.01704641, -0.01707885, -0.01712487,\n",
      "       -0.01711977, -0.01707603, -0.01720666, -0.01710752, -0.01712118,\n",
      "       -0.01646327, -0.0164653 , -0.01647034, -0.01664872, -0.01666626,\n",
      "       -0.01659515, -0.01683765, -0.01681107, -0.01677292, -0.01674553,\n",
      "       -0.01676582, -0.01671698, -0.01681438, -0.01677729, -0.01674294,\n",
      "       -0.01694224, -0.01696886, -0.01694232, -0.01715751, -0.01703035,\n",
      "       -0.01707638, -0.01710716, -0.0170638 , -0.01707962, -0.01715086,\n",
      "       -0.01709268, -0.01710682, -0.00897112, -0.00890569, -0.00889487,\n",
      "       -0.00972803, -0.00976205, -0.00968692, -0.01094602, -0.0108113 ,\n",
      "       -0.01081184, -0.00995009, -0.00989945, -0.00980107, -0.01023869,\n",
      "       -0.01020021, -0.01009763, -0.01145646, -0.01138361, -0.01132947,\n",
      "       -0.01173046, -0.01169498, -0.01169873, -0.01172357, -0.01166665,\n",
      "       -0.01165303, -0.01211552, -0.01206134, -0.01199911, -0.00895264,\n",
      "       -0.00882954, -0.0087356 , -0.00999955, -0.00993456, -0.0098475 ,\n",
      "       -0.01131208, -0.01112652, -0.01116972, -0.01029728, -0.01038311,\n",
      "       -0.01036348, -0.01070736, -0.01065081, -0.01060785, -0.01194281,\n",
      "       -0.01190576, -0.0118737 , -0.01247642, -0.01232928, -0.01241769,\n",
      "       -0.01242574, -0.01244452, -0.01233212, -0.01278388, -0.01273247,\n",
      "       -0.01263062, -0.00894724, -0.00887914, -0.00876957, -0.01006754,\n",
      "       -0.00995627, -0.00991598, -0.01130652, -0.0112196 , -0.0111588 ,\n",
      "       -0.01040514, -0.01031448, -0.01032928, -0.01080834, -0.01068883,\n",
      "       -0.01064443, -0.01200296, -0.01194025, -0.01184313, -0.0124472 ,\n",
      "       -0.01240322, -0.01239255, -0.01255505, -0.01240818, -0.01238325,\n",
      "       -0.01281902, -0.01275368, -0.0126956 , -0.00514866, -0.00514856,\n",
      "       -0.00504126, -0.0064027 , -0.00635867, -0.00627685, -0.00809074,\n",
      "       -0.00809634, -0.00805446, -0.00716376, -0.0070191 , -0.00699898,\n",
      "       -0.00751548, -0.00748935, -0.00742997, -0.00928763, -0.00919321,\n",
      "       -0.00916495, -0.01014178, -0.01001795, -0.00995353, -0.01007013,\n",
      "       -0.01003152, -0.00997675, -0.01062588, -0.01046995, -0.01050304,\n",
      "       -0.00488071, -0.00483827, -0.00474107, -0.00664303, -0.00652386,\n",
      "       -0.00647174, -0.00855689, -0.00851848, -0.00846655, -0.0075473 ,\n",
      "       -0.00743943, -0.00742671, -0.00807294, -0.00794406, -0.00789722,\n",
      "       -0.00989458, -0.00977499, -0.00975097, -0.01089369, -0.01077152,\n",
      "       -0.01077955, -0.010866  , -0.01079599, -0.01074525, -0.01135676,\n",
      "       -0.0112442 , -0.01120118, -0.00492684, -0.00477122, -0.00478356,\n",
      "       -0.006555  , -0.0065119 , -0.00647349, -0.00862581, -0.0085575 ,\n",
      "       -0.00845426, -0.00766651, -0.00746837, -0.00745529, -0.00805867,\n",
      "       -0.00792179, -0.00788709, -0.00994465, -0.00977315, -0.00975398,\n",
      "       -0.01087175, -0.01081129, -0.01074083, -0.01084475, -0.0108322 ,\n",
      "       -0.01078303, -0.01123579, -0.01122386, -0.01120879, -0.00396712,\n",
      "       -0.00385975, -0.00378524, -0.00541946, -0.00529305, -0.00520784,\n",
      "       -0.00723936, -0.00718807, -0.00713721, -0.00634508, -0.00625912,\n",
      "       -0.006179  , -0.00681341, -0.00671461, -0.00665697, -0.00867423,\n",
      "       -0.0086305 , -0.00856348, -0.00964156, -0.00969491, -0.00962223,\n",
      "       -0.00970382, -0.00965547, -0.00962038, -0.01021327, -0.01017281,\n",
      "       -0.010129  , -0.00379627, -0.0037433 , -0.00361078, -0.00573965,\n",
      "       -0.00553325, -0.00551799, -0.00782142, -0.00775004, -0.00769884,\n",
      "       -0.00692092, -0.00682366, -0.00674583, -0.00734247, -0.00732094,\n",
      "       -0.00722117, -0.00937902, -0.0092681 , -0.00925568, -0.01060611,\n",
      "       -0.01052651, -0.01047731, -0.01056949, -0.01053074, -0.01050345,\n",
      "       -0.01111112, -0.01103127, -0.01096989, -0.00383771, -0.00367429,\n",
      "       -0.00368244, -0.00567306, -0.00554525, -0.00552579, -0.00783422,\n",
      "       -0.00773942, -0.00772053, -0.0068704 , -0.00679534, -0.00675106,\n",
      "       -0.00735077, -0.00726789, -0.00725769, -0.00934278, -0.00926189,\n",
      "       -0.00924815, -0.01055209, -0.01054602, -0.01052659, -0.01062028,\n",
      "       -0.01052566, -0.01048074, -0.01107284, -0.01099716, -0.01098494]), 'std_train_score': array([0.00013494, 0.00010321, 0.00015032, 0.00012834, 0.00017406,\n",
      "       0.00015913, 0.00026418, 0.00022318, 0.00021429, 0.00018479,\n",
      "       0.00015744, 0.00018322, 0.00017743, 0.0001873 , 0.00015593,\n",
      "       0.00024914, 0.0002515 , 0.00029133, 0.00040319, 0.00029343,\n",
      "       0.00028007, 0.00035735, 0.00032227, 0.00029739, 0.00027683,\n",
      "       0.00030711, 0.00031309, 0.00014312, 0.00014026, 0.00011667,\n",
      "       0.00013996, 0.0002048 , 0.00013735, 0.00028034, 0.00020818,\n",
      "       0.00025243, 0.00020584, 0.00024343, 0.00020924, 0.00015414,\n",
      "       0.00029001, 0.000221  , 0.00029225, 0.000288  , 0.00032527,\n",
      "       0.00035251, 0.00034366, 0.00031514, 0.00033324, 0.00033376,\n",
      "       0.00035119, 0.00033665, 0.00035634, 0.00035649, 0.00012691,\n",
      "       0.00013936, 0.00014045, 0.00023469, 0.00017716, 0.00015291,\n",
      "       0.00031597, 0.00023037, 0.00022505, 0.00028079, 0.0002328 ,\n",
      "       0.00019694, 0.00025939, 0.00020774, 0.00017522, 0.00033827,\n",
      "       0.000309  , 0.00029636, 0.0003596 , 0.00035488, 0.00033046,\n",
      "       0.00031951, 0.00036163, 0.00032704, 0.0003717 , 0.00034386,\n",
      "       0.0003555 , 0.00066989, 0.00061616, 0.00064815, 0.00063788,\n",
      "       0.00064773, 0.00062382, 0.0006068 , 0.00060125, 0.00062982,\n",
      "       0.00061528, 0.0006089 , 0.00060871, 0.00061147, 0.00066248,\n",
      "       0.00061839, 0.00061386, 0.00066147, 0.00060848, 0.00058763,\n",
      "       0.0005848 , 0.00059991, 0.00057645, 0.0006264 , 0.00058923,\n",
      "       0.00055621, 0.00056949, 0.00058453, 0.00061245, 0.00062158,\n",
      "       0.00062566, 0.00057002, 0.00065325, 0.0006479 , 0.00062456,\n",
      "       0.00065187, 0.00062519, 0.00062907, 0.00058151, 0.00062941,\n",
      "       0.00063897, 0.00061924, 0.00061214, 0.00064874, 0.00063439,\n",
      "       0.00062223, 0.00056185, 0.00059827, 0.00063559, 0.00062821,\n",
      "       0.00059353, 0.0005931 , 0.00059469, 0.00063289, 0.00061422,\n",
      "       0.00057859, 0.00060503, 0.00062861, 0.00066929, 0.00059312,\n",
      "       0.00065565, 0.00062471, 0.00059911, 0.00062814, 0.00064463,\n",
      "       0.00065967, 0.00063793, 0.00063536, 0.00059742, 0.00062968,\n",
      "       0.00055622, 0.00064264, 0.00061114, 0.00062772, 0.00059184,\n",
      "       0.00060474, 0.00066057, 0.00057098, 0.00059375, 0.00067901,\n",
      "       0.00054715, 0.00059958, 0.00050698, 0.0004942 , 0.00042105,\n",
      "       0.00052258, 0.00040703, 0.00041597, 0.00040259, 0.00048836,\n",
      "       0.00055177, 0.00030002, 0.00039538, 0.00040636, 0.00044499,\n",
      "       0.0004108 , 0.00049214, 0.00042956, 0.00045772, 0.00050816,\n",
      "       0.00045574, 0.00036655, 0.00044492, 0.00043775, 0.00042295,\n",
      "       0.0004718 , 0.00046048, 0.00044066, 0.00046406, 0.0004472 ,\n",
      "       0.00044652, 0.00040718, 0.00040935, 0.00049512, 0.00044966,\n",
      "       0.00051933, 0.00037585, 0.00046575, 0.00037108, 0.000442  ,\n",
      "       0.00038979, 0.00046303, 0.0003655 , 0.00041615, 0.00037322,\n",
      "       0.00051476, 0.00049602, 0.00041688, 0.00049715, 0.00046552,\n",
      "       0.00042704, 0.00047575, 0.00044252, 0.00042061, 0.00045358,\n",
      "       0.00043415, 0.00046586, 0.00033667, 0.0003977 , 0.0004638 ,\n",
      "       0.00039728, 0.00040787, 0.00048817, 0.00045066, 0.00046704,\n",
      "       0.00035296, 0.00044054, 0.00046441, 0.00048902, 0.0004136 ,\n",
      "       0.00041818, 0.00047417, 0.00045171, 0.00040918, 0.00046019,\n",
      "       0.00050083, 0.00045365, 0.0005182 , 0.0003921 , 0.00043025,\n",
      "       0.000504  , 0.00048272, 0.00045463, 0.00028159, 0.00026302,\n",
      "       0.00027309, 0.00028475, 0.0002731 , 0.0002794 , 0.00032746,\n",
      "       0.00035043, 0.00034895, 0.00022635, 0.00025417, 0.00026332,\n",
      "       0.0002474 , 0.00026335, 0.0002618 , 0.00034191, 0.00034507,\n",
      "       0.00034461, 0.00031678, 0.00030519, 0.00029978, 0.00034715,\n",
      "       0.00029775, 0.0003425 , 0.00031911, 0.00036848, 0.0003455 ,\n",
      "       0.00028655, 0.00024872, 0.00025651, 0.00031593, 0.00029874,\n",
      "       0.00026317, 0.0003217 , 0.0003807 , 0.0003428 , 0.00026881,\n",
      "       0.00029361, 0.00027122, 0.00029062, 0.00030624, 0.00028075,\n",
      "       0.00031345, 0.00038632, 0.00036248, 0.00034797, 0.00035777,\n",
      "       0.00039296, 0.00039571, 0.00034419, 0.00033163, 0.00037988,\n",
      "       0.00036048, 0.00036649, 0.00019127, 0.00024088, 0.0002212 ,\n",
      "       0.00034306, 0.0002417 , 0.00026029, 0.000297  , 0.00039369,\n",
      "       0.00035215, 0.00021286, 0.00021524, 0.00027068, 0.00026539,\n",
      "       0.00027938, 0.00028035, 0.0004511 , 0.0003886 , 0.00037845,\n",
      "       0.00036448, 0.00034255, 0.00032093, 0.00037653, 0.00033146,\n",
      "       0.00032993, 0.00033623, 0.00032829, 0.0003665 , 0.00016267,\n",
      "       0.00015804, 0.00014804, 0.00016324, 0.00019961, 0.0001615 ,\n",
      "       0.0002904 , 0.0002437 , 0.00028442, 0.00017192, 0.00018533,\n",
      "       0.00015837, 0.00021229, 0.00021063, 0.00017944, 0.00028221,\n",
      "       0.00026132, 0.00022905, 0.00031324, 0.0003051 , 0.00028244,\n",
      "       0.00023982, 0.00031222, 0.00026292, 0.00033823, 0.00034638,\n",
      "       0.00028871, 0.00016607, 0.0001563 , 0.00014671, 0.00025467,\n",
      "       0.00025119, 0.00020753, 0.00030266, 0.00030525, 0.00026548,\n",
      "       0.00028277, 0.00020986, 0.00023195, 0.0002441 , 0.00028577,\n",
      "       0.00021506, 0.00038944, 0.0002815 , 0.00029688, 0.00033368,\n",
      "       0.00030323, 0.0003255 , 0.00031882, 0.00032701, 0.00034249,\n",
      "       0.0003742 , 0.00039678, 0.00035502, 0.00014448, 0.00014965,\n",
      "       0.00015753, 0.00017092, 0.00025483, 0.00021242, 0.00031492,\n",
      "       0.00029317, 0.0002794 , 0.00019644, 0.00024608, 0.00019975,\n",
      "       0.00029964, 0.0002561 , 0.00025898, 0.00033986, 0.00033658,\n",
      "       0.00030042, 0.00041516, 0.00031623, 0.00032494, 0.0003571 ,\n",
      "       0.00029761, 0.00029891, 0.00041054, 0.00033874, 0.00032297])}\n"
     ]
    }
   ],
   "source": [
    "# Access the full results for Random Forest\n",
    "cv_results = grid_CV.cv_results_\n",
    "print(\"CV Results for Random Forest:\", cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Right now (temporary) we will this hyperparameters as the best one:\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_score</th>\n",
       "      <th>sign_fscore</th>\n",
       "      <th>sign_fscore_0_1</th>\n",
       "      <th>corr</th>\n",
       "      <th>EN_coef</th>\n",
       "      <th>boruta_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>etr_y_past</th>\n",
       "      <td>1.009402</td>\n",
       "      <td>1.304040e-84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etr_y_ma</th>\n",
       "      <td>0.825650</td>\n",
       "      <td>2.473770e-125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt</th>\n",
       "      <td>0.633067</td>\n",
       "      <td>5.246456e-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.368732</td>\n",
       "      <td>1.466269e-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>0.632640</td>\n",
       "      <td>2.257712e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.291716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>0.613297</td>\n",
       "      <td>1.747230e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.263458</td>\n",
       "      <td>-3.442000e-07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mi_score    sign_fscore  sign_fscore_0_1      corr       EN_coef  \\\n",
       "etr_y_past  1.009402   1.304040e-84                1  0.520405           NaN   \n",
       "etr_y_ma    0.825650  2.473770e-125                1  0.526871           NaN   \n",
       "txt         0.633067   5.246456e-13                1  0.368732  1.466269e-05   \n",
       "diff        0.632640   2.257712e-02                1 -0.291716           NaN   \n",
       "ni          0.613297   1.747230e-09                1  0.263458 -3.442000e-07   \n",
       "\n",
       "            boruta_rank  \n",
       "etr_y_past            1  \n",
       "etr_y_ma              1  \n",
       "txt                   1  \n",
       "diff                  1  \n",
       "ni                    7  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature ranking\n",
    "fr.sort_values(\"mi_score\", ascending=False, inplace=True)\n",
    "fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_features = fr[fr.boruta_rank.isin([1, 2, 3])].index.tolist()\n",
    "mi_features = fr.iloc[0:20].index.tolist()\n",
    "mi_features_25 = fr.iloc[0:25].index.tolist()\n",
    "mi_features_35 = fr.iloc[0:35].index.tolist()\n",
    "mi_features_50 = fr.iloc[0:50].index.tolist()\n",
    "fr[\"corr_abs\"] = np.abs(fr[\"corr\"])\n",
    "fr.sort_values(\"corr_abs\", ascending=False, inplace=True)\n",
    "corr_features = fr.iloc[0:20].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use our intuition and create two additional benchmark sets of variables:\n",
    "benchmark = [\n",
    "    \"rok\",\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"capex2_scaled\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"y_e_p_polity\",\n",
    "    \"y_BR_Democracy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"sektor_consumer discretionary\",\n",
    "    \"sektor_consumer staples\",\n",
    "    \"sektor_energy\",\n",
    "    \"sektor_health care\",\n",
    "    \"sektor_industrials\",\n",
    "    \"sektor_materials\",\n",
    "    \"sektor_real estate\",\n",
    "    \"sektor_technology\",\n",
    "    \"sektor_utilities\",\n",
    "    \"gielda_2\",\n",
    "    \"gielda_3\",\n",
    "    \"gielda_4\",\n",
    "    \"gielda_5\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = [\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward elimination\n",
    "forward_elimination = [\n",
    "    \"rok\",\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"capex2_scaled\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"y_e_p_polity\",\n",
    "    \"y_BR_Democracy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"sektor_consumer discretionary\",\n",
    "    \"sektor_consumer staples\",\n",
    "    \"sektor_energy\",\n",
    "    \"sektor_health care\",\n",
    "    \"sektor_industrials\",\n",
    "    \"sektor_materials\",\n",
    "    \"sektor_real estate\",\n",
    "    \"sektor_technology\",\n",
    "    \"sektor_utilities\",\n",
    "    \"gielda_2\",\n",
    "    \"gielda_3\",\n",
    "    \"gielda_4\",\n",
    "    \"gielda_5\",\n",
    "    \"ta_log\",\n",
    "    \"txt_cat_(-63.011, -34.811]\",\n",
    "    \"txt_cat_(-34.811, 0.488]\",\n",
    "    \"txt_cat_(0.488, 24.415]\",\n",
    "    \"txt_cat_(24.415, 25.05]\",\n",
    "    \"txt_cat_(25.05, 308.55]\",\n",
    "    \"txt_cat_(308.55, 327.531]\",\n",
    "    \"txt_cat_(327.531, inf]\",\n",
    "    \"pi_cat_(-8975.0, -1.523]\",\n",
    "    \"pi_cat_(-1.523, 157.119]\",\n",
    "    \"pi_cat_(157.119, 465.9]\",\n",
    "    \"pi_cat_(465.9, 7875.5]\",\n",
    "    \"pi_cat_(7875.5, 8108.5]\",\n",
    "    \"pi_cat_(8108.5, inf]\",\n",
    "    \"str_cat_(0.0875, 0.192]\",\n",
    "    \"str_cat_(0.192, 0.28]\",\n",
    "    \"str_cat_(0.28, inf]\",\n",
    "    \"xrd_exists\",\n",
    "    \"ni_profit\",\n",
    "    \"ni_profit_20000\",\n",
    "    \"ppent_sqrt\",\n",
    "    \"intant_sqrt\",\n",
    "    \"dlc_cat_(42.262, 176.129]\",\n",
    "    \"dlc_cat_(176.129, 200.9]\",\n",
    "    \"dlc_cat_(200.9, inf]\",\n",
    "    \"dltt_cat_(39.38, 327.85]\",\n",
    "    \"dltt_cat_(327.85, 876.617]\",\n",
    "    \"dltt_cat_(876.617, inf]\",\n",
    "    \"capex_cat_(7.447, 79.55]\",\n",
    "    \"capex_cat_(79.55, 5451.0]\",\n",
    "    \"capex_cat_(5451.0, inf]\",\n",
    "    \"revenue_cat_(0.174, 1248.817]\",\n",
    "    \"revenue_cat_(1248.817, 4233.587]\",\n",
    "    \"revenue_cat_(4233.587, inf]\",\n",
    "    \"cce_cat_(5.619, 63.321]\",\n",
    "    \"cce_cat_(63.321, inf]\",\n",
    "    \"adv_cat_(0.3, 874.5]\",\n",
    "    \"adv_cat_(874.5, inf]\",\n",
    "    \"diff_positive\",\n",
    "    \"roa_clip\",\n",
    "    \"lev_sqrt\",\n",
    "    \"intan_pow2\",\n",
    "    \"rd_sqrt\",\n",
    "    \"ppe_clip\",\n",
    "    \"cash_holdings_sqrt\",\n",
    "    \"adv_expenditure_positive\",\n",
    "    \"diff_dta\",\n",
    "    \"cfc_dta\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]\n",
    "forward_elimination.remove(\"ta_log\")\n",
    "forward_elimination.remove(\"ppent_sqrt\")\n",
    "forward_elimination.remove(\"intant_sqrt\")\n",
    "forward_elimination.remove(\"roa\")\n",
    "forward_elimination.remove(\"lev\")\n",
    "forward_elimination.remove(\"intan\")\n",
    "forward_elimination.remove(\"rd_sqrt\")\n",
    "forward_elimination.remove(\"ppe\")\n",
    "forward_elimination.remove(\"cash_holdings_sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_withoud_discr = [i for i in forward_elimination if \"]\" not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**grid_CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = SFS(\n",
    "    model,\n",
    "    n_features_to_select=15,\n",
    "    direction='forward',\n",
    "    scoring=mse,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rok', 'str', 'dta', 'y_e_p_polity', 'y_BR_Democracy', 'WB_GDPgrowth',\n",
      "       'WB_GDPpc', 'WB_Inflation', 'sektor_consumer discretionary', 'gielda_3',\n",
      "       'gielda_5', 'xrd_exists', 'etr_y_past', 'etr_y_ma', 'diff_ma'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sffit = sf.fit(\n",
    "    df.loc[:, candidates_withoud_discr].values, df.loc[:, \"etr\"].values.ravel()\n",
    ")\n",
    "\n",
    "sf_features = df.loc[:, candidates_withoud_discr].columns[sffit.support_]\n",
    "\n",
    "print(sf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**grid_CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = SFS(\n",
    "    model,\n",
    "    n_features_to_select=(10),\n",
    "    direction='forward',\n",
    "    scoring=mse,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rok', 'y_v2x_polyarchy', 'y_BR_Democracy', 'WB_GDPgrowth', 'WB_GDPpc',\n",
       "       'txt_cat_(24.415, 25.05]', 'capex_cat_(5451.0, inf]', 'etr_y_past',\n",
       "       'etr_y_ma', 'diff_ma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sffit = sf.fit(\n",
    "    df.loc[:, forward_elimination].values, df.loc[:, \"etr\"].values.ravel()\n",
    ")\n",
    "\n",
    "sf_features2 = df.loc[:, forward_elimination].columns[sffit.support_]\n",
    "\n",
    "sf_features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_one_more = ['rok', \n",
    "               'y_v2x_polyarchy', \n",
    "               'y_BR_Democracy', \n",
    "               'WB_GDPgrowth', \n",
    "               'WB_GDPpc',\n",
    "               'txt_cat_(24.415, 25.05]', \n",
    "               'capex_cat_(5451.0, inf]', \n",
    "               'etr_y_past',\n",
    "               'etr_y_ma', \n",
    "               'diff_ma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**grid_CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = SFS(\n",
    "    model,\n",
    "    n_features_to_select=(5),\n",
    "    direction='forward',\n",
    "    scoring=mse,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rok', 'WB_GDPpc', 'txt_cat_(24.415, 25.05]', 'etr_y_past', 'etr_y_ma'], dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sffit = sf.fit(df.loc[:, sf_one_more].values, df.loc[:, \"etr\"].values.ravel())\n",
    "\n",
    "sf_features3 = df.loc[:, sf_one_more].columns[sffit.support_]\n",
    "\n",
    "sf_features3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters Tunning for each group of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_proc(var):\n",
    "    model = RandomForestRegressor()\n",
    "    grid_CV = GridSearchCV(\n",
    "        model, param, cv=5, scoring=mse, return_train_score=True, n_jobs=-1\n",
    "    )\n",
    "    grid_CV.fit(df.loc[:, var].values, df.loc[:, \"etr\"].values.ravel())\n",
    "    print(grid_CV.best_params_)\n",
    "    print(grid_CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18452\\2031961920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv_proc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18452\\3794242252.py\u001b[0m in \u001b[0;36mcv_proc\u001b[1;34m(var)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     )\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mgrid_CV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"etr\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_CV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_CV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_proc(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proc(benchmark2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proc(mi_features_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proc(mi_features_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proc(mi_features_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proc(br_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proc(mi_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proc(corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proc(sf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proc(sf_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_proc(sf_features3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"rok\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper_CV(x, y, model, display_res=False):\n",
    "    train_score = list()\n",
    "    valid_score = list()\n",
    "    train_indexes = [0, 1452]\n",
    "    valid_indexes = [1452, 1815]\n",
    "    for i in range(0, 6):\n",
    "        train_x = x[x.index.isin(range(train_indexes[0], train_indexes[1]))]\n",
    "        train_y = y[y.index.isin(range(train_indexes[0], train_indexes[1]))]\n",
    "        valid_x = x[x.index.isin(range(valid_indexes[0], valid_indexes[1]))]\n",
    "        valid_y = y[y.index.isin(range(valid_indexes[0], valid_indexes[1]))]\n",
    "\n",
    "        model.fit(train_x.values, train_y.values.ravel())\n",
    "\n",
    "        pred_y_train = model.predict(train_x.values)\n",
    "        rmse = np.sqrt(mean_squared_error(train_y, pred_y_train))\n",
    "        train_score.append(rmse)\n",
    "\n",
    "        pred_y_val = model.predict(valid_x.values)\n",
    "        rmse = np.sqrt(mean_squared_error(valid_y, pred_y_val))\n",
    "        valid_score.append(rmse)\n",
    "\n",
    "        train_indexes = [0, valid_indexes[1]]\n",
    "        valid_indexes = [train_indexes[1], valid_indexes[1] + 363]\n",
    "\n",
    "    if display_res == True:\n",
    "        view = pd.DataFrame([train_score, valid_score]).T.rename(\n",
    "            columns={0: \"cv_train\", 1: \"cv_val\"}\n",
    "        )\n",
    "        display(view)\n",
    "        return train_score, valid_score, view\n",
    "    else:\n",
    "        return train_score, valid_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = [\n",
    "    ,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[0])\n",
    "var = benchmark\n",
    "cv_output0 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[1])\n",
    "var = benchmark2\n",
    "cv_output1 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[2])\n",
    "var = br_features\n",
    "cv_output2 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[3])\n",
    "var = mi_features\n",
    "cv_output3 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[4])\n",
    "var = corr_features\n",
    "cv_output4 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[5])\n",
    "var = sf_features\n",
    "cv_output5 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[6])\n",
    "var = sf_features2\n",
    "cv_output6 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[7])\n",
    "var = sf_features3\n",
    "cv_output7 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[8])\n",
    "var = mi_features_25\n",
    "cv_output8 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[9])\n",
    "var = mi_features_35\n",
    "cv_output9 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[10])\n",
    "var = mi_features_50\n",
    "cv_output10 = proper_CV(df.loc[:, var], df.loc[:, \"etr\"], model, display_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        cv_output0[2].mean().tolist(),\n",
    "        cv_output1[2].mean().tolist(),\n",
    "        cv_output2[2].mean().tolist(),\n",
    "        cv_output3[2].mean().tolist(),\n",
    "        cv_output4[2].mean().tolist(),\n",
    "        cv_output5[2].mean().tolist(),\n",
    "        cv_output6[2].mean().tolist(),\n",
    "        cv_output7[2].mean().tolist(),\n",
    "        cv_output8[2].mean().tolist(),\n",
    "        cv_output9[2].mean().tolist(),\n",
    "        cv_output10[2].mean().tolist(),\n",
    "    ],\n",
    "    columns=[\"train_mean\", \"test_mean\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        cv_output0[2].std().tolist(),\n",
    "        cv_output1[2].std().tolist(),\n",
    "        cv_output2[2].std().tolist(),\n",
    "        cv_output3[2].std().tolist(),\n",
    "        cv_output4[2].std().tolist(),\n",
    "        cv_output5[2].std().tolist(),\n",
    "        cv_output6[2].std().tolist(),\n",
    "        cv_output7[2].std().tolist(),\n",
    "        cv_output8[2].std().tolist(),\n",
    "        cv_output9[2].std().tolist(),\n",
    "        cv_output10[2].std().tolist(),\n",
    "    ],\n",
    "    columns=[\"train_std\", \"test_std\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \n",
    "print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(**hp[ ])\n",
    "model.fit(df.loc[:,  ].values, df.loc[:, \"etr\"].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"C:/Users/adria/Desktop/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates-main/models/rf.sav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_output_data_path = \"C:/Users/adria/Desktop/ML-in-Finance-I-case-study-forecasting-tax-avoidance-rates-main/data/output\"\n",
    "\n",
    "df = pd.read_csv(f\"{preprocessed_output_data_path}/train_fe.csv\", index_col=0)\n",
    "\n",
    "fr = pd.read_excel(f\"{preprocessed_output_data_path}/feature_ranking.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can omit that part in the case of Decision Tree \n",
    "# (as stated in the exercise description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['etr_y_past', 'etr_y_ma', 'txt', 'diff', 'ni', 'pi', 'intant', 'intant_sqrt', 'ta', 'revenue']\n"
     ]
    }
   ],
   "source": [
    "# Searching for \"good enough\" model to feature selection\n",
    "var = fr.mi_score.sort_values(ascending=False).index.tolist()[0:10]\n",
    "print(var) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.190189111918315"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Elastic Net: {'alpha': 0.5, 'l1_ratio': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Elastic Net\n",
    "param_elastic_net = {\n",
    "    \"alpha\": [0.1, 0.5, 1.0],\n",
    "    \"l1_ratio\": [0.1, 0.5, 0.9],\n",
    "}\n",
    "\n",
    "# Define the mean squared error scorer\n",
    "mse_elastic_net = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Create the ElasticNet model\n",
    "model_elastic_net = ElasticNet()\n",
    "\n",
    "# Create the GridSearchCV object for Elastic Net\n",
    "grid_CV_elastic_net = GridSearchCV(\n",
    "    model_elastic_net, param_elastic_net, cv=5, scoring=mse_elastic_net, return_train_score=True, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_CV_elastic_net.fit(df.loc[:, var].values, df.loc[:, \"etr\"].values.ravel())\n",
    "\n",
    "# Get the best parameters for Elastic Net\n",
    "best_params_elastic_net = grid_CV_elastic_net.best_params_\n",
    "print(\"Best Parameters for Elastic Net:\", best_params_elastic_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.02202797, 0.01693521, 0.00815468, 0.00857191, 0.00376339,\n",
      "       0.00565724, 0.01005464, 0.00635309, 0.00528479]), 'std_fit_time': array([0.00407073, 0.00798678, 0.00018821, 0.00068305, 0.00460919,\n",
      "       0.00692971, 0.00820958, 0.00712128, 0.00270563]), 'mean_score_time': array([1.99947357e-03, 0.00000000e+00, 2.54888535e-03, 1.60164833e-03,\n",
      "       0.00000000e+00, 7.53879547e-05, 0.00000000e+00, 4.24194336e-04,\n",
      "       8.84675980e-04]), 'std_score_time': array([0.00275932, 0.        , 0.00312173, 0.0032033 , 0.        ,\n",
      "       0.00015078, 0.        , 0.00084839, 0.0011698 ]), 'param_alpha': masked_array(data=[0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_l1_ratio': masked_array(data=[0.1, 0.5, 0.9, 0.1, 0.5, 0.9, 0.1, 0.5, 0.9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.1, 'l1_ratio': 0.1}, {'alpha': 0.1, 'l1_ratio': 0.5}, {'alpha': 0.1, 'l1_ratio': 0.9}, {'alpha': 0.5, 'l1_ratio': 0.1}, {'alpha': 0.5, 'l1_ratio': 0.5}, {'alpha': 0.5, 'l1_ratio': 0.9}, {'alpha': 1.0, 'l1_ratio': 0.1}, {'alpha': 1.0, 'l1_ratio': 0.5}, {'alpha': 1.0, 'l1_ratio': 0.9}], 'split0_test_score': array([-0.02084236, -0.02090618, -0.02095647, -0.02090678, -0.02145826,\n",
      "       -0.0214792 , -0.02097562, -0.02145504, -0.02128016]), 'split1_test_score': array([-0.02167706, -0.0216256 , -0.02159319, -0.02162498, -0.02164193,\n",
      "       -0.0217907 , -0.02158734, -0.02179648, -0.02183627]), 'split2_test_score': array([-0.0200194 , -0.02003677, -0.02006719, -0.02003715, -0.02028103,\n",
      "       -0.0204105 , -0.02007748, -0.020405  , -0.02036969]), 'split3_test_score': array([-0.0313799 , -0.02703238, -0.02688979, -0.0270296 , -0.02711186,\n",
      "       -0.02734033, -0.0268648 , -0.0273374 , -0.02732256]), 'split4_test_score': array([-0.02646603, -0.026549  , -0.02664526, -0.02654995, -0.02714273,\n",
      "       -0.02727663, -0.02667323, -0.02727803, -0.02728787]), 'mean_test_score': array([-0.02407695, -0.02322998, -0.02323038, -0.02322969, -0.02352716,\n",
      "       -0.02365947, -0.02323569, -0.02365439, -0.02361931]), 'std_test_score': array([0.00428314, 0.00295448, 0.00292949, 0.00295387, 0.00297638,\n",
      "       0.00301444, 0.00292528, 0.00301804, 0.00304576]), 'rank_test_score': array([9, 2, 3, 1, 5, 8, 4, 7, 6]), 'split0_train_score': array([-0.02345851, -0.02347798, -0.02350662, -0.02347821, -0.02377819,\n",
      "       -0.02384081, -0.02351713, -0.02384177, -0.02385314]), 'split1_train_score': array([-0.02311416, -0.02315013, -0.02318669, -0.02315044, -0.02345925,\n",
      "       -0.02369541, -0.02319721, -0.02369586, -0.02369783]), 'split2_train_score': array([-0.02346861, -0.02350343, -0.02353847, -0.02350368, -0.0237807 ,\n",
      "       -0.02396836, -0.02354794, -0.02397014, -0.02399062]), 'split3_train_score': array([-0.02158858, -0.02174107, -0.02177828, -0.02174148, -0.02212905,\n",
      "       -0.02226645, -0.02179234, -0.02226814, -0.02227661]), 'split4_train_score': array([-0.02186711, -0.0219023 , -0.02193696, -0.02190253, -0.02218728,\n",
      "       -0.02227083, -0.02194663, -0.02227114, -0.02227318]), 'mean_train_score': array([-0.02269939, -0.02275498, -0.0227894 , -0.02275527, -0.02306689,\n",
      "       -0.02320837, -0.02280025, -0.02320941, -0.02321827]), 'std_train_score': array([0.00080828, 0.00077384, 0.00077232, 0.0007738 , 0.00075135,\n",
      "       0.00077213, 0.00077137, 0.00077221, 0.00077582])}\n"
     ]
    }
   ],
   "source": [
    "# Access the full results\n",
    "cv_results_elastic_net = grid_CV_elastic_net.cv_results_\n",
    "print(cv_results_elastic_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.5, 'l1_ratio': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Right now (temporary) we will this hyperparameters as the best one:\n",
    "print(best_params_elastic_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_score</th>\n",
       "      <th>sign_fscore</th>\n",
       "      <th>sign_fscore_0_1</th>\n",
       "      <th>corr</th>\n",
       "      <th>EN_coef</th>\n",
       "      <th>boruta_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>etr_y_past</th>\n",
       "      <td>1.009402</td>\n",
       "      <td>1.304040e-84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etr_y_ma</th>\n",
       "      <td>0.825650</td>\n",
       "      <td>2.473770e-125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt</th>\n",
       "      <td>0.633067</td>\n",
       "      <td>5.246456e-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.368732</td>\n",
       "      <td>1.466269e-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>0.632640</td>\n",
       "      <td>2.257712e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.291716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>0.613297</td>\n",
       "      <td>1.747230e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.263458</td>\n",
       "      <td>-3.442000e-07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mi_score    sign_fscore  sign_fscore_0_1      corr       EN_coef  \\\n",
       "etr_y_past  1.009402   1.304040e-84                1  0.520405           NaN   \n",
       "etr_y_ma    0.825650  2.473770e-125                1  0.526871           NaN   \n",
       "txt         0.633067   5.246456e-13                1  0.368732  1.466269e-05   \n",
       "diff        0.632640   2.257712e-02                1 -0.291716           NaN   \n",
       "ni          0.613297   1.747230e-09                1  0.263458 -3.442000e-07   \n",
       "\n",
       "            boruta_rank  \n",
       "etr_y_past            1  \n",
       "etr_y_ma              1  \n",
       "txt                   1  \n",
       "diff                  1  \n",
       "ni                    7  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature ranking\n",
    "fr.sort_values(\"mi_score\", ascending=False, inplace=True)\n",
    "fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_features = fr[fr.boruta_rank.isin([1, 2, 3])].index.tolist()\n",
    "mi_features = fr.iloc[0:20].index.tolist()\n",
    "mi_features_25 = fr.iloc[0:25].index.tolist()\n",
    "mi_features_35 = fr.iloc[0:35].index.tolist()\n",
    "mi_features_50 = fr.iloc[0:50].index.tolist()\n",
    "fr[\"corr_abs\"] = np.abs(fr[\"corr\"])\n",
    "fr.sort_values(\"corr_abs\", ascending=False, inplace=True)\n",
    "corr_features = fr.iloc[0:20].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use our intuition and create two additional benchmark sets of variables:\n",
    "benchmark = [\n",
    "    \"rok\",\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"capex2_scaled\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"y_e_p_polity\",\n",
    "    \"y_BR_Democracy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"sektor_consumer discretionary\",\n",
    "    \"sektor_consumer staples\",\n",
    "    \"sektor_energy\",\n",
    "    \"sektor_health care\",\n",
    "    \"sektor_industrials\",\n",
    "    \"sektor_materials\",\n",
    "    \"sektor_real estate\",\n",
    "    \"sektor_technology\",\n",
    "    \"sektor_utilities\",\n",
    "    \"gielda_2\",\n",
    "    \"gielda_3\",\n",
    "    \"gielda_4\",\n",
    "    \"gielda_5\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_elastic_net = {\n",
    "    \"alpha\": [0.1, 0.5, 1.0],\n",
    "    \"l1_ratio\": [0.1, 0.5, 0.9],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark2 = [\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward elimination\n",
    "forward_elimination = [\n",
    "    \"rok\",\n",
    "    \"ta\",\n",
    "    \"txt\",\n",
    "    \"pi\",\n",
    "    \"str\",\n",
    "    \"xrd\",\n",
    "    \"ni\",\n",
    "    \"ppent\",\n",
    "    \"intant\",\n",
    "    \"dlc\",\n",
    "    \"dltt\",\n",
    "    \"capex\",\n",
    "    \"revenue\",\n",
    "    \"cce\",\n",
    "    \"adv\",\n",
    "    \"diff\",\n",
    "    \"roa\",\n",
    "    \"lev\",\n",
    "    \"intan\",\n",
    "    \"rd\",\n",
    "    \"ppe\",\n",
    "    \"sale\",\n",
    "    \"cash_holdings\",\n",
    "    \"adv_expenditure\",\n",
    "    \"capex2\",\n",
    "    \"cfc\",\n",
    "    \"dta\",\n",
    "    \"capex2_scaled\",\n",
    "    \"y_v2x_polyarchy\",\n",
    "    \"y_e_p_polity\",\n",
    "    \"y_BR_Democracy\",\n",
    "    \"WB_GDPgrowth\",\n",
    "    \"WB_GDPpc\",\n",
    "    \"WB_Inflation\",\n",
    "    \"rr_per_country\",\n",
    "    \"rr_per_sector\",\n",
    "    \"sektor_consumer discretionary\",\n",
    "    \"sektor_consumer staples\",\n",
    "    \"sektor_energy\",\n",
    "    \"sektor_health care\",\n",
    "    \"sektor_industrials\",\n",
    "    \"sektor_materials\",\n",
    "    \"sektor_real estate\",\n",
    "    \"sektor_technology\",\n",
    "    \"sektor_utilities\",\n",
    "    \"gielda_2\",\n",
    "    \"gielda_3\",\n",
    "    \"gielda_4\",\n",
    "    \"gielda_5\",\n",
    "    \"ta_log\",\n",
    "    \"txt_cat_(-63.011, -34.811]\",\n",
    "    \"txt_cat_(-34.811, 0.488]\",\n",
    "    \"txt_cat_(0.488, 24.415]\",\n",
    "    \"txt_cat_(24.415, 25.05]\",\n",
    "    \"txt_cat_(25.05, 308.55]\",\n",
    "    \"txt_cat_(308.55, 327.531]\",\n",
    "    \"txt_cat_(327.531, inf]\",\n",
    "    \"pi_cat_(-8975.0, -1.523]\",\n",
    "    \"pi_cat_(-1.523, 157.119]\",\n",
    "    \"pi_cat_(157.119, 465.9]\",\n",
    "    \"pi_cat_(465.9, 7875.5]\",\n",
    "    \"pi_cat_(7875.5, 8108.5]\",\n",
    "    \"pi_cat_(8108.5, inf]\",\n",
    "    \"str_cat_(0.0875, 0.192]\",\n",
    "    \"str_cat_(0.192, 0.28]\",\n",
    "    \"str_cat_(0.28, inf]\",\n",
    "    \"xrd_exists\",\n",
    "    \"ni_profit\",\n",
    "    \"ni_profit_20000\",\n",
    "    \"ppent_sqrt\",\n",
    "    \"intant_sqrt\",\n",
    "    \"dlc_cat_(42.262, 176.129]\",\n",
    "    \"dlc_cat_(176.129, 200.9]\",\n",
    "    \"dlc_cat_(200.9, inf]\",\n",
    "    \"dltt_cat_(39.38, 327.85]\",\n",
    "    \"dltt_cat_(327.85, 876.617]\",\n",
    "    \"dltt_cat_(876.617, inf]\",\n",
    "    \"capex_cat_(7.447, 79.55]\",\n",
    "    \"capex_cat_(79.55, 5451.0]\",\n",
    "    \"capex_cat_(5451.0, inf]\",\n",
    "    \"revenue_cat_(0.174, 1248.817]\",\n",
    "    \"revenue_cat_(1248.817, 4233.587]\",\n",
    "    \"revenue_cat_(4233.587, inf]\",\n",
    "    \"cce_cat_(5.619, 63.321]\",\n",
    "    \"cce_cat_(63.321, inf]\",\n",
    "    \"adv_cat_(0.3, 874.5]\",\n",
    "    \"adv_cat_(874.5, inf]\",\n",
    "    \"diff_positive\",\n",
    "    \"roa_clip\",\n",
    "    \"lev_sqrt\",\n",
    "    \"intan_pow2\",\n",
    "    \"rd_sqrt\",\n",
    "    \"ppe_clip\",\n",
    "    \"cash_holdings_sqrt\",\n",
    "    \"adv_expenditure_positive\",\n",
    "    \"diff_dta\",\n",
    "    \"cfc_dta\",\n",
    "    \"etr_y_past\",\n",
    "    \"etr_y_ma\",\n",
    "    \"diff_ma\",\n",
    "    \"roa_ma\",\n",
    "    \"lev_ma\",\n",
    "    \"intan_ma\",\n",
    "    \"ppe_ma\",\n",
    "    \"sale_ma\",\n",
    "    \"cash_holdings_ma\",\n",
    "    \"roa_past\",\n",
    "    \"lev_past\",\n",
    "    \"intan_past\",\n",
    "    \"ppe_past\",\n",
    "    \"sale_past\",\n",
    "    \"cash_holdings_past\",\n",
    "]\n",
    "forward_elimination.remove(\"ta_log\")\n",
    "forward_elimination.remove(\"ppent_sqrt\")\n",
    "forward_elimination.remove(\"intant_sqrt\")\n",
    "forward_elimination.remove(\"roa\")\n",
    "forward_elimination.remove(\"lev\")\n",
    "forward_elimination.remove(\"intan\")\n",
    "forward_elimination.remove(\"rd_sqrt\")\n",
    "forward_elimination.remove(\"ppe\")\n",
    "forward_elimination.remove(\"cash_holdings_sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_withoud_discr = [i for i in forward_elimination if \"]\" not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.5, 'l1_ratio': 0.1}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_CV_elastic_net.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rok', 'str', 'capex', 'adv', 'rd', 'sale', 'cash_holdings',\n",
      "       'adv_expenditure', 'cfc', 'dta', 'capex2_scaled', 'y_v2x_polyarchy',\n",
      "       'y_e_p_polity', 'WB_GDPpc', 'diff_ma'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "model_linear_elastic_net = ElasticNet(**grid_CV_elastic_net.best_params_)\n",
    "\n",
    "sf = SFS(\n",
    "    model_linear_elastic_net,\n",
    "    n_features_to_select=15,\n",
    "    direction='forward',\n",
    "    scoring=mse_elastic_net,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "sffit_linear_elastic_net = sf.fit(\n",
    "    df.loc[:, candidates_withoud_discr].values, df.loc[:, \"etr\"].values.ravel()\n",
    ")\n",
    "\n",
    "sf_features_linear_elastic_net = df.loc[:, candidates_withoud_discr].columns[sffit_linear_elastic_net.support_]\n",
    "\n",
    "sf_features_linear_elastic_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rok', 'str', 'capex', 'adv', 'rd', 'sale', 'cash_holdings',\n",
       "       'adv_expenditure', 'WB_GDPpc', 'diff_ma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear_elastic_net = ElasticNet(**grid_CV_elastic_net.best_params_)\n",
    "\n",
    "sf = SFS(\n",
    "    model_linear_elastic_net,\n",
    "    n_features_to_select=10,\n",
    "    direction='forward',\n",
    "    scoring=mse_elastic_net,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "sffit_linear_elastic_net = sf.fit(\n",
    "    df.loc[:, forward_elimination].values, df.loc[:, \"etr\"].values.ravel()\n",
    ")\n",
    "\n",
    "sf_features2_linear_elastic_net = df.loc[:, forward_elimination].columns[sffit_linear_elastic_net.support_]\n",
    "\n",
    "sf_features2_linear_elastic_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_one_more_linear_elastic_net = ['rok', 'str', 'capex', 'adv', 'rd', 'sale', 'cash_holdings','adv_expenditure', 'cfc', 'dta', 'capex2_scaled', 'y_v2x_polyarchy','y_e_p_polity', 'WB_GDPpc', 'diff_ma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rok', 'capex', 'adv', 'WB_GDPpc', 'diff_ma'], dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linear_elastic_net = ElasticNet(**grid_CV_elastic_net.best_params_)\n",
    "\n",
    "sf = SFS(\n",
    "    model_linear_elastic_net,\n",
    "    n_features_to_select=5,\n",
    "    direction='forward',\n",
    "    scoring=mse_elastic_net,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "sffit_linear_elastic_net = sf.fit(df.loc[:, sf_one_more_linear_elastic_net].values, df.loc[:, \"etr\"].values.ravel())\n",
    "\n",
    "sf_features3_linear_elastic_net = df.loc[:, sf_one_more_linear_elastic_net].columns[sffit_linear_elastic_net.support_]\n",
    "\n",
    "sf_features3_linear_elastic_net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters Tunning for each group of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bff0f7c864331389fa2ce0c5d534e26d0bfdbc8f9c927a5938dc8a191fde6d96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
